{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting whether a DNA sequence region is binding site to a specifictranscription factor.\n",
    "\n",
    "\n",
    "\n",
    "In this Kaggle Competition we were working on binary classification task of predicting whether a DNA sequence region is binding site to a specifictranscription factor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## [Optuna](https://optuna.org/) \n",
    "- A hyperparameter optimization framework\n",
    "\n",
    "## [cvxopt](https://cvxopt.org/) \n",
    "- A convex optimization package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cvxopt -q\n",
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import os\n",
    "import optuna\n",
    "import random\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import sklearn\n",
    "\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = pd.read_csv('data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n",
    "y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuction will help us get the label \n",
    "\n",
    "- Label will be  0 or 1 if we use type=0\n",
    "- label will be -1 or 1 if we use type=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(type=0):\n",
    "    y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)\n",
    "    if type == 0:\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    else:\n",
    "        y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    \n",
    "get_label(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will return train-val split data using sklearns built in train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y,p):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  seq\n",
       "Id                                                   \n",
       "0   GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THE DATA \n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa06304bb90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THE DATA IS PROPORTIONAL DATA \n",
    "y['Bound'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa062fa2110>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ADDITIONALLY ALL DATA CONTAINS 101 LENGTH SEQUENCES SO THERE WILL BE NO NEED OF PADDING \n",
    "X_train_['Count'] = X_train_.seq.apply(lambda x:len(x))\n",
    "X_train_['Count'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Related Experiments\n",
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.01086957 0.01086957 0.01086957 0.0326087  0.01086957 0.0326087\n",
      " 0.01086957 0.         0.         0.01086957 0.0326087  0.\n",
      " 0.         0.01086957 0.02173913 0.01086957 0.01086957 0.01086957\n",
      " 0.         0.0326087  0.02173913 0.         0.         0.01086957\n",
      " 0.01086957 0.01086957 0.         0.02173913 0.         0.01086957\n",
      " 0.01086957 0.04347826 0.         0.01086957 0.01086957 0.01086957\n",
      " 0.         0.01086957 0.04347826 0.01086957 0.02173913 0.02173913\n",
      " 0.         0.         0.01086957 0.02173913 0.02173913 0.\n",
      " 0.         0.         0.         0.01086957 0.         0.0326087\n",
      " 0.01086957 0.         0.01086957 0.         0.01086957 0.02173913\n",
      " 0.         0.01086957 0.01086957 0.02173913 0.01086957 0.\n",
      " 0.01086957 0.01086957 0.01086957 0.         0.         0.\n",
      " 0.         0.         0.01086957 0.01086957 0.         0.02173913\n",
      " 0.01086957 0.         0.         0.         0.         0.\n",
      " 0.04347826 0.01086957 0.01086957 0.01086957 0.01086957 0.02173913\n",
      " 0.02173913 0.         0.         0.         0.01086957 0.\n",
      " 0.         0.02173913 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',X_train_mat100[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal encoding DNA\n",
    "-------------------------------------------------------\n",
    "\n",
    "we assign \n",
    "\n",
    "    A - 0.25\n",
    "    C - 0.50\n",
    "    G - 0.71\n",
    "    T - 1.0\n",
    "    \n",
    "    \n",
    "and convert data to matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['A','C','G','T']))\n",
    "\n",
    "def ordinal_encoder(sequence):\n",
    "    integer_encoded = label_encoder.transform(np.array(list(sequence)))\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25\n",
    "    float_encoded[float_encoded == 1] = 0.50\n",
    "    float_encoded[float_encoded == 2] = 0.75\n",
    "    float_encoded[float_encoded == 3] = 1.00 \n",
    "    return float_encoded\n",
    "\n",
    "def get_ordinal_data(x_train):\n",
    "    X_list = []\n",
    "    for i in x_train:\n",
    "        X_list.append(ordinal_encoder(i))\n",
    "    return np.array(X_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.75 0.25 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.75 0.75 0.25 0.75\n",
      " 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.5  0.5  0.5  0.25 0.75 0.25\n",
      " 0.75 0.75 0.5  0.25 0.5  0.5  0.25 0.75 0.25 0.5  1.   0.5  1.   0.75\n",
      " 0.5  0.25 0.75 0.25 0.25 0.5  0.5  0.25 0.5  0.5  0.5  0.25 0.75 0.75\n",
      " 0.5  0.25 1.   1.   0.75 1.   0.75 0.75 0.75 0.75 0.5  1.   0.75 0.5\n",
      " 0.5  0.5  1.   0.75 0.5  0.5  0.25 0.5  0.5  1.   0.75 0.5  1.   0.75\n",
      " 0.75 0.5  0.5  0.75 0.5  1.   0.5  0.5  1.   0.75 0.75 1.   0.75 0.75\n",
      " 0.5  0.25 0.75]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',get_ordinal_data(X_train_.seq.values)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer counting/Spectral Embedding\n",
    "--------------------------------------------------------\n",
    "\n",
    "\n",
    "K-mer of size 3 \n",
    "\n",
    "    'ACAAT' = ['aca', 'caa', 'aat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size=3):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "\n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "def get_data(kmer_size):\n",
    "    data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "    train_text = data.seq.values\n",
    "    kmer_data = []\n",
    "    for i in train_text:\n",
    "        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))\n",
    "\n",
    "    return np.array(kmer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer / TfidfTransformer\n",
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "#### Count Vectorizer \n",
    "    \n",
    "   - ngram_range = 2,analyzer='char'\n",
    "    \n",
    "    'ACAAATTTGGGGAAA' - [4, 1, 1, 1, 1, 3, 1, 2]\n",
    "    \n",
    " \n",
    "#### TfidfVectorizer \n",
    "\n",
    "   - ngram_range = 2,analyzer='char'\n",
    "\n",
    "    'ACAAATTTGGGGAAA' - [0.68599434, 0.17149859, 0.17149859, 0.17149859, 0.17149859,\n",
    "        0.51449576, 0.17149859, 0.34299717]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_grams(data,n=6):\n",
    "    cv = CountVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X\n",
    "\n",
    "def get_tf_idf_grams(data,n=6):\n",
    "    cv = TfidfVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Related Experiments\n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started this experiment with a simple logistic regression with a batch gradient descent. \n",
    "This algorithm was train and validated with the  data processings we did above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression \n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=64,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))+(2*(self._lambda/len(self.train_labels ))*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(len(self.train_labels)//self.batch_size):\n",
    "                idx = list(np.random.choice(np.arange(len(self.train_labels)),self.batch_size,replace=False))\n",
    "                data = self.train_data[idx]\n",
    "                label = self.train_labels[idx]\n",
    "\n",
    "                y_pred = self.sigmoid(np.dot(data,self.params))\n",
    "                loss = self.cost(label,y_pred)\n",
    "\n",
    "                gra = self.gradient(label,y_pred,data)\n",
    "                self.params -= self.lr*gra\n",
    "\n",
    "                self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=4,batch_size=64,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_result = cross_validate(X_train_mat100,get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "ordinal_result = cross_validate(get_ordinal_data(X_train_.seq.values),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "kmer_result = cross_validate(get_data(6)[:2000,:],get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "count_result = cross_validate(get_count_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "tfidf_result = cross_validate(get_tf_idf_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test which data is better representation\n",
    "----------------------------------------------\n",
    "\n",
    "\n",
    " The First Result Shows The Quality of the data on a simple logistic regression without any hyper-parameters search. Meaning that this is not the best value this method can achive but it can show us the quality of the data preprocessing\n",
    " \n",
    "- The parameters of logistic regression was not optimized for each data so this result might not show the real value.\n",
    " \n",
    "- Count Vectorizer is the best representation so far "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot === 0.483\n",
      "Ordinal === 0.49499999999999994\n",
      "K-mer === 0.607\n",
      "Count-Vectorizer === 0.624\n",
      "Tf-idf === 0.5189999999999999\n"
     ]
    }
   ],
   "source": [
    "final_value = {'One Hot':one_hot_result,'Ordinal':ordinal_result,'K-mer':kmer_result,'Count-Vectorizer':count_result,'Tf-idf':tfidf_result}\n",
    "final_value\n",
    "\n",
    "for k,v in final_value.items():\n",
    "    print('{} === {}'.format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Related Experiments +  Kernel Related Experiments\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already experimented with Logistic regression now we will add \n",
    "\n",
    "- Ridge Regression\n",
    "- SVM\n",
    "- Kernelized Method of the Variants\n",
    "\n",
    "In the folowing lines of code  define a set of kernels that we will applied with ridge regression and SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2.T)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is Base class for all Kernelized method we saw in class \n",
    "     \n",
    "All kernelized methods are derived from this class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is  implementation of ridge regression with kernel.\n",
    "- We train this model with alll the kernels above.\n",
    "- It gives the best performance in the leaderboard with linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X,X,**self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with all the kernels defined above.\n",
    "-----------------------------------------------------\n",
    "\n",
    "- After training, we realized that the linear kernel with the k-mer data was giving the best result(65% on cross validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We cross validated all of our submissions to avoud overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,model_name,lr=None,kernel=None,lambd=0.2,C=3,sigma=0.5,k=5,power=2):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "\n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)\n",
    "\n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "\n",
    "        if model_name == 'KernelRidgeRegression':\n",
    "            model = KernelRidgeRegression(\n",
    "                    kernel=kernel,\n",
    "                    lambd=lambd,\n",
    "                    sigma=sigma,\n",
    "                    power=power\n",
    "                ).fit(x_train, y_train)\n",
    "            result =sum(np.sign(model.predict(x_test))==y_test)/len(y_test)#roc_auc_score(np.sign(model.predict(x_test)),y_test) #\n",
    "\n",
    "        elif model_name == 'KernelSVM':\n",
    "\n",
    "            model = KernelSVM(C=C,\n",
    "                              kernel=kernel,\n",
    "                              lambd=lambd,\n",
    "                              sigma=sigma,\n",
    "                              power=power)\n",
    "            model.fit(x_train, y_train.flatten())\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            result = sum((y_pred.flatten()==y_test.flatten()))/len(y_test)\n",
    "\n",
    "        else:\n",
    "            print('wrong model_name')\n",
    "            return 0\n",
    "\n",
    "        aggrigate_result.append(result)\n",
    "\n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optuna](https://optuna.org/) \n",
    "\n",
    "- A hyperparameter optimization framework\n",
    "- we tried to get the best hyperparameters for the models we worked on using this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e0aaba62e441138060c5900abf72c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2020-06-01 10:32:21,828] Finished trial#0 with value: 0.562 with parameters: {'sigma': 128.99795620168032, 'k': 5, 'C': 22.54113808303137, 'kmer_size': 3}. Best is trial#0 with value: 0.562.\n",
      "[I 2020-06-01 10:32:23,962] Finished trial#1 with value: 0.5725 with parameters: {'sigma': 24.400117286390017, 'k': 8, 'C': 35.79361689279468, 'kmer_size': 4}. Best is trial#1 with value: 0.5725.\n",
      "[I 2020-06-01 10:32:26,520] Finished trial#2 with value: 0.583 with parameters: {'sigma': 66.01415659934182, 'k': 4, 'C': 29.44839669923022, 'kmer_size': 4}. Best is trial#2 with value: 0.583.\n",
      "[I 2020-06-01 10:32:28,980] Finished trial#3 with value: 0.5835 with parameters: {'sigma': 83.66670812198443, 'k': 4, 'C': 49.82572811712092, 'kmer_size': 4}. Best is trial#3 with value: 0.5835.\n",
      "[I 2020-06-01 10:32:37,115] Finished trial#4 with value: 0.6425 with parameters: {'sigma': 87.437965421459, 'k': 5, 'C': 46.820413160314324, 'kmer_size': 8}. Best is trial#4 with value: 0.6425.\n",
      "[I 2020-06-01 10:32:39,520] Finished trial#5 with value: 0.554 with parameters: {'sigma': 128.45298479612143, 'k': 4, 'C': 6.1370861834487185, 'kmer_size': 3}. Best is trial#4 with value: 0.6425.\n",
      "[I 2020-06-01 10:32:41,638] Finished trial#6 with value: 0.594 with parameters: {'sigma': 16.10638751251582, 'k': 8, 'C': 13.336151813637128, 'kmer_size': 5}. Best is trial#4 with value: 0.6425.\n",
      "[I 2020-06-01 10:32:43,810] Finished trial#7 with value: 0.55 with parameters: {'sigma': 115.24894159903602, 'k': 8, 'C': 10.268836194273867, 'kmer_size': 5}. Best is trial#4 with value: 0.6425.\n",
      "[I 2020-06-01 10:32:46,402] Finished trial#8 with value: 0.549 with parameters: {'sigma': 71.73106478344341, 'k': 4, 'C': 49.30243147360836, 'kmer_size': 3}. Best is trial#4 with value: 0.6425.\n",
      "[I 2020-06-01 10:32:53,586] Finished trial#9 with value: 0.634 with parameters: {'sigma': 54.98477450994484, 'k': 8, 'C': 30.563594218199704, 'kmer_size': 8}. Best is trial#4 with value: 0.6425.\n",
      "[I 2020-06-01 10:33:01,527] Finished trial#10 with value: 0.6365000000000001 with parameters: {'sigma': 100.14397534441186, 'k': 5, 'C': 41.4423347987118, 'kmer_size': 8}. Best is trial#4 with value: 0.6425.\n",
      "[I 2020-06-01 10:33:09,188] Finished trial#11 with value: 0.6385 with parameters: {'sigma': 97.02698360303098, 'k': 5, 'C': 41.822944916571615, 'kmer_size': 8}. Best is trial#4 with value: 0.6425.\n",
      "[I 2020-06-01 10:33:13,671] Finished trial#12 with value: 0.645 with parameters: {'sigma': 98.42365912494891, 'k': 5, 'C': 42.79580665391893, 'kmer_size': 7}. Best is trial#12 with value: 0.645.\n",
      "[I 2020-06-01 10:33:17,610] Finished trial#13 with value: 0.645 with parameters: {'sigma': 41.86561319562589, 'k': 5, 'C': 44.35753052217398, 'kmer_size': 7}. Best is trial#12 with value: 0.645.\n",
      "[I 2020-06-01 10:33:23,311] Finished trial#14 with value: 0.6455 with parameters: {'sigma': 39.22543981826696, 'k': 5, 'C': 40.18405304459805, 'kmer_size': 7}. Best is trial#14 with value: 0.6455.\n",
      "[I 2020-06-01 10:33:28,068] Finished trial#15 with value: 0.6465 with parameters: {'sigma': 38.28079320087854, 'k': 5, 'C': 36.20751863587375, 'kmer_size': 7}. Best is trial#15 with value: 0.6465.\n",
      "[I 2020-06-01 10:33:32,300] Finished trial#16 with value: 0.6485000000000001 with parameters: {'sigma': 5.115940591947755, 'k': 5, 'C': 35.952304209122595, 'kmer_size': 7}. Best is trial#16 with value: 0.6485000000000001.\n",
      "[I 2020-06-01 10:33:35,474] Finished trial#17 with value: 0.5 with parameters: {'sigma': 1.9451487595138062, 'k': 5, 'C': 24.149024982299856, 'kmer_size': 6}. Best is trial#16 with value: 0.6485000000000001.\n",
      "[I 2020-06-01 10:33:38,326] Finished trial#18 with value: 0.5 with parameters: {'sigma': 0.01755325397149221, 'k': 5, 'C': 32.51812995774021, 'kmer_size': 6}. Best is trial#16 with value: 0.6485000000000001.\n",
      "[I 2020-06-01 10:33:42,782] Finished trial#19 with value: 0.6434999999999998 with parameters: {'sigma': 22.67995740070605, 'k': 5, 'C': 19.199041271897723, 'kmer_size': 7}. Best is trial#16 with value: 0.6485000000000001.\n",
      "[I 2020-06-01 10:33:46,209] Finished trial#20 with value: 0.6205 with parameters: {'sigma': 39.583675133607834, 'k': 5, 'C': 38.074094529722124, 'kmer_size': 6}. Best is trial#16 with value: 0.6485000000000001.\n",
      "[I 2020-06-01 10:33:50,630] Finished trial#21 with value: 0.6455 with parameters: {'sigma': 40.72689626919953, 'k': 5, 'C': 34.900072262268516, 'kmer_size': 7}. Best is trial#16 with value: 0.6485000000000001.\n",
      "[I 2020-06-01 10:33:55,794] Finished trial#22 with value: 0.6515 with parameters: {'sigma': 13.287654436893252, 'k': 5, 'C': 34.33192389814006, 'kmer_size': 7}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:01,738] Finished trial#23 with value: 0.6329999999999999 with parameters: {'sigma': 10.395022868349667, 'k': 5, 'C': 27.890523973472064, 'kmer_size': 6}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:08,321] Finished trial#24 with value: 0.6435000000000001 with parameters: {'sigma': 26.73666886036404, 'k': 5, 'C': 34.90730089809348, 'kmer_size': 7}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:19,420] Finished trial#25 with value: 0.5 with parameters: {'sigma': 0.6684008147058407, 'k': 5, 'C': 37.647269241826784, 'kmer_size': 8}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:23,217] Finished trial#26 with value: 0.617 with parameters: {'sigma': 54.25472744386549, 'k': 5, 'C': 26.046119364842326, 'kmer_size': 6}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:28,054] Finished trial#27 with value: 0.6515 with parameters: {'sigma': 11.235415148817019, 'k': 5, 'C': 19.526092824498665, 'kmer_size': 7}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:30,461] Finished trial#28 with value: 0.6175 with parameters: {'sigma': 10.687455000563787, 'k': 5, 'C': 17.621614575732877, 'kmer_size': 5}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:34,500] Finished trial#29 with value: 0.65 with parameters: {'sigma': 5.495550603329001, 'k': 5, 'C': 21.745799620901558, 'kmer_size': 7}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:42,271] Finished trial#30 with value: 0.6485000000000001 with parameters: {'sigma': 18.754029366657818, 'k': 5, 'C': 21.504173530919093, 'kmer_size': 8}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:49,281] Finished trial#31 with value: 0.6485000000000001 with parameters: {'sigma': 18.791541418667602, 'k': 5, 'C': 21.206581157264647, 'kmer_size': 8}. Best is trial#22 with value: 0.6515.\n",
      "[I 2020-06-01 10:34:57,536] Finished trial#32 with value: 0.6545000000000001 with parameters: {'sigma': 29.96510649255368, 'k': 5, 'C': 15.482448911244525, 'kmer_size': 8}. Best is trial#32 with value: 0.6545000000000001.\n",
      "[I 2020-06-01 10:35:01,573] Finished trial#33 with value: 0.6434999999999998 with parameters: {'sigma': 25.629903117399316, 'k': 5, 'C': 15.38109585062718, 'kmer_size': 7}. Best is trial#32 with value: 0.6545000000000001.\n",
      "[I 2020-06-01 10:35:10,692] Finished trial#34 with value: 0.6455 with parameters: {'sigma': 32.36660140078941, 'k': 4, 'C': 1.6331474489010986, 'kmer_size': 8}. Best is trial#32 with value: 0.6545000000000001.\n",
      "[I 2020-06-01 10:35:13,433] Finished trial#35 with value: 0.6145 with parameters: {'sigma': 51.59364356671718, 'k': 8, 'C': 10.888453556939623, 'kmer_size': 6}. Best is trial#32 with value: 0.6545000000000001.\n",
      "[I 2020-06-01 10:35:17,670] Finished trial#36 with value: 0.6525000000000001 with parameters: {'sigma': 10.3208289833565, 'k': 5, 'C': 17.834909300315054, 'kmer_size': 7}. Best is trial#32 with value: 0.6545000000000001.\n",
      "[I 2020-06-01 10:35:25,769] Finished trial#37 with value: 0.656 with parameters: {'sigma': 12.253201905711522, 'k': 4, 'C': 15.358691700993838, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:35:33,204] Finished trial#38 with value: 0.645 with parameters: {'sigma': 32.011058445010434, 'k': 4, 'C': 6.387845170463278, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:35:41,363] Finished trial#39 with value: 0.6234999999999999 with parameters: {'sigma': 147.76453405899565, 'k': 4, 'C': 15.572347058463707, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2020-06-01 10:35:48,735] Finished trial#40 with value: 0.6475 with parameters: {'sigma': 65.85012221827802, 'k': 4, 'C': 11.211238628207138, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:35:53,118] Finished trial#41 with value: 0.642 with parameters: {'sigma': 12.630859648668418, 'k': 4, 'C': 17.136727203415578, 'kmer_size': 7}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:01,216] Finished trial#42 with value: 0.656 with parameters: {'sigma': 12.267519174365416, 'k': 4, 'C': 7.732742453383768, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:09,456] Finished trial#43 with value: 0.6475000000000001 with parameters: {'sigma': 29.13457399971819, 'k': 4, 'C': 7.396581899870303, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:17,642] Finished trial#44 with value: 0.6505000000000001 with parameters: {'sigma': 7.039986524500167, 'k': 4, 'C': 1.7894281829649117, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:25,153] Finished trial#45 with value: 0.654 with parameters: {'sigma': 16.655566640417717, 'k': 4, 'C': 13.761105457137766, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:33,590] Finished trial#46 with value: 0.6535 with parameters: {'sigma': 21.43281902715622, 'k': 4, 'C': 12.7506806797131, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:41,633] Finished trial#47 with value: 0.654 with parameters: {'sigma': 20.515303555374196, 'k': 4, 'C': 8.227038679776653, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:48,959] Finished trial#48 with value: 0.646 with parameters: {'sigma': 49.51717593539332, 'k': 4, 'C': 4.021434943711922, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:56,670] Finished trial#49 with value: 0.649 with parameters: {'sigma': 33.36877843514472, 'k': 4, 'C': 8.690352186813445, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:36:59,160] Finished trial#50 with value: 0.588 with parameters: {'sigma': 47.41004019330317, 'k': 4, 'C': 13.94119654299816, 'kmer_size': 4}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:37:06,829] Finished trial#51 with value: 0.653 with parameters: {'sigma': 21.23356571010592, 'k': 4, 'C': 12.701393149619227, 'kmer_size': 8}. Best is trial#37 with value: 0.656.\n",
      "[I 2020-06-01 10:37:14,572] Finished trial#52 with value: 0.657 with parameters: {'sigma': 18.419073644676157, 'k': 4, 'C': 4.572830510889204, 'kmer_size': 8}. Best is trial#52 with value: 0.657.\n",
      "[I 2020-06-01 10:37:23,267] Finished trial#53 with value: 0.658 with parameters: {'sigma': 15.988389521578528, 'k': 4, 'C': 4.202029033820121, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:37:30,730] Finished trial#54 with value: 0.499 with parameters: {'sigma': 3.0643004664818996, 'k': 4, 'C': 4.103256372209795, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:37:38,493] Finished trial#55 with value: 0.648 with parameters: {'sigma': 26.432289274256323, 'k': 4, 'C': 4.8514509971093345, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:37:46,649] Finished trial#56 with value: 0.509 with parameters: {'sigma': 65.13604324826653, 'k': 4, 'C': 0.5601302416614757, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:37:54,476] Finished trial#57 with value: 0.6545000000000001 with parameters: {'sigma': 16.695598340466887, 'k': 4, 'C': 9.467826296537723, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:38:01,823] Finished trial#58 with value: 0.623 with parameters: {'sigma': 35.42476073943902, 'k': 8, 'C': 9.523038770984744, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:38:09,464] Finished trial#59 with value: 0.529 with parameters: {'sigma': 45.11370422581261, 'k': 4, 'C': 2.6796581650975204, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:38:13,494] Finished trial#60 with value: 0.495 with parameters: {'sigma': 0.009932830194980369, 'k': 4, 'C': 6.975259707284004, 'kmer_size': 7}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:38:21,219] Finished trial#61 with value: 0.655 with parameters: {'sigma': 14.796658358510513, 'k': 4, 'C': 8.60106988119689, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:38:29,696] Finished trial#62 with value: 0.656 with parameters: {'sigma': 13.684173484027458, 'k': 4, 'C': 5.06389712737334, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:38:38,505] Finished trial#63 with value: 0.657 with parameters: {'sigma': 15.196717783773249, 'k': 4, 'C': 5.449421912688706, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:38:47,163] Finished trial#64 with value: 0.6545 with parameters: {'sigma': 7.555067774747975, 'k': 4, 'C': 5.401680891446891, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:38:52,406] Finished trial#65 with value: 0.644 with parameters: {'sigma': 16.063746626524104, 'k': 4, 'C': 2.412238467439017, 'kmer_size': 7}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:39:01,988] Finished trial#66 with value: 0.5825 with parameters: {'sigma': 84.92161167020991, 'k': 4, 'C': 3.4959523788678655, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:39:11,757] Finished trial#67 with value: 0.5155 with parameters: {'sigma': 4.492585456039627, 'k': 4, 'C': 0.26184650329216375, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:39:16,530] Finished trial#68 with value: 0.64 with parameters: {'sigma': 15.091589418341686, 'k': 4, 'C': 6.2092327115696335, 'kmer_size': 7}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:39:19,061] Finished trial#69 with value: 0.5665 with parameters: {'sigma': 24.30510961188921, 'k': 4, 'C': 10.855428633887506, 'kmer_size': 3}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:39:28,749] Finished trial#70 with value: 0.495 with parameters: {'sigma': 0.2679411758145367, 'k': 4, 'C': 7.732056804700643, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:39:36,998] Finished trial#71 with value: 0.655 with parameters: {'sigma': 13.906571096174105, 'k': 4, 'C': 9.616288728044534, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:39:45,790] Finished trial#72 with value: 0.6565000000000001 with parameters: {'sigma': 10.890884424202214, 'k': 4, 'C': 4.79227051429522, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:39:53,579] Finished trial#73 with value: 0.653 with parameters: {'sigma': 8.558415796598332, 'k': 4, 'C': 5.24313033417019, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:40:01,268] Finished trial#74 with value: 0.53 with parameters: {'sigma': 110.76757620947183, 'k': 4, 'C': 3.833493747853854, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:40:10,121] Finished trial#75 with value: 0.495 with parameters: {'sigma': 23.223310424568922, 'k': 4, 'C': 0.30442159149210024, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:40:19,209] Finished trial#76 with value: 0.509 with parameters: {'sigma': 4.4159022460765405, 'k': 8, 'C': 11.82488141645609, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:40:26,450] Finished trial#77 with value: 0.6455000000000001 with parameters: {'sigma': 10.647899082478759, 'k': 4, 'C': 6.128469233129083, 'kmer_size': 7}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:40:42,791] Finished trial#78 with value: 0.6545000000000001 with parameters: {'sigma': 27.79734424130237, 'k': 4, 'C': 10.009904100900156, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:40:51,772] Finished trial#79 with value: 0.6215 with parameters: {'sigma': 12.875089926788377, 'k': 4, 'C': 1.5375349852519489, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:40:59,298] Finished trial#80 with value: 0.6535000000000001 with parameters: {'sigma': 19.178560908880502, 'k': 4, 'C': 8.145927345406788, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2020-06-01 10:41:06,749] Finished trial#81 with value: 0.656 with parameters: {'sigma': 14.154446831012935, 'k': 4, 'C': 5.005566877068541, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:41:14,188] Finished trial#82 with value: 0.6525000000000001 with parameters: {'sigma': 7.819745913677279, 'k': 4, 'C': 2.9083538103173034, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:41:22,687] Finished trial#83 with value: 0.6555000000000001 with parameters: {'sigma': 12.388509736242316, 'k': 4, 'C': 4.96263952086538, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:41:30,515] Finished trial#84 with value: 0.495 with parameters: {'sigma': 0.726891297432795, 'k': 4, 'C': 5.3407228417518695, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:41:39,659] Finished trial#85 with value: 0.647 with parameters: {'sigma': 36.44477854664494, 'k': 4, 'C': 7.198279464448125, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:41:44,825] Finished trial#86 with value: 0.6415000000000001 with parameters: {'sigma': 18.23318425569571, 'k': 4, 'C': 4.433883952029524, 'kmer_size': 7}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:41:54,419] Finished trial#87 with value: 0.528 with parameters: {'sigma': 24.25050939069592, 'k': 4, 'C': 0.5885076591273446, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:42:02,764] Finished trial#88 with value: 0.6515000000000001 with parameters: {'sigma': 6.829274989647841, 'k': 4, 'C': 1.3778776537185013, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:42:15,085] Finished trial#89 with value: 0.657 with parameters: {'sigma': 11.551397188439205, 'k': 4, 'C': 6.228104162027128, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:42:23,162] Finished trial#90 with value: 0.623 with parameters: {'sigma': 29.429278489371953, 'k': 8, 'C': 3.251649613238736, 'kmer_size': 7}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:42:37,372] Finished trial#91 with value: 0.655 with parameters: {'sigma': 9.494178082902168, 'k': 4, 'C': 6.446656070597413, 'kmer_size': 8}. Best is trial#53 with value: 0.658.\n",
      "[I 2020-06-01 10:42:51,454] Finished trial#92 with value: 0.6595 with parameters: {'sigma': 20.924048914171447, 'k': 4, 'C': 5.468643148499604, 'kmer_size': 8}. Best is trial#92 with value: 0.6595.\n",
      "[I 2020-06-01 10:42:58,872] Finished trial#93 with value: 0.654 with parameters: {'sigma': 19.770115905358207, 'k': 4, 'C': 6.225218148528591, 'kmer_size': 8}. Best is trial#92 with value: 0.6595.\n",
      "[I 2020-06-01 10:43:07,612] Finished trial#94 with value: 0.4955 with parameters: {'sigma': 2.3151882587313057, 'k': 4, 'C': 2.365699054083091, 'kmer_size': 8}. Best is trial#92 with value: 0.6595.\n",
      "[I 2020-06-01 10:43:16,433] Finished trial#95 with value: 0.654 with parameters: {'sigma': 22.68671731047302, 'k': 4, 'C': 8.845237725441109, 'kmer_size': 8}. Best is trial#92 with value: 0.6595.\n",
      "[I 2020-06-01 10:43:24,410] Finished trial#96 with value: 0.654 with parameters: {'sigma': 16.76211952886807, 'k': 4, 'C': 7.466873728579058, 'kmer_size': 8}. Best is trial#92 with value: 0.6595.\n",
      "[I 2020-06-01 10:43:26,970] Finished trial#97 with value: 0.6255000000000001 with parameters: {'sigma': 4.563490798937014, 'k': 4, 'C': 4.3421205416349675, 'kmer_size': 5}. Best is trial#92 with value: 0.6595.\n",
      "[I 2020-06-01 10:43:29,613] Finished trial#98 with value: 0.595 with parameters: {'sigma': 12.737877293204969, 'k': 4, 'C': 12.09332748265709, 'kmer_size': 4}. Best is trial#92 with value: 0.6595.\n",
      "[I 2020-06-01 10:43:37,470] Finished trial#99 with value: 0.6465 with parameters: {'sigma': 31.117062199595317, 'k': 4, 'C': 5.462847448016438, 'kmer_size': 8}. Best is trial#92 with value: 0.6595.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "#     lambd = trial.suggest_float('lambd', 1e-5, 100.0)\n",
    "    sigma = trial.suggest_float('sigma', 1e-5, 150)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8])\n",
    "    C =  trial.suggest_float('C', 0.1,50)\n",
    "#     power =  trial.suggest_int('power', 2,5)\n",
    "    kmer_size =  trial.suggest_int('kmer_size', 3,8)\n",
    "#     kernel =  trial.suggest_categorical('kernel', ['linear','rbf','gaussian_kernel','polynomial'])\n",
    "#     model_name\n",
    "    \n",
    "    return cross_validate(get_data(kmer_size)[:2000,:],get_label(type=-1),model_name='KernelSVM',C=C,kernel='rbf',lambd=0,k=k,sigma=sigma,power=1)\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=100,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.sort_values(by=['value']).tail(7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "             value\t\tparams_C\tparams_k\tparams_kmer_size\tparams_lambd\tparams_power params_sigma\n",
    "\n",
    "\n",
    "linear  -     0.6520\t   47.102628\t    4\t     7\t    0.756909\t    3\t       15.369069\n",
    "rbf           0.6470\t\t9.071834\t5\t7\t77.976361\t4\t3.775633\n",
    "polynomial    0.6585\t\t27.187947\t4\t7\t1.418356\t2    -  \n",
    "\n",
    "\n",
    "svm\n",
    "\n",
    "linear        0.6525\t\t10.791498\t5\t8\t52.239587\t4\t74.078190\n",
    "rbf           0.6530\t\t14.611283\t4\t7\t32.915987\t2\t45.600422\n",
    "polynomial    0.6315\t  \t18.056135\t4\t5\t53.476413\t3\t9.218339"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we use our best parameters and train our model and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 65536) (20, 65536) (1980, 1) (20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test  = get_train_test(get_data(8)[:2000,:],get_label(type=-1).reshape(-1,1),p=0.01)\n",
    "\n",
    "\n",
    "kernel = 'rbf'\n",
    "power = 3\n",
    "sigma = 12.217523\n",
    "C = 9.839876\n",
    "lambd = 38.202739\n",
    "model = KernelSVM(C=C, kernel=kernel, sigma=sigma,lambd=lambd, power=power)\n",
    "model.fit(X_train, y_train.flatten())\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "sum(y_pred.flatten()==y_test.flatten())/len(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(get_data(8)[:2000,:],get_label(type=-1),\n",
    "               model_name='KernelSVM',\n",
    "               kernel = 'rbf',\n",
    "               k=4,\n",
    "                power = 3,\n",
    "                sigma = 12.217523,\n",
    "                C = 9.839876,\n",
    "                lambd = 38.202739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final  = model.predict(get_data(8)[2000:,:])\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = X_test_final[i]\n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_rbf-svm.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- we tried and tested and found that Ridge Regression,SVM are good models to work on when we have small data set coupled with special kernels.\n",
    "- Resources on writing kernels were very scarce and some additional kernels we tried to implement was not succsessful because of time constraint. For example Mismatch kernel and String simillarity kernels\n",
    "- Optimizing parameters for kernels is very difficult task. we took more than half of the time doing parameter search.\n",
    "- new data represetnations are the best way to improve our model looking forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional\n",
    "\n",
    "- Please take a look at the code we worked on to see detail implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

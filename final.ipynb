{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cvxopt -q\n",
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import os\n",
    "import optuna\n",
    "import random\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import sklearn\n",
    "\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = pd.read_csv('data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n",
    "y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Fuction will help us get the label \n",
    "\n",
    "- Label will be  0 or 1 if we use type=0\n",
    "- label will be -1 or 1 if we use type=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(type=0):\n",
    "    y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)\n",
    "    if type == 0:\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    else:\n",
    "        y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    \n",
    "get_label(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will return train-val split data using sklearns built in train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y,p):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  seq\n",
       "Id                                                   \n",
       "0   GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THE DATA \n",
    "\n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f03a0bb57f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THE DATA IS PROPORTIONAL DATA \n",
    "\n",
    "y['Bound'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f03a0ec6668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ADDITIONALLY ALL DATA CONTAINS 101 LENGTH SEQUENCES SO THERE WILL BE NO NEED OF PADDING \n",
    "\n",
    "X_train_['Count'] = X_train_.seq.apply(lambda x:len(x))\n",
    "X_train_['Count'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.01086957 0.01086957 0.01086957 0.0326087  0.01086957 0.0326087\n",
      " 0.01086957 0.         0.         0.01086957 0.0326087  0.\n",
      " 0.         0.01086957 0.02173913 0.01086957 0.01086957 0.01086957\n",
      " 0.         0.0326087  0.02173913 0.         0.         0.01086957\n",
      " 0.01086957 0.01086957 0.         0.02173913 0.         0.01086957\n",
      " 0.01086957 0.04347826 0.         0.01086957 0.01086957 0.01086957\n",
      " 0.         0.01086957 0.04347826 0.01086957 0.02173913 0.02173913\n",
      " 0.         0.         0.01086957 0.02173913 0.02173913 0.\n",
      " 0.         0.         0.         0.01086957 0.         0.0326087\n",
      " 0.01086957 0.         0.01086957 0.         0.01086957 0.02173913\n",
      " 0.         0.01086957 0.01086957 0.02173913 0.01086957 0.\n",
      " 0.01086957 0.01086957 0.01086957 0.         0.         0.\n",
      " 0.         0.         0.01086957 0.01086957 0.         0.02173913\n",
      " 0.01086957 0.         0.         0.         0.         0.\n",
      " 0.04347826 0.01086957 0.01086957 0.01086957 0.01086957 0.02173913\n",
      " 0.02173913 0.         0.         0.         0.01086957 0.\n",
      " 0.         0.02173913 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',X_train_mat100[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal encoding DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['A','C','G','T']))\n",
    "\n",
    "def ordinal_encoder(sequence):\n",
    "    integer_encoded = label_encoder.transform(np.array(list(sequence)))\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25\n",
    "    float_encoded[float_encoded == 1] = 0.50\n",
    "    float_encoded[float_encoded == 2] = 0.75\n",
    "    float_encoded[float_encoded == 3] = 1.00 \n",
    "    return float_encoded\n",
    "\n",
    "def get_ordinal_data(x_train):\n",
    "    X_list = []\n",
    "    for i in x_train:\n",
    "        X_list.append(ordinal_encoder(i))\n",
    "    return np.array(X_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.75 0.25 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.75 0.75 0.25 0.75\n",
      " 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.5  0.5  0.5  0.25 0.75 0.25\n",
      " 0.75 0.75 0.5  0.25 0.5  0.5  0.25 0.75 0.25 0.5  1.   0.5  1.   0.75\n",
      " 0.5  0.25 0.75 0.25 0.25 0.5  0.5  0.25 0.5  0.5  0.5  0.25 0.75 0.75\n",
      " 0.5  0.25 1.   1.   0.75 1.   0.75 0.75 0.75 0.75 0.5  1.   0.75 0.5\n",
      " 0.5  0.5  1.   0.75 0.5  0.5  0.25 0.5  0.5  1.   0.75 0.5  1.   0.75\n",
      " 0.75 0.5  0.5  0.75 0.5  1.   0.5  0.5  1.   0.75 0.75 1.   0.75 0.75\n",
      " 0.5  0.25 0.75]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',get_ordinal_data(X_train_.seq.values)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer counting/Spectral Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size=3):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "def get_data(kmer_size):\n",
    "    data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "    train_text = data.seq.values\n",
    "    # X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "    kmer_data = []\n",
    "    for i in train_text:\n",
    "        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))\n",
    "\n",
    "    return np.array(kmer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer / TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_grams(data,n=6):\n",
    "    cv = CountVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X\n",
    "\n",
    "def get_tf_idf_grams(data,n=6):\n",
    "    cv = TfidfVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_count_grams(X_train_.seq.values).shape\n",
    "# get_tf_idf_grams(X_train_.seq.values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=64,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))+(2*(self._lambda/len(self.train_labels ))*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(len(self.train_labels)//self.batch_size):\n",
    "                idx = list(np.random.choice(np.arange(len(self.train_labels)),self.batch_size,replace=False))\n",
    "                data = self.train_data[idx]\n",
    "                label = self.train_labels[idx]\n",
    "\n",
    "                y_pred = self.sigmoid(np.dot(data,self.params))\n",
    "                loss = self.cost(label,y_pred)\n",
    "\n",
    "                gra = self.gradient(label,y_pred,data)\n",
    "                self.params -= self.lr*gra\n",
    "\n",
    "                self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=4,batch_size=64,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_result = cross_validate(X_train_mat100,get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "ordinal_result = cross_validate(get_ordinal_data(X_train_.seq.values),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "kmer_result = cross_validate(get_data(6)[:2000,:],get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "count_result = cross_validate(get_count_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "tfidf_result = cross_validate(get_tf_idf_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_value = {'One Hot':one_hot_result,'Ordinal':ordinal_result,'K-mer':kmer_result,'Count-Vectorizer':count_result,'Tf-idf':tfidf_result}\n",
    "final_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The First Result Shows The Qualty of the data on non optimized logistic regression model this is not the best value this method can achive but it can show us the quality of the data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot === 0.483\n",
      "Ordinal === 0.49499999999999994\n",
      "K-mer === 0.607\n",
      "Count-Vectorizer === 0.624\n",
      "Tf-idf === 0.5189999999999999\n"
     ]
    }
   ],
   "source": [
    "for k,v in final_value.items():\n",
    "    print('{} === {}'.format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Related Experiments +  Kernel Related Experiments\n",
    "\n",
    "We alady implemennted Logistic regression now we will add \n",
    "\n",
    "- Ridge Regression\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2.T)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "            \n",
    "        \n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X,X,**self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,model_name,lr=None,kernel=None,lambd=0.2,C=3,sigma=0.5,k=5,power=2):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        if model_name == 'KernelRidgeRegression':\n",
    "            model = KernelRidgeRegression(\n",
    "                    kernel=kernel,\n",
    "                    lambd=lambd,\n",
    "                    sigma=sigma,\n",
    "                    power=power\n",
    "                ).fit(x_train, y_train)\n",
    "            result =sum(np.sign(model.predict(x_test))==y_test)/len(y_test)#roc_auc_score(np.sign(model.predict(x_test)),y_test) #\n",
    "            \n",
    "        elif model_name == 'KernelSVM':\n",
    "\n",
    "            model = KernelSVM(C=C,\n",
    "                              kernel=kernel,\n",
    "                              lambd=lambd,\n",
    "                              sigma=sigma,\n",
    "                              power=power)\n",
    "            model.fit(x_train, y_train.flatten())\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            result = sum((y_pred.flatten()==y_test.flatten()))/len(y_test)\n",
    "            \n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80113f07830e4749992fcd73d9c335d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-31 12:34:31,728]\u001b[0m Finished trial#0 with value: 0.0 with parameters: {'lr': 0.033360428599157214, 'lambd': 26.163928843357315, 'sigma': 87.55003249838137, 'k': 4, 'C': 5.316245176108491, 'power': 2, 'kmer_size': 8}. Best is trial#0 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:34:35,486]\u001b[0m Finished trial#1 with value: 0.0055 with parameters: {'lr': 0.024315458307228012, 'lambd': 89.27978032835702, 'sigma': 108.9201301899593, 'k': 8, 'C': 39.03062969413706, 'power': 3, 'kmer_size': 4}. Best is trial#1 with value: 0.0055.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:34:39,739]\u001b[0m Finished trial#2 with value: 0.0 with parameters: {'lr': 0.06763393207199944, 'lambd': 20.22057736258069, 'sigma': 1.2164310860757672, 'k': 8, 'C': 29.69252879872462, 'power': 4, 'kmer_size': 5}. Best is trial#1 with value: 0.0055.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning:\n",
      "\n",
      "overflow encountered in exp\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:151: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in reduce\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-31 12:34:42,955]\u001b[0m Finished trial#3 with value: 0.0 with parameters: {'lr': 0.08880240227042373, 'lambd': 84.96831035399558, 'sigma': 23.28450564948509, 'k': 8, 'C': 43.09298213552291, 'power': 3, 'kmer_size': 3}. Best is trial#1 with value: 0.0055.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:34:59,703]\u001b[0m Finished trial#4 with value: 0.003 with parameters: {'lr': 0.02725360995460915, 'lambd': 25.303400498424217, 'sigma': 11.566013968857419, 'k': 5, 'C': 33.025584731152065, 'power': 4, 'kmer_size': 7}. Best is trial#1 with value: 0.0055.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-890aa2bc739e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 334\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 )\n\u001b[1;32m    336\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-60-890aa2bc739e>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     model_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-d7056814b70d>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(x_data, y_data, model_name, lr, kernel, lambd, C, sigma, k, power)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-5f8e9632a61f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    lambd = trial.suggest_float('lambd', 1e-5, 100.0)\n",
    "    sigma = trial.suggest_float('sigma', 1e-5, 150)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8])\n",
    "    C =  trial.suggest_float('C', 0.1,50)\n",
    "    power =  trial.suggest_int('power', 2,5)\n",
    "    kmer_size =  trial.suggest_int('kmer_size', 3,8)\n",
    "#     kernel =  trial.suggest_categorical('kernel', ['linear','rbf','gaussian_kernel','polynomial'])\n",
    "#     model_name\n",
    "    \n",
    "    return cross_validate(get_data(kmer_size)[:2000,:],get_label(type=-1),model_name='logistic',C=C,kernel='linear',lambd=lambd,k=k,sigma=sigma,power=power)\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=100,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.sort_values(by=['value']).tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              value\t\tparams_C\tparams_k\tparams_kmer_size\tparams_lambd\tparams_power\tparams_sigma\n",
    "\n",
    "\n",
    "linear  -     0.6520\t   47.102628\t    4\t     7\t    0.756909\t    3\t       15.369069\n",
    "rbf           0.6470\t00:00:04.427092\t9.071834\t5\t7\t77.976361\t4\t3.775633\n",
    "polinomial    0.6585\t00:00:03.992723\t27.187947\t4\t7\t1.418356\t2\n",
    "\n",
    "\n",
    "svm\n",
    "\n",
    "linear        0.6525\t00:00:08.438371\t10.791498\t5\t8\t52.239587\t4\t74.078190\n",
    "rbf           0.6530\t00:00:05.553817\t14.611283\t4\t7\t32.915987\t2\t45.600422\n",
    "pol           0.6315\t00:00:03.624395\t18.056135\t4\t5\t53.476413\t3\t9.218339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 65536) (20, 65536) (1980, 1) (20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test  = get_train_test(get_data(8)[:2000,:],get_label(type=-1).reshape(-1,1),p=0.01)\n",
    "\n",
    "\n",
    "kernel = 'rbf'\n",
    "power = 3\n",
    "sigma = 12.217523\n",
    "C = 9.839876\n",
    "lambd = 38.202739\n",
    "model = KernelSVM(C=C, kernel=kernel, sigma=sigma,lambd=lambd, power=power)\n",
    "model.fit(X_train, y_train.flatten())\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "sum(y_pred.flatten()==y_test.flatten())/len(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(get_data(8)[:2000,:],get_label(type=-1),\n",
    "               model_name='KernelSVM',\n",
    "               kernel = 'rbf',\n",
    "               k=4,\n",
    "                power = 3,\n",
    "                sigma = 12.217523,\n",
    "                C = 9.839876,\n",
    "                lambd = 38.202739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def miss(s, t):\n",
    "    \"\"\" Count the number of mismatches between two strings.\"\"\"\n",
    "    return sum((si != sj for si, sj in zip(s, t)))\n",
    "\n",
    "def string_kernel_mismatch(s, t, k=10, delta=1, m=1):\n",
    "    \"\"\" String kernel with displacement and mismatches. \"\"\"\n",
    "    L = len(s)\n",
    "    return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n",
    "                for i, d in it.product(range(L - k + 1), range(-delta, delta + 1))\n",
    "                if i + d + k <= L and i + d >= 0))\n",
    "\n",
    "string_kernel_mismatch(s,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-a355b2ec373b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_kernel_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-191-8798ade79624>\u001b[0m in \u001b[0;36mstring_kernel_mismatch\u001b[0;34m(s, t, k, delta, m)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 if i + d + k <= L and i + d >= 0))\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-191-8798ade79624>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 if i + d + k <= L and i + d >= 0))\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstring_kernel_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = get_data(8)[:2000,:]\n",
    "\n",
    "result = np.zeros((len(data),len(data)))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data)):\n",
    "        result[i][j] = string_kernel_mismatch(data[i],data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "        1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Bound\n",
       "0    0      1\n",
       "1    1      1\n",
       "2    2      0\n",
       "3    3      0\n",
       "4    4      1\n",
       "5    5      1\n",
       "6    6      1\n",
       "7    7      0\n",
       "8    8      1\n",
       "9    9      1\n",
       "10  10      1\n",
       "11  11      1\n",
       "12  12      1\n",
       "13  13      1\n",
       "14  14      0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final  = model.predict(get_data(8)[2000:,:])\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = X_test_final[i]\n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_rbf-svm.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-145189adb853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msumbission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-80a06a324978>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-164-80a06a324978>\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mK_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_function_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mK_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e25f7751f78e>\u001b[0m in \u001b[0;36mrbf_kernel\u001b[0;34m(X1, X2, sigma)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mX1_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX1_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX2_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "X_test_final = get_data(8)[2000:,:]\n",
    "\n",
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = model.predict(X_test_final[i])\n",
    "    \n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_linear_overfitted.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

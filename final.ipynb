{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cvxopt -q\n",
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7cad0dd5c525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m _DEFAULT_TAGS = {\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m from .validation import (as_float_array,\n\u001b[1;32m     29\u001b[0m                          \u001b[0massert_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,\n\u001b[0m\u001b[1;32m     11\u001b[0m                                     rv_frozen)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# for root finding for discrete distribution ppf, and max likelihood estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_basinhopping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_linprog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinprog_verbose_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lsap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear_sum_assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_differentialevolution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdifferential_evolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lsq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsq_linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/_lsap.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_lsap_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import os\n",
    "import optuna\n",
    "import random\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import sklearn\n",
    "\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = pd.read_csv('data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Fuction will help us get the label \n",
    "\n",
    "- Label will be  0 or 1 if we use type=0\n",
    "- label will be -1 or 1 if we use type=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(type=0):\n",
    "    y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)\n",
    "    if type == 0:\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    else:\n",
    "        y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    \n",
    "get_label(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will return train-val split data using sklearns built in train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y,p):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE DATA \n",
    "\n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE DATA IS PROPORTIONAL DATA \n",
    "\n",
    "y['Bound'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIONALLY ALL DATA CONTAINS 101 LENGTH SEQUENCES SO THERE WILL BE NO NEED OF PADDING \n",
    "\n",
    "X_train_['Count'] = X_train_.seq.apply(lambda x:len(x))\n",
    "X_train_['Count'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',X_train_mat100[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal encoding DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['A','C','G','T']))\n",
    "\n",
    "def ordinal_encoder(sequence):\n",
    "    integer_encoded = label_encoder.transform(np.array(list(sequence)))\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25\n",
    "    float_encoded[float_encoded == 1] = 0.50\n",
    "    float_encoded[float_encoded == 2] = 0.75\n",
    "    float_encoded[float_encoded == 3] = 1.00 \n",
    "    return float_encoded\n",
    "\n",
    "def get_ordinal_data(x_train):\n",
    "    X_list = []\n",
    "    for i in x_train:\n",
    "        X_list.append(ordinal_encoder(i))\n",
    "    return np.array(X_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',get_ordinal_data(X_train_.seq.values)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer counting/Spectral Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size=3):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "def get_data(kmer_size):\n",
    "    data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "    train_text = data.seq.values\n",
    "    # X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "    kmer_data = []\n",
    "    for i in train_text:\n",
    "        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))\n",
    "\n",
    "    return np.array(kmer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer / TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_grams(data,n=6):\n",
    "    cv = CountVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X\n",
    "\n",
    "def get_tf_idf_grams(data,n=6):\n",
    "    cv = TfidfVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_count_grams(X_train_.seq.values).shape\n",
    "# get_tf_idf_grams(X_train_.seq.values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=64,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))+(2*(self._lambda/len(self.train_labels ))*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(len(self.train_labels)//self.batch_size):\n",
    "                idx = list(np.random.choice(np.arange(len(self.train_labels)),self.batch_size,replace=False))\n",
    "                data = self.train_data[idx]\n",
    "                label = self.train_labels[idx]\n",
    "\n",
    "                y_pred = self.sigmoid(np.dot(data,self.params))\n",
    "                loss = self.cost(label,y_pred)\n",
    "\n",
    "                gra = self.gradient(label,y_pred,data)\n",
    "                self.params -= self.lr*gra\n",
    "\n",
    "                self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=4,batch_size=64,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_result = cross_validate(X_train_mat100,get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "ordinal_result = cross_validate(get_ordinal_data(X_train_.seq.values),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "kmer_result = cross_validate(get_data(6)[:2000,:],get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "count_result = cross_validate(get_count_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "tfidf_result = cross_validate(get_tf_idf_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_value = {'One Hot':one_hot_result,'Ordinal':ordinal_result,'K-mer':kmer_result,'Count-Vectorizer':count_result,'Tf-idf':tfidf_result}\n",
    "final_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The First Result Shows The Qualty of the data on non optimized logistic regression model this is not the best value this method can achive but it can show us the quality of the data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot === 0.483\n",
      "Ordinal === 0.49499999999999994\n",
      "K-mer === 0.607\n",
      "Count-Vectorizer === 0.624\n",
      "Tf-idf === 0.5189999999999999\n"
     ]
    }
   ],
   "source": [
    "for k,v in final_value.items():\n",
    "    print('{} === {}'.format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Related Experiments +  Kernel Related Experiments\n",
    "\n",
    "We alady implemennted Logistic regression now we will add \n",
    "\n",
    "- Ridge Regression\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2.T)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "            \n",
    "        \n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X,X,**self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,model_name,kernel=None,lambd=0.2,C=3,sigma=0.5,k=5,power=2):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        if model_name == 'KernelRidgeRegression':\n",
    "            model = KernelRidgeRegression(\n",
    "                    kernel=kernel,\n",
    "                    lambd=lambd,\n",
    "                    sigma=sigma,\n",
    "                    power=power\n",
    "                ).fit(x_train, y_train)\n",
    "            result =sum(np.sign(model.predict(x_test))==y_test)/len(y_test)#roc_auc_score(np.sign(model.predict(x_test)),y_test) #\n",
    "        elif model_name == 'logistic':\n",
    "            logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "            logistic.train()\n",
    "\n",
    "            result = logistic.evaluate(x_test,y_test)\n",
    "            \n",
    "        elif model_name == 'KernelSVM':\n",
    "\n",
    "            model = KernelSVM(C=C,\n",
    "                              kernel=kernel,\n",
    "                              lambd=lambd,\n",
    "                              sigma=sigma,\n",
    "                              power=power)\n",
    "            model.fit(x_train, y_train.flatten())\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            result = sum((y_pred.flatten()==y_test.flatten()))/len(y_test)\n",
    "            \n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KernelMethodBase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2a49c50f9fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mKernelLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernelMethodBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     '''\n\u001b[1;32m      7\u001b[0m     \u001b[0mKernel\u001b[0m \u001b[0mLogistic\u001b[0m \u001b[0mRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KernelMethodBase' is not defined"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "class KernelLogisticRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Logistic Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelLogisticRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, max_iter=100, tol=1e-5):\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        K = self.kernel_function_(X, X, **self.kernel_parameters)\n",
    "        \n",
    "        # IRLS\n",
    "        WKRR = KernelRidgeRegression(\n",
    "            lambd=self.lambd,\n",
    "            kernel=self.kernel_name,\n",
    "            **self.kernel_parameters\n",
    "        )\n",
    "        # Initialize\n",
    "        alpha = np.zeros_like(self.y_train)\n",
    "        # Iterate until convergence or max iterations\n",
    "        for n_iter in range(max_iter):\n",
    "            alpha_old = alpha\n",
    "            f = K.dot(alpha_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(-y*f)\n",
    "            alpha = WKRR.fit(K, z, sample_weights=w).alpha\n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < tol:\n",
    "                break\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        return self\n",
    "            \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)    \n",
    "        return K_x\n",
    "\n",
    "    def predict(self, X):\n",
    "        decisions = self.decision_function(X)\n",
    "        return predicted_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = get_train_test(get_data(8)[:2000,:],get_label(type=-1).reshape(-1,1),p=0.01)\n",
    "\n",
    "\n",
    "kernel = 'polynomial'\n",
    "power = 2\n",
    "sigma = .4\n",
    "lambd = 1.\n",
    "fig_title = 'Logistic Regression, {} Kernel'.format(kernel)\n",
    "\n",
    "model = KernelLogisticRegression(lambd=lambd, kernel=kernel, sigma=sigma, power=power)\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170f13ba22be46a1bfd0b4906614d4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-30 23:59:42,237]\u001b[0m Finished trial#0 with value: 0.5595 with parameters: {'lambd': 95.11288717397517, 'sigma': 116.59873302740698, 'k': 8, 'C': 11.72257186167034, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#0 with value: 0.5595.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 23:59:45,314]\u001b[0m Finished trial#1 with value: 0.601 with parameters: {'lambd': 64.77025123998703, 'sigma': 87.46478012901063, 'k': 5, 'C': 25.137621818430343, 'power': 4, 'kmer_size': 5, 'kernel': 'linear'}. Best is trial#1 with value: 0.601.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 23:59:48,153]\u001b[0m Finished trial#2 with value: 0.5850000000000001 with parameters: {'lambd': 25.25349695918506, 'sigma': 72.76262525571832, 'k': 8, 'C': 28.122496660427228, 'power': 5, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#1 with value: 0.601.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 23:59:51,132]\u001b[0m Finished trial#3 with value: 0.5485 with parameters: {'lambd': 6.430495667962775, 'sigma': 79.89620107323005, 'k': 4, 'C': 27.700544706630446, 'power': 3, 'kmer_size': 3, 'kernel': 'linear'}. Best is trial#1 with value: 0.601.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 23:59:53,512]\u001b[0m Finished trial#4 with value: 0.553 with parameters: {'lambd': 31.25294819616798, 'sigma': 119.00833929347908, 'k': 8, 'C': 48.17246366767359, 'power': 5, 'kmer_size': 2, 'kernel': 'polynomial'}. Best is trial#1 with value: 0.601.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 23:59:57,150]\u001b[0m Finished trial#5 with value: 0.575 with parameters: {'lambd': 77.7033239803307, 'sigma': 102.61416818683412, 'k': 4, 'C': 2.212224623653226, 'power': 5, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#1 with value: 0.601.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 23:59:59,840]\u001b[0m Finished trial#6 with value: 0.559 with parameters: {'lambd': 53.81311796570429, 'sigma': 4.69246756652197, 'k': 8, 'C': 11.08907835249249, 'power': 3, 'kmer_size': 3, 'kernel': 'polynomial'}. Best is trial#1 with value: 0.601.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:00:03,009]\u001b[0m Finished trial#7 with value: 0.5974999999999999 with parameters: {'lambd': 3.8460564225960283, 'sigma': 40.22107196183666, 'k': 5, 'C': 7.540653264418722, 'power': 5, 'kmer_size': 5, 'kernel': 'linear'}. Best is trial#1 with value: 0.601.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:00:06,702]\u001b[0m Finished trial#8 with value: 0.6279999999999999 with parameters: {'lambd': 12.77961204942528, 'sigma': 107.43996475830163, 'k': 5, 'C': 24.587249427062925, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#8 with value: 0.6279999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:00:09,443]\u001b[0m Finished trial#9 with value: 0.5740000000000001 with parameters: {'lambd': 40.485611244215335, 'sigma': 6.387282720508323, 'k': 5, 'C': 0.6419215339575571, 'power': 5, 'kmer_size': 2, 'kernel': 'polynomial'}. Best is trial#8 with value: 0.6279999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:00:20,160]\u001b[0m Finished trial#10 with value: 0.6375000000000001 with parameters: {'lambd': 15.494896856676824, 'sigma': 145.85095679640938, 'k': 5, 'C': 40.25657366623195, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#10 with value: 0.6375000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:00:30,867]\u001b[0m Finished trial#11 with value: 0.6375000000000001 with parameters: {'lambd': 16.143354484557253, 'sigma': 146.3886579037469, 'k': 5, 'C': 42.25768163023041, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#10 with value: 0.6375000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:00:41,464]\u001b[0m Finished trial#12 with value: 0.6345000000000001 with parameters: {'lambd': 22.800739621560407, 'sigma': 147.81684041360305, 'k': 5, 'C': 49.1811785052334, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#10 with value: 0.6375000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:00:52,191]\u001b[0m Finished trial#13 with value: 0.6369999999999999 with parameters: {'lambd': 16.396105383901265, 'sigma': 149.10692107394925, 'k': 5, 'C': 40.34817079485944, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#10 with value: 0.6375000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:00:57,313]\u001b[0m Finished trial#14 with value: 0.6425 with parameters: {'lambd': 0.25756527531272866, 'sigma': 136.52032156184055, 'k': 5, 'C': 39.28886657082443, 'power': 2, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#14 with value: 0.6425.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:02,516]\u001b[0m Finished trial#15 with value: 0.642 with parameters: {'lambd': 1.6684694637255806, 'sigma': 133.40095358186082, 'k': 5, 'C': 34.799228977749415, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#14 with value: 0.6425.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:07,883]\u001b[0m Finished trial#16 with value: 0.6465 with parameters: {'lambd': 2.018807437872211, 'sigma': 130.08718960487195, 'k': 4, 'C': 33.14818842914819, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#16 with value: 0.6465.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:13,286]\u001b[0m Finished trial#17 with value: 0.6475 with parameters: {'lambd': 40.27575045270819, 'sigma': 129.97326224087885, 'k': 4, 'C': 33.795663943245124, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#17 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:18,775]\u001b[0m Finished trial#18 with value: 0.6435000000000001 with parameters: {'lambd': 45.68345474370311, 'sigma': 48.8722517694046, 'k': 4, 'C': 21.585527252569612, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#17 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:22,571]\u001b[0m Finished trial#19 with value: 0.625 with parameters: {'lambd': 76.58746134533223, 'sigma': 121.92428853474937, 'k': 4, 'C': 33.982155689730874, 'power': 3, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#17 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:28,046]\u001b[0m Finished trial#20 with value: 0.6475 with parameters: {'lambd': 35.40684164273945, 'sigma': 99.2521500411633, 'k': 4, 'C': 19.725421614097197, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#17 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:33,573]\u001b[0m Finished trial#21 with value: 0.649 with parameters: {'lambd': 35.871756612823106, 'sigma': 88.52811153047867, 'k': 4, 'C': 17.91038543140948, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#21 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:37,332]\u001b[0m Finished trial#22 with value: 0.6255 with parameters: {'lambd': 36.578455832343145, 'sigma': 94.58992018075122, 'k': 4, 'C': 20.2021991627379, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#21 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:42,795]\u001b[0m Finished trial#23 with value: 0.6465 with parameters: {'lambd': 55.33183306648984, 'sigma': 65.79366549147593, 'k': 4, 'C': 17.81037651798072, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#21 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:46,629]\u001b[0m Finished trial#24 with value: 0.627 with parameters: {'lambd': 33.46586911655021, 'sigma': 59.692515701932734, 'k': 4, 'C': 13.501440322468081, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#21 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:52,134]\u001b[0m Finished trial#25 with value: 0.642 with parameters: {'lambd': 46.80426060255657, 'sigma': 100.69761807106408, 'k': 4, 'C': 16.915127958104794, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#21 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:01:55,298]\u001b[0m Finished trial#26 with value: 0.5820000000000001 with parameters: {'lambd': 62.07458195869942, 'sigma': 87.66437514829632, 'k': 4, 'C': 6.701122155682125, 'power': 4, 'kmer_size': 4, 'kernel': 'linear'}. Best is trial#21 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:02:06,601]\u001b[0m Finished trial#27 with value: 0.6485 with parameters: {'lambd': 24.868745693631375, 'sigma': 112.08355322114383, 'k': 4, 'C': 28.744635390916937, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#21 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:02:17,744]\u001b[0m Finished trial#28 with value: 0.648 with parameters: {'lambd': 27.252579745639395, 'sigma': 81.63577918771963, 'k': 4, 'C': 16.017191762626197, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#21 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:02:28,970]\u001b[0m Finished trial#29 with value: 0.6535 with parameters: {'lambd': 27.601723536841774, 'sigma': 34.19274875501407, 'k': 4, 'C': 14.739300746138074, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#29 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:02:40,129]\u001b[0m Finished trial#30 with value: 0.654 with parameters: {'lambd': 20.51670155481705, 'sigma': 25.279097722700705, 'k': 4, 'C': 13.015745910591267, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#30 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:02:51,307]\u001b[0m Finished trial#31 with value: 0.654 with parameters: {'lambd': 22.940249162388014, 'sigma': 30.541677176812787, 'k': 4, 'C': 11.926304019547098, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#30 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:03:02,506]\u001b[0m Finished trial#32 with value: 0.6525000000000001 with parameters: {'lambd': 19.440853222819026, 'sigma': 24.046141277778432, 'k': 4, 'C': 11.544468428416073, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#30 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:03:13,622]\u001b[0m Finished trial#33 with value: 0.654 with parameters: {'lambd': 9.641066348076041, 'sigma': 21.2274299348521, 'k': 4, 'C': 8.776149030046525, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#30 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:03:24,770]\u001b[0m Finished trial#34 with value: 0.654 with parameters: {'lambd': 10.028217731892575, 'sigma': 24.487635286256502, 'k': 4, 'C': 6.367218060878826, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#30 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:03:34,156]\u001b[0m Finished trial#35 with value: 0.6305000000000001 with parameters: {'lambd': 11.411747405142679, 'sigma': 21.892552454405195, 'k': 8, 'C': 7.326864960830882, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#30 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:03:45,334]\u001b[0m Finished trial#36 with value: 0.655 with parameters: {'lambd': 8.466982064583402, 'sigma': 14.50923249702821, 'k': 4, 'C': 3.681839747628151, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:03:56,440]\u001b[0m Finished trial#37 with value: 0.655 with parameters: {'lambd': 9.187726623854292, 'sigma': 12.54807128075265, 'k': 4, 'C': 3.403366926370948, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:04:06,390]\u001b[0m Finished trial#38 with value: 0.634 with parameters: {'lambd': 6.934544748494008, 'sigma': 16.919930838820036, 'k': 8, 'C': 4.227263267580305, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:04:09,511]\u001b[0m Finished trial#39 with value: 0.495 with parameters: {'lambd': 8.558260528969864, 'sigma': 0.3804980446955035, 'k': 4, 'C': 2.6993961099274077, 'power': 2, 'kmer_size': 4, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:04:13,339]\u001b[0m Finished trial#40 with value: 0.6225 with parameters: {'lambd': 6.170089668885762, 'sigma': 11.31585877303366, 'k': 4, 'C': 4.5608250704047295, 'power': 3, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:04:24,657]\u001b[0m Finished trial#41 with value: 0.643 with parameters: {'lambd': 99.19674550796557, 'sigma': 43.34598034480354, 'k': 4, 'C': 9.19262264013441, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:04:35,862]\u001b[0m Finished trial#42 with value: 0.644 with parameters: {'lambd': 12.344642019340382, 'sigma': 32.38335362742504, 'k': 4, 'C': 1.3036811632129148, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:04:41,366]\u001b[0m Finished trial#43 with value: 0.6445000000000001 with parameters: {'lambd': 9.489037387557833, 'sigma': 11.750568553854105, 'k': 4, 'C': 9.761414072069979, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:04:52,441]\u001b[0m Finished trial#44 with value: 0.495 with parameters: {'lambd': 0.8016631922851207, 'sigma': 2.3564493133817717, 'k': 4, 'C': 0.23939257082028753, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:05:03,791]\u001b[0m Finished trial#45 with value: 0.6535 with parameters: {'lambd': 20.335627116133274, 'sigma': 31.226534615316282, 'k': 4, 'C': 12.679993312058926, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:05:08,522]\u001b[0m Finished trial#46 with value: 0.5710000000000001 with parameters: {'lambd': 18.727773611320984, 'sigma': 52.51009603487452, 'k': 8, 'C': 4.214869148857863, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:05:19,630]\u001b[0m Finished trial#47 with value: 0.6545 with parameters: {'lambd': 14.782901116220497, 'sigma': 15.907198088359038, 'k': 4, 'C': 6.175915279737451, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#36 with value: 0.655.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:05:30,755]\u001b[0m Finished trial#48 with value: 0.6565000000000001 with parameters: {'lambd': 5.004179759848529, 'sigma': 14.971456399314972, 'k': 4, 'C': 5.552340059312717, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:05:36,304]\u001b[0m Finished trial#49 with value: 0.641 with parameters: {'lambd': 5.052221359897065, 'sigma': 14.75388243788204, 'k': 4, 'C': 8.966022846300765, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:05:39,638]\u001b[0m Finished trial#50 with value: 0.5845 with parameters: {'lambd': 14.305663438503444, 'sigma': 7.555637876353089, 'k': 4, 'C': 0.28480253089192464, 'power': 3, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:05:50,791]\u001b[0m Finished trial#51 with value: 0.643 with parameters: {'lambd': 14.587301613140035, 'sigma': 38.58481424364021, 'k': 4, 'C': 6.3759939023277505, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:06:01,966]\u001b[0m Finished trial#52 with value: 0.645 with parameters: {'lambd': 0.7360588539639998, 'sigma': 19.766321402033327, 'k': 4, 'C': 3.374788568409843, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:06:13,097]\u001b[0m Finished trial#53 with value: 0.647 with parameters: {'lambd': 28.473584254445186, 'sigma': 28.87139696876084, 'k': 4, 'C': 6.056929835736298, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:06:24,051]\u001b[0m Finished trial#54 with value: 0.6515 with parameters: {'lambd': 4.280003378056197, 'sigma': 5.982203879168029, 'k': 4, 'C': 2.0367623171009783, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:06:29,434]\u001b[0m Finished trial#55 with value: 0.495 with parameters: {'lambd': 9.959673443561105, 'sigma': 0.6508504236581985, 'k': 4, 'C': 9.125641266716817, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:06:34,786]\u001b[0m Finished trial#56 with value: 0.639 with parameters: {'lambd': 0.09401425480406722, 'sigma': 17.389946974615295, 'k': 4, 'C': 5.402002909029778, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#48 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:06:45,945]\u001b[0m Finished trial#57 with value: 0.657 with parameters: {'lambd': 22.971959053201832, 'sigma': 11.744458612409442, 'k': 4, 'C': 11.00927638952582, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:06:55,213]\u001b[0m Finished trial#58 with value: 0.6355 with parameters: {'lambd': 16.18792203155998, 'sigma': 10.571000191395434, 'k': 8, 'C': 2.345914598192544, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:06:57,954]\u001b[0m Finished trial#59 with value: 0.556 with parameters: {'lambd': 4.533749449879388, 'sigma': 14.073746913486557, 'k': 4, 'C': 7.64917409082444, 'power': 3, 'kmer_size': 2, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:07:03,279]\u001b[0m Finished trial#60 with value: 0.64 with parameters: {'lambd': 18.576041044109118, 'sigma': 27.168036169948905, 'k': 4, 'C': 11.040857470594231, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:07:14,438]\u001b[0m Finished trial#61 with value: 0.654 with parameters: {'lambd': 22.12270684236204, 'sigma': 19.47038432706045, 'k': 4, 'C': 10.581882498732929, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:07:25,596]\u001b[0m Finished trial#62 with value: 0.6545000000000001 with parameters: {'lambd': 30.476132689079893, 'sigma': 36.51757274058687, 'k': 4, 'C': 14.187450242206024, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:07:36,683]\u001b[0m Finished trial#63 with value: 0.64 with parameters: {'lambd': 12.301414116490605, 'sigma': 37.855298266842084, 'k': 4, 'C': 5.264607853383924, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:07:47,766]\u001b[0m Finished trial#64 with value: 0.6495 with parameters: {'lambd': 32.056226494018155, 'sigma': 43.65083095645386, 'k': 4, 'C': 14.325644156103335, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:07:52,962]\u001b[0m Finished trial#65 with value: 0.644 with parameters: {'lambd': 22.814741933450193, 'sigma': 6.824235751361556, 'k': 5, 'C': 25.860036416829942, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:08:04,177]\u001b[0m Finished trial#66 with value: 0.654 with parameters: {'lambd': 40.97959375562973, 'sigma': 19.12229522351653, 'k': 4, 'C': 10.98316051010514, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:08:15,257]\u001b[0m Finished trial#67 with value: 0.499 with parameters: {'lambd': 29.40948660819639, 'sigma': 3.040436580437561, 'k': 4, 'C': 7.242644100838935, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:08:20,676]\u001b[0m Finished trial#68 with value: 0.643 with parameters: {'lambd': 16.666088202874633, 'sigma': 11.587216633992528, 'k': 4, 'C': 15.463260815038481, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:08:31,875]\u001b[0m Finished trial#69 with value: 0.649 with parameters: {'lambd': 8.193322772690141, 'sigma': 35.179957293714416, 'k': 4, 'C': 3.2901028570880744, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:08:42,988]\u001b[0m Finished trial#70 with value: 0.6505 with parameters: {'lambd': 23.844779014296783, 'sigma': 26.78479489923236, 'k': 4, 'C': 22.913882209439628, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:08:54,108]\u001b[0m Finished trial#71 with value: 0.653 with parameters: {'lambd': 39.39330975722608, 'sigma': 23.77278754941082, 'k': 4, 'C': 8.35515899474511, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:09:05,083]\u001b[0m Finished trial#72 with value: 0.6545 with parameters: {'lambd': 52.532710091744974, 'sigma': 17.069539497972308, 'k': 4, 'C': 5.537768793145865, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:09:16,240]\u001b[0m Finished trial#73 with value: 0.652 with parameters: {'lambd': 52.033434898605314, 'sigma': 7.940939629441325, 'k': 4, 'C': 10.348198153018878, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:09:27,371]\u001b[0m Finished trial#74 with value: 0.6435 with parameters: {'lambd': 60.808900414835534, 'sigma': 51.79803402853189, 'k': 4, 'C': 12.989127500918388, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:09:32,671]\u001b[0m Finished trial#75 with value: 0.641 with parameters: {'lambd': 56.48715552430653, 'sigma': 16.483497160022424, 'k': 4, 'C': 1.21088705129787, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:09:43,633]\u001b[0m Finished trial#76 with value: 0.6555000000000001 with parameters: {'lambd': 44.9863460554199, 'sigma': 15.165407733464347, 'k': 4, 'C': 4.975749488613342, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:09:54,221]\u001b[0m Finished trial#77 with value: 0.651 with parameters: {'lambd': 72.20098274443427, 'sigma': 14.375865734671333, 'k': 5, 'C': 3.9817610828309062, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:09:59,494]\u001b[0m Finished trial#78 with value: 0.5125 with parameters: {'lambd': 46.50526737261964, 'sigma': 3.6206825632440633, 'k': 4, 'C': 5.988372837553134, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:10:10,404]\u001b[0m Finished trial#79 with value: 0.495 with parameters: {'lambd': 49.24356331331711, 'sigma': 0.15210395212863226, 'k': 4, 'C': 7.794266066571375, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:10:21,446]\u001b[0m Finished trial#80 with value: 0.654 with parameters: {'lambd': 69.6673561328776, 'sigma': 10.153218743930168, 'k': 4, 'C': 4.736713817678893, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:10:32,464]\u001b[0m Finished trial#81 with value: 0.6555000000000001 with parameters: {'lambd': 69.51140990357165, 'sigma': 9.901738269524696, 'k': 4, 'C': 4.8828862817860035, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:10:43,591]\u001b[0m Finished trial#82 with value: 0.587 with parameters: {'lambd': 57.76851491594817, 'sigma': 13.997665506310119, 'k': 4, 'C': 0.19030952651325972, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:10:54,782]\u001b[0m Finished trial#83 with value: 0.6255 with parameters: {'lambd': 68.62716311655086, 'sigma': 21.45044513048068, 'k': 4, 'C': 1.5503870007564413, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:11:05,702]\u001b[0m Finished trial#84 with value: 0.6545 with parameters: {'lambd': 80.90325357621747, 'sigma': 4.846486164656991, 'k': 4, 'C': 2.7919051929077785, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:11:16,712]\u001b[0m Finished trial#85 with value: 0.656 with parameters: {'lambd': 83.9098165600603, 'sigma': 5.72054241866233, 'k': 4, 'C': 3.1992064434222267, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:11:19,711]\u001b[0m Finished trial#86 with value: 0.5725 with parameters: {'lambd': 87.70122150230182, 'sigma': 9.957978127668722, 'k': 4, 'C': 3.4610510528482106, 'power': 3, 'kmer_size': 3, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:11:29,389]\u001b[0m Finished trial#87 with value: 0.612 with parameters: {'lambd': 42.78559375608009, 'sigma': 7.218200858449045, 'k': 8, 'C': 7.2594594194342665, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:11:34,717]\u001b[0m Finished trial#88 with value: 0.634 with parameters: {'lambd': 87.9541718106008, 'sigma': 23.450377418858, 'k': 4, 'C': 4.775507593280022, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:11:45,825]\u001b[0m Finished trial#89 with value: 0.649 with parameters: {'lambd': 80.50158507953502, 'sigma': 29.36506780603812, 'k': 4, 'C': 46.71424988113483, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:11:57,212]\u001b[0m Finished trial#90 with value: 0.495 with parameters: {'lambd': 87.19559491646592, 'sigma': 73.7098746701776, 'k': 4, 'C': 0.2843037163934836, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:12:08,083]\u001b[0m Finished trial#91 with value: 0.5115000000000001 with parameters: {'lambd': 93.8825334461871, 'sigma': 3.692725892737994, 'k': 4, 'C': 2.462282700162315, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:12:19,155]\u001b[0m Finished trial#92 with value: 0.6555000000000001 with parameters: {'lambd': 37.24968591302028, 'sigma': 15.237986132584862, 'k': 4, 'C': 6.085990890263073, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:12:30,170]\u001b[0m Finished trial#93 with value: 0.655 with parameters: {'lambd': 35.10240677319839, 'sigma': 18.175906850898873, 'k': 4, 'C': 5.423158926099387, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:12:41,178]\u001b[0m Finished trial#94 with value: 0.656 with parameters: {'lambd': 34.355044247710765, 'sigma': 11.482918162780079, 'k': 4, 'C': 8.168325161636462, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:12:52,220]\u001b[0m Finished trial#95 with value: 0.656 with parameters: {'lambd': 37.10889195650696, 'sigma': 12.23530714262301, 'k': 4, 'C': 8.429183232807341, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:13:03,283]\u001b[0m Finished trial#96 with value: 0.6535000000000001 with parameters: {'lambd': 37.63206810156321, 'sigma': 8.915910466028526, 'k': 4, 'C': 7.891950708520743, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:13:14,377]\u001b[0m Finished trial#97 with value: 0.656 with parameters: {'lambd': 34.1603475425338, 'sigma': 13.623882441872317, 'k': 4, 'C': 9.093810666475695, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:13:19,840]\u001b[0m Finished trial#98 with value: 0.495 with parameters: {'lambd': 33.695771623850455, 'sigma': 0.35323809812024365, 'k': 4, 'C': 9.77043415634238, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:13:31,068]\u001b[0m Finished trial#99 with value: 0.654 with parameters: {'lambd': 44.733692574106286, 'sigma': 19.069306428921365, 'k': 4, 'C': 8.625235178471474, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:13:42,021]\u001b[0m Finished trial#100 with value: 0.6555 with parameters: {'lambd': 34.69125479024491, 'sigma': 5.626505116756056, 'k': 4, 'C': 11.98605766382673, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:13:52,954]\u001b[0m Finished trial#101 with value: 0.656 with parameters: {'lambd': 36.369156941579256, 'sigma': 11.983516090470413, 'k': 4, 'C': 6.3618422760447455, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 00:14:03,999]\u001b[0m Finished trial#102 with value: 0.657 with parameters: {'lambd': 37.728327567986106, 'sigma': 12.808099507106073, 'k': 4, 'C': 9.83987564473659, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#57 with value: 0.657.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-49f24c4b7705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 334\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 )\n\u001b[1;32m    336\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-196-49f24c4b7705>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     model_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'KernelSVM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-163-ba1971ee83c4>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(x_data, y_data, model_name, kernel, lambd, C, sigma, k, power)\u001b[0m\n\u001b[1;32m     43\u001b[0m                               \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                               power=power)\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-80a06a324978>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, tol)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Kernel matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         K = self.kernel_function_(\n\u001b[0;32m---> 47\u001b[0;31m             self.X_train, self.X_train, **self.kernel_parameters)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Solve dual problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e25f7751f78e>\u001b[0m in \u001b[0;36mrbf_kernel\u001b[0;34m(X1, X2, sigma)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mX2_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mX1_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX1_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX2_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    lambd = trial.suggest_float('lambd', 1e-5, 100.0)\n",
    "    sigma = trial.suggest_float('sigma', 1e-5, 150)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8])\n",
    "    C =  trial.suggest_float('C', 0.1,50)\n",
    "    power =  trial.suggest_int('power', 2,5)\n",
    "    kmer_size =  trial.suggest_int('kmer_size', 2,8)\n",
    "    kernel =  trial.suggest_categorical('kernel', ['linear','polynomial'])\n",
    "#     model_name\n",
    "    \n",
    "    return cross_validate(get_data(kmer_size)[:2000,:],get_label(type=-1),model_name='KernelSVM',C=C,kernel='rbf',lambd=lambd,k=k,sigma=sigma,power=power)\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=500,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_C</th>\n",
       "      <th>params_k</th>\n",
       "      <th>params_kernel</th>\n",
       "      <th>params_kmer_size</th>\n",
       "      <th>params_lambd</th>\n",
       "      <th>params_power</th>\n",
       "      <th>params_sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>00:00:11.004795</td>\n",
       "      <td>3.199206</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>8</td>\n",
       "      <td>83.909817</td>\n",
       "      <td>3</td>\n",
       "      <td>5.720542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>00:00:11.004034</td>\n",
       "      <td>8.168325</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>8</td>\n",
       "      <td>34.355044</td>\n",
       "      <td>3</td>\n",
       "      <td>11.482918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>00:00:11.036553</td>\n",
       "      <td>8.429183</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>8</td>\n",
       "      <td>37.108892</td>\n",
       "      <td>3</td>\n",
       "      <td>12.235307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>00:00:11.120104</td>\n",
       "      <td>5.552340</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>8</td>\n",
       "      <td>5.004180</td>\n",
       "      <td>3</td>\n",
       "      <td>14.971456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>00:00:11.153805</td>\n",
       "      <td>11.009276</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>8</td>\n",
       "      <td>22.971959</td>\n",
       "      <td>3</td>\n",
       "      <td>11.744459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>00:00:11.040938</td>\n",
       "      <td>9.839876</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>8</td>\n",
       "      <td>37.728328</td>\n",
       "      <td>3</td>\n",
       "      <td>12.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>9.841442</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>8</td>\n",
       "      <td>38.202739</td>\n",
       "      <td>3</td>\n",
       "      <td>12.217523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number   value        duration  ...  params_lambd  params_power params_sigma\n",
       "85       85  0.6560 00:00:11.004795  ...     83.909817             3     5.720542\n",
       "94       94  0.6560 00:00:11.004034  ...     34.355044             3    11.482918\n",
       "95       95  0.6560 00:00:11.036553  ...     37.108892             3    12.235307\n",
       "48       48  0.6565 00:00:11.120104  ...      5.004180             3    14.971456\n",
       "57       57  0.6570 00:00:11.153805  ...     22.971959             3    11.744459\n",
       "102     102  0.6570 00:00:11.040938  ...     37.728328             3    12.808100\n",
       "103     103     NaN             NaT  ...     38.202739             3    12.217523\n",
       "\n",
       "[7 rows x 10 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.sort_values(by=['value']).tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 65536) (20, 65536) (1980, 1) (20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test  = get_train_test(get_data(8)[:2000,:],get_label(type=-1).reshape(-1,1),p=0.01)\n",
    "\n",
    "\n",
    "kernel = 'rbf'\n",
    "power = 3\n",
    "sigma = 12.217523\n",
    "C = 9.839876\n",
    "lambd = 38.202739\n",
    "model = KernelSVM(C=C, kernel=kernel, sigma=sigma,lambd=lambd, power=power)\n",
    "model.fit(X_train, y_train.flatten())\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "sum(y_pred.flatten()==y_test.flatten())/len(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(get_data(8)[:2000,:],get_label(type=-1),\n",
    "               model_name='KernelSVM',\n",
    "               kernel = 'rbf',\n",
    "               k=4,\n",
    "                power = 3,\n",
    "                sigma = 12.217523,\n",
    "                C = 9.839876,\n",
    "                lambd = 38.202739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def miss(s, t):\n",
    "    \"\"\" Count the number of mismatches between two strings.\"\"\"\n",
    "    return sum((si != sj for si, sj in zip(s, t)))\n",
    "\n",
    "def string_kernel_mismatch(s, t, k=10, delta=1, m=1):\n",
    "    \"\"\" String kernel with displacement and mismatches. \"\"\"\n",
    "    L = len(s)\n",
    "    return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n",
    "                for i, d in it.product(range(L - k + 1), range(-delta, delta + 1))\n",
    "                if i + d + k <= L and i + d >= 0))\n",
    "\n",
    "string_kernel_mismatch(s,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-a355b2ec373b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_kernel_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-191-8798ade79624>\u001b[0m in \u001b[0;36mstring_kernel_mismatch\u001b[0;34m(s, t, k, delta, m)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 if i + d + k <= L and i + d >= 0))\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-191-8798ade79624>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 if i + d + k <= L and i + d >= 0))\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstring_kernel_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = get_data(8)[:2000,:]\n",
    "\n",
    "result = np.zeros((len(data),len(data)))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data)):\n",
    "        result[i][j] = string_kernel_mismatch(data[i],data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "        1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Bound\n",
       "0    0      1\n",
       "1    1      1\n",
       "2    2      0\n",
       "3    3      0\n",
       "4    4      1\n",
       "5    5      1\n",
       "6    6      1\n",
       "7    7      0\n",
       "8    8      1\n",
       "9    9      1\n",
       "10  10      1\n",
       "11  11      1\n",
       "12  12      1\n",
       "13  13      1\n",
       "14  14      0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final  = model.predict(get_data(8)[2000:,:])\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = X_test_final[i]\n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_rbf-svm.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-145189adb853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msumbission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-80a06a324978>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-164-80a06a324978>\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mK_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_function_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mK_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e25f7751f78e>\u001b[0m in \u001b[0;36mrbf_kernel\u001b[0;34m(X1, X2, sigma)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mX1_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX1_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX2_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "X_test_final = get_data(8)[2000:,:]\n",
    "\n",
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = model.predict(X_test_final[i])\n",
    "    \n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_linear_overfitted.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cvxopt -q\n",
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import os\n",
    "import optuna\n",
    "import random\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import sklearn\n",
    "\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = pd.read_csv('data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Fuction will help us get the label \n",
    "\n",
    "- Label will be  0 or 1 if we use type=0\n",
    "- label will be -1 or 1 if we use type=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(type=0):\n",
    "    y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)\n",
    "    if type == 0:\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    else:\n",
    "        y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    \n",
    "get_label(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will return train-val split data using sklearns built in train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y,p):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  seq\n",
       "Id                                                   \n",
       "0   GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THE DATA \n",
    "\n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-dcdd8c5cc6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# THE DATA IS PROPORTIONAL DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bound'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# THE DATA IS PROPORTIONAL DATA \n",
    "\n",
    "y['Bound'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1b6bd8d4e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ADDITIONALLY ALL DATA CONTAINS 101 LENGTH SEQUENCES SO THERE WILL BE NO NEED OF PADDING \n",
    "\n",
    "X_train_['Count'] = X_train_.seq.apply(lambda x:len(x))\n",
    "X_train_['Count'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.01086957 0.01086957 0.01086957 0.0326087  0.01086957 0.0326087\n",
      " 0.01086957 0.         0.         0.01086957 0.0326087  0.\n",
      " 0.         0.01086957 0.02173913 0.01086957 0.01086957 0.01086957\n",
      " 0.         0.0326087  0.02173913 0.         0.         0.01086957\n",
      " 0.01086957 0.01086957 0.         0.02173913 0.         0.01086957\n",
      " 0.01086957 0.04347826 0.         0.01086957 0.01086957 0.01086957\n",
      " 0.         0.01086957 0.04347826 0.01086957 0.02173913 0.02173913\n",
      " 0.         0.         0.01086957 0.02173913 0.02173913 0.\n",
      " 0.         0.         0.         0.01086957 0.         0.0326087\n",
      " 0.01086957 0.         0.01086957 0.         0.01086957 0.02173913\n",
      " 0.         0.01086957 0.01086957 0.02173913 0.01086957 0.\n",
      " 0.01086957 0.01086957 0.01086957 0.         0.         0.\n",
      " 0.         0.         0.01086957 0.01086957 0.         0.02173913\n",
      " 0.01086957 0.         0.         0.         0.         0.\n",
      " 0.04347826 0.01086957 0.01086957 0.01086957 0.01086957 0.02173913\n",
      " 0.02173913 0.         0.         0.         0.01086957 0.\n",
      " 0.         0.02173913 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',X_train_mat100[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal encoding DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['A','C','G','T']))\n",
    "\n",
    "def ordinal_encoder(sequence):\n",
    "    integer_encoded = label_encoder.transform(np.array(list(sequence)))\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25\n",
    "    float_encoded[float_encoded == 1] = 0.50\n",
    "    float_encoded[float_encoded == 2] = 0.75\n",
    "    float_encoded[float_encoded == 3] = 1.00 \n",
    "    return float_encoded\n",
    "\n",
    "def get_ordinal_data(x_train):\n",
    "    X_list = []\n",
    "    for i in x_train:\n",
    "        X_list.append(ordinal_encoder(i))\n",
    "    return np.array(X_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.75 0.25 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.75 0.75 0.25 0.75\n",
      " 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.5  0.5  0.5  0.25 0.75 0.25\n",
      " 0.75 0.75 0.5  0.25 0.5  0.5  0.25 0.75 0.25 0.5  1.   0.5  1.   0.75\n",
      " 0.5  0.25 0.75 0.25 0.25 0.5  0.5  0.25 0.5  0.5  0.5  0.25 0.75 0.75\n",
      " 0.5  0.25 1.   1.   0.75 1.   0.75 0.75 0.75 0.75 0.5  1.   0.75 0.5\n",
      " 0.5  0.5  1.   0.75 0.5  0.5  0.25 0.5  0.5  1.   0.75 0.5  1.   0.75\n",
      " 0.75 0.5  0.5  0.75 0.5  1.   0.5  0.5  1.   0.75 0.75 1.   0.75 0.75\n",
      " 0.5  0.25 0.75]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',get_ordinal_data(X_train_.seq.values)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer counting/Spectral Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size=3):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "def get_data(kmer_size):\n",
    "    data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "    train_text = data.seq.values\n",
    "    # X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "    kmer_data = []\n",
    "    for i in train_text:\n",
    "        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))\n",
    "\n",
    "    return np.array(kmer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer / TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_grams(data,n=6):\n",
    "    cv = CountVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X\n",
    "\n",
    "def get_tf_idf_grams(data,n=6):\n",
    "    cv = TfidfVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_count_grams(X_train_.seq.values).shape\n",
    "# get_tf_idf_grams(X_train_.seq.values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=64,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))+(2*(self._lambda/len(self.train_labels ))*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(len(self.train_labels)//self.batch_size):\n",
    "                idx = list(np.random.choice(np.arange(len(self.train_labels)),self.batch_size,replace=False))\n",
    "                data = self.train_data[idx]\n",
    "                label = self.train_labels[idx]\n",
    "\n",
    "                y_pred = self.sigmoid(np.dot(data,self.params))\n",
    "                loss = self.cost(label,y_pred)\n",
    "\n",
    "                gra = self.gradient(label,y_pred,data)\n",
    "                self.params -= self.lr*gra\n",
    "\n",
    "                self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=4,batch_size=64,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_result = cross_validate(X_train_mat100,get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "ordinal_result = cross_validate(get_ordinal_data(X_train_.seq.values),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "kmer_result = cross_validate(get_data(6)[:2000,:],get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "count_result = cross_validate(get_count_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "tfidf_result = cross_validate(get_tf_idf_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Count-Vectorizer': 0.624,\n",
       " 'K-mer': 0.607,\n",
       " 'One Hot': 0.483,\n",
       " 'Ordinal': 0.49499999999999994,\n",
       " 'Tf-idf': 0.5189999999999999}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_value = {'One Hot':one_hot_result,'Ordinal':ordinal_result,'K-mer':kmer_result,'Count-Vectorizer':count_result,'Tf-idf':tfidf_result}\n",
    "final_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The First Result Shows The Qualty of the data on non optimized logistic regression model this is not the best value this method can achive but it can show us the quality of the data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot === 0.483\n",
      "Ordinal === 0.49499999999999994\n",
      "K-mer === 0.607\n",
      "Count-Vectorizer === 0.624\n",
      "Tf-idf === 0.5189999999999999\n"
     ]
    }
   ],
   "source": [
    "for k,v in final_value.items():\n",
    "    print('{} === {}'.format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Related Experiments +  Kernel Related Experiments\n",
    "\n",
    "We alady implemennted Logistic regression now we will add \n",
    "\n",
    "- Ridge Regression\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2.T)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "            \n",
    "        \n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X,X,**self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,model_name,kernel=None,lambd=0.2,C=3,sigma=0.5,k=5,power=2):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        if model_name == 'KernelRidgeRegression':\n",
    "            model = KernelRidgeRegression(\n",
    "                    kernel=kernel,\n",
    "                    lambd=lambd,\n",
    "                    sigma=sigma,\n",
    "                    power=power\n",
    "                ).fit(x_train, y_train)\n",
    "            result =sum(np.sign(model.predict(x_test))==y_test)/len(y_test)#roc_auc_score(np.sign(model.predict(x_test)),y_test) #\n",
    "        elif model_name == 'logistic':\n",
    "            logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "            logistic.train()\n",
    "\n",
    "            result = logistic.evaluate(x_test,y_test)\n",
    "            \n",
    "        elif model_name == 'KernelSVM':\n",
    "\n",
    "            model = KernelSVM(C=C,\n",
    "                              kernel=kernel,\n",
    "                              lambd=lambd,\n",
    "                              sigma=sigma,\n",
    "                              power=power)\n",
    "            model.fit(x_train, y_train.flatten())\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            result = sum((y_pred.flatten()==y_test.flatten()))/len(y_test)\n",
    "            \n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6276feca1204ba199e5477998b76613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-30 22:26:42,629]\u001b[0m Finished trial#0 with value: 0.62 with parameters: {'lambd': 49.90849164556973, 'sigma': 134.6978627084693, 'k': 4, 'C': 22.295775974721785, 'power': 5, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#0 with value: 0.62.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-30 22:26:45,819]\u001b[0m Finished trial#1 with value: 0.0 with parameters: {'lambd': 75.13866937197157, 'sigma': 62.12927114449364, 'k': 4, 'C': 33.53982822134812, 'power': 5, 'kmer_size': 3, 'kernel': 'polynomial'}. Best is trial#0 with value: 0.62.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:26:54,827]\u001b[0m Finished trial#2 with value: 0.6465000000000001 with parameters: {'lambd': 45.28801191286693, 'sigma': 106.9238827977568, 'k': 4, 'C': 39.50975356276979, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#2 with value: 0.6465000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:03,665]\u001b[0m Finished trial#3 with value: 0.647 with parameters: {'lambd': 87.49473428702757, 'sigma': 109.69284756453925, 'k': 4, 'C': 26.907490153862735, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#3 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:06,940]\u001b[0m Finished trial#4 with value: 0.0 with parameters: {'lambd': 74.4523823343271, 'sigma': 81.39773095638381, 'k': 4, 'C': 48.125561689092734, 'power': 5, 'kmer_size': 3, 'kernel': 'polynomial'}. Best is trial#3 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:10,131]\u001b[0m Finished trial#5 with value: 0.5395 with parameters: {'lambd': 69.01936391490295, 'sigma': 33.691772373302136, 'k': 5, 'C': 38.087582371924796, 'power': 2, 'kmer_size': 3, 'kernel': 'linear'}. Best is trial#3 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:13,521]\u001b[0m Finished trial#6 with value: 0.0 with parameters: {'lambd': 8.48777883608098, 'sigma': 3.726981417788659, 'k': 4, 'C': 44.22986859153042, 'power': 4, 'kmer_size': 4, 'kernel': 'polynomial'}. Best is trial#3 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:17,024]\u001b[0m Finished trial#7 with value: 0.5825 with parameters: {'lambd': 34.64221920913379, 'sigma': 15.411186326060658, 'k': 4, 'C': 30.22524342620798, 'power': 2, 'kmer_size': 5, 'kernel': 'linear'}. Best is trial#3 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:20,195]\u001b[0m Finished trial#8 with value: 0.0 with parameters: {'lambd': 63.681312954976754, 'sigma': 120.76591028334707, 'k': 8, 'C': 41.81120420344388, 'power': 5, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#3 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:23,971]\u001b[0m Finished trial#9 with value: 0.6300000000000001 with parameters: {'lambd': 8.943722205623688, 'sigma': 142.42576972342403, 'k': 5, 'C': 27.88121780293779, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#3 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:30,887]\u001b[0m Finished trial#10 with value: 0.628 with parameters: {'lambd': 96.70738474851551, 'sigma': 92.1674913182739, 'k': 8, 'C': 9.02512691240059, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#3 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:39,692]\u001b[0m Finished trial#11 with value: 0.6475 with parameters: {'lambd': 32.64727894551969, 'sigma': 109.367735036945, 'k': 4, 'C': 19.77386769564606, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#11 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:44,519]\u001b[0m Finished trial#12 with value: 0.6345000000000001 with parameters: {'lambd': 26.933005281796802, 'sigma': 60.72716715707068, 'k': 4, 'C': 17.168288239456363, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#11 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:53,189]\u001b[0m Finished trial#13 with value: 0.6465000000000001 with parameters: {'lambd': 23.788252170885677, 'sigma': 109.19212998094302, 'k': 4, 'C': 13.905006124182432, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#11 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:27:57,837]\u001b[0m Finished trial#14 with value: 0.6345000000000001 with parameters: {'lambd': 98.27721355944891, 'sigma': 146.77512998576844, 'k': 4, 'C': 3.771228674317058, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#11 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:02,103]\u001b[0m Finished trial#15 with value: 0.638 with parameters: {'lambd': 87.71630814202936, 'sigma': 124.87481236664928, 'k': 8, 'C': 22.450252707239105, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#11 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:10,285]\u001b[0m Finished trial#16 with value: 0.6519999999999999 with parameters: {'lambd': 37.16412079335235, 'sigma': 91.78818758526798, 'k': 5, 'C': 17.93081531917657, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#16 with value: 0.6519999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:14,150]\u001b[0m Finished trial#17 with value: 0.621 with parameters: {'lambd': 39.36635846598909, 'sigma': 88.41908898421312, 'k': 5, 'C': 15.672574828354168, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#16 with value: 0.6519999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:18,720]\u001b[0m Finished trial#18 with value: 0.641 with parameters: {'lambd': 19.727141075506417, 'sigma': 53.915519863477854, 'k': 5, 'C': 3.710014146944822, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#16 with value: 0.6519999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:21,677]\u001b[0m Finished trial#19 with value: 0.5369999999999999 with parameters: {'lambd': 59.51234200591792, 'sigma': 96.48713641032703, 'k': 5, 'C': 10.445273517832463, 'power': 4, 'kmer_size': 2, 'kernel': 'linear'}. Best is trial#16 with value: 0.6519999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:29,860]\u001b[0m Finished trial#20 with value: 0.6525000000000001 with parameters: {'lambd': 31.957608272966194, 'sigma': 72.50828770364934, 'k': 5, 'C': 21.645466263291038, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:37,909]\u001b[0m Finished trial#21 with value: 0.6525000000000001 with parameters: {'lambd': 34.134754251772776, 'sigma': 71.28548953035379, 'k': 5, 'C': 23.322030449783764, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:42,511]\u001b[0m Finished trial#22 with value: 0.641 with parameters: {'lambd': 15.98561378211233, 'sigma': 72.83763182798327, 'k': 5, 'C': 23.186164700358965, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:50,546]\u001b[0m Finished trial#23 with value: 0.6519999999999999 with parameters: {'lambd': 41.15478833788419, 'sigma': 44.395153582261294, 'k': 5, 'C': 12.52333909710938, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:54,132]\u001b[0m Finished trial#24 with value: 0.621 with parameters: {'lambd': 53.65358675503404, 'sigma': 36.57533188422207, 'k': 5, 'C': 10.528968461973532, 'power': 3, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:28:58,779]\u001b[0m Finished trial#25 with value: 0.641 with parameters: {'lambd': 0.5725532960851325, 'sigma': 73.79652105018677, 'k': 5, 'C': 32.89094131964764, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:06,708]\u001b[0m Finished trial#26 with value: 0.6519999999999999 with parameters: {'lambd': 44.6597159502675, 'sigma': 43.78126469703274, 'k': 5, 'C': 14.011979885551701, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:11,253]\u001b[0m Finished trial#27 with value: 0.641 with parameters: {'lambd': 28.50276830220887, 'sigma': 26.923710078763577, 'k': 5, 'C': 7.116767101499306, 'power': 2, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:19,286]\u001b[0m Finished trial#28 with value: 0.6525000000000001 with parameters: {'lambd': 43.81228793660337, 'sigma': 52.44211917086088, 'k': 5, 'C': 24.506681180859708, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:23,105]\u001b[0m Finished trial#29 with value: 0.621 with parameters: {'lambd': 51.643093707195106, 'sigma': 62.196514338163524, 'k': 5, 'C': 24.28110178693636, 'power': 3, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:27,659]\u001b[0m Finished trial#30 with value: 0.6405 with parameters: {'lambd': 55.20679405956095, 'sigma': 52.84718867832844, 'k': 5, 'C': 19.514545750203204, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:35,637]\u001b[0m Finished trial#31 with value: 0.6525000000000001 with parameters: {'lambd': 44.394788312109945, 'sigma': 44.67061306497969, 'k': 5, 'C': 21.19969806447861, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:43,643]\u001b[0m Finished trial#32 with value: 0.6525 with parameters: {'lambd': 47.89922063995077, 'sigma': 68.76085249509188, 'k': 5, 'C': 30.496889375564475, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:51,624]\u001b[0m Finished trial#33 with value: 0.6519999999999999 with parameters: {'lambd': 30.82592741126739, 'sigma': 22.18925799853031, 'k': 5, 'C': 20.544414042074173, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:29:59,647]\u001b[0m Finished trial#34 with value: 0.6525000000000001 with parameters: {'lambd': 43.14995558882866, 'sigma': 49.943524400105744, 'k': 5, 'C': 24.244265130771737, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:07,690]\u001b[0m Finished trial#35 with value: 0.6525000000000001 with parameters: {'lambd': 45.423044510673684, 'sigma': 41.97844482905728, 'k': 5, 'C': 25.435319033978733, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:12,177]\u001b[0m Finished trial#36 with value: 0.6250000000000001 with parameters: {'lambd': 22.882784338844168, 'sigma': 82.61387881884473, 'k': 5, 'C': 27.166784432793786, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:15,798]\u001b[0m Finished trial#37 with value: 0.621 with parameters: {'lambd': 62.27930409821484, 'sigma': 53.26925063080604, 'k': 5, 'C': 33.69849035333914, 'power': 5, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:18,581]\u001b[0m Finished trial#38 with value: 0.559 with parameters: {'lambd': 47.70724600192297, 'sigma': 6.332698403315227, 'k': 8, 'C': 29.352529622843456, 'power': 2, 'kmer_size': 4, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:26,614]\u001b[0m Finished trial#39 with value: 0.6139999999999999 with parameters: {'lambd': 69.88844238807948, 'sigma': 40.2219450151858, 'k': 5, 'C': 36.99454424441864, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:31,214]\u001b[0m Finished trial#40 with value: 0.641 with parameters: {'lambd': 13.929236380954261, 'sigma': 68.77003176812927, 'k': 5, 'C': 21.37430199692561, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:39,151]\u001b[0m Finished trial#41 with value: 0.6525 with parameters: {'lambd': 43.38793043326082, 'sigma': 27.891833542671684, 'k': 5, 'C': 26.323554001649594, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:47,131]\u001b[0m Finished trial#42 with value: 0.6525 with parameters: {'lambd': 39.2619018756234, 'sigma': 46.08212458850624, 'k': 5, 'C': 26.056504820993187, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:30:55,157]\u001b[0m Finished trial#43 with value: 0.6525000000000001 with parameters: {'lambd': 35.929061812422965, 'sigma': 31.649063783982555, 'k': 5, 'C': 23.22957767264193, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:03,268]\u001b[0m Finished trial#44 with value: 0.6525000000000001 with parameters: {'lambd': 59.56008308775064, 'sigma': 59.575296772639334, 'k': 5, 'C': 24.150547627331452, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:07,838]\u001b[0m Finished trial#45 with value: 0.641 with parameters: {'lambd': 57.70827753890662, 'sigma': 60.332653256487546, 'k': 5, 'C': 31.88321485387844, 'power': 5, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:14,673]\u001b[0m Finished trial#46 with value: 0.5065 with parameters: {'lambd': 66.83602043318548, 'sigma': 31.253224200426743, 'k': 8, 'C': 28.4649678951441, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:22,651]\u001b[0m Finished trial#47 with value: 0.6519999999999999 with parameters: {'lambd': 49.082316861578825, 'sigma': 15.098956101698384, 'k': 5, 'C': 18.267145773845172, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:25,930]\u001b[0m Finished trial#48 with value: 0.592 with parameters: {'lambd': 74.99839549836406, 'sigma': 20.49312055503706, 'k': 5, 'C': 35.06107085515354, 'power': 3, 'kmer_size': 5, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:29,076]\u001b[0m Finished trial#49 with value: 0.5579999999999999 with parameters: {'lambd': 44.63605286835851, 'sigma': 46.9919785922705, 'k': 5, 'C': 25.249280858378143, 'power': 4, 'kmer_size': 4, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:33,652]\u001b[0m Finished trial#50 with value: 0.641 with parameters: {'lambd': 27.953953932534063, 'sigma': 80.25876090558185, 'k': 5, 'C': 15.975079044800742, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:41,674]\u001b[0m Finished trial#51 with value: 0.6525000000000001 with parameters: {'lambd': 35.1794945952052, 'sigma': 63.36899370945152, 'k': 5, 'C': 21.656225463774756, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:49,716]\u001b[0m Finished trial#52 with value: 0.6525000000000001 with parameters: {'lambd': 33.42499545758275, 'sigma': 65.98319865661092, 'k': 5, 'C': 21.552889086577515, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:31:57,700]\u001b[0m Finished trial#53 with value: 0.6519999999999999 with parameters: {'lambd': 50.78292878253573, 'sigma': 36.51431832957828, 'k': 5, 'C': 19.046518029817086, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:05,737]\u001b[0m Finished trial#54 with value: 0.6525 with parameters: {'lambd': 42.37326873029009, 'sigma': 52.0655916139582, 'k': 5, 'C': 27.62532359467614, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:10,413]\u001b[0m Finished trial#55 with value: 0.634 with parameters: {'lambd': 35.5741400493412, 'sigma': 66.29180533766825, 'k': 4, 'C': 21.602804611177206, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:17,265]\u001b[0m Finished trial#56 with value: 0.628 with parameters: {'lambd': 36.1754667830548, 'sigma': 56.27345509914002, 'k': 8, 'C': 25.317050716717937, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:25,289]\u001b[0m Finished trial#57 with value: 0.6525000000000001 with parameters: {'lambd': 22.21886600685666, 'sigma': 82.33515848800008, 'k': 5, 'C': 23.109084433404842, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:29,905]\u001b[0m Finished trial#58 with value: 0.641 with parameters: {'lambd': 37.92660442260132, 'sigma': 65.09712638857948, 'k': 5, 'C': 16.45402856958091, 'power': 5, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:33,032]\u001b[0m Finished trial#59 with value: 0.5315 with parameters: {'lambd': 25.720338280505025, 'sigma': 77.87722567529349, 'k': 5, 'C': 29.58392180263659, 'power': 3, 'kmer_size': 2, 'kernel': 'polynomial'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:41,165]\u001b[0m Finished trial#60 with value: 0.6525000000000001 with parameters: {'lambd': 19.21975258413149, 'sigma': 87.20990831081967, 'k': 5, 'C': 23.68129858084378, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:49,328]\u001b[0m Finished trial#61 with value: 0.6525000000000001 with parameters: {'lambd': 32.54111337448773, 'sigma': 99.52117329653521, 'k': 5, 'C': 22.516033090483123, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:32:57,354]\u001b[0m Finished trial#62 with value: 0.6519999999999999 with parameters: {'lambd': 30.572228408218127, 'sigma': 99.3520838152938, 'k': 5, 'C': 19.9790160998014, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:05,472]\u001b[0m Finished trial#63 with value: 0.6519999999999999 with parameters: {'lambd': 40.673514391421584, 'sigma': 49.211482579538, 'k': 5, 'C': 17.60710062300075, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:10,012]\u001b[0m Finished trial#64 with value: 0.641 with parameters: {'lambd': 16.85275900334687, 'sigma': 85.81718016472246, 'k': 5, 'C': 22.04880683701239, 'power': 5, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:18,081]\u001b[0m Finished trial#65 with value: 0.6525000000000001 with parameters: {'lambd': 19.588553826701865, 'sigma': 117.04363472413634, 'k': 5, 'C': 24.285480750759863, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:22,804]\u001b[0m Finished trial#66 with value: 0.634 with parameters: {'lambd': 54.6874314124982, 'sigma': 117.8040252940682, 'k': 4, 'C': 24.72137684996526, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:30,890]\u001b[0m Finished trial#67 with value: 0.6525 with parameters: {'lambd': 4.443270635663936, 'sigma': 57.53735187003546, 'k': 5, 'C': 26.57504096012812, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:38,843]\u001b[0m Finished trial#68 with value: 0.6525000000000001 with parameters: {'lambd': 11.323956576769776, 'sigma': 99.03958958552835, 'k': 5, 'C': 22.81459655258971, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:46,936]\u001b[0m Finished trial#69 with value: 0.6519999999999999 with parameters: {'lambd': 21.081759209661225, 'sigma': 130.39468776971538, 'k': 5, 'C': 14.200430467317073, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:51,508]\u001b[0m Finished trial#70 with value: 0.641 with parameters: {'lambd': 47.017429217111975, 'sigma': 39.92643404030939, 'k': 5, 'C': 31.577761811439967, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:33:59,467]\u001b[0m Finished trial#71 with value: 0.6525 with parameters: {'lambd': 57.581996759583646, 'sigma': 41.566496726579075, 'k': 5, 'C': 28.239726677513005, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:34:07,615]\u001b[0m Finished trial#72 with value: 0.6519999999999999 with parameters: {'lambd': 51.58987608287936, 'sigma': 34.132594721809156, 'k': 5, 'C': 20.61490141336114, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:34:15,667]\u001b[0m Finished trial#73 with value: 0.6525000000000001 with parameters: {'lambd': 30.7781323975621, 'sigma': 94.20070452344311, 'k': 5, 'C': 23.47690427124927, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:34:23,574]\u001b[0m Finished trial#74 with value: 0.6525000000000001 with parameters: {'lambd': 28.880037131951486, 'sigma': 117.11658649311627, 'k': 5, 'C': 25.077762420974672, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:34:31,671]\u001b[0m Finished trial#75 with value: 0.6519999999999999 with parameters: {'lambd': 25.220336693067935, 'sigma': 104.14854312376059, 'k': 5, 'C': 18.830338651991823, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:34:39,696]\u001b[0m Finished trial#76 with value: 0.6519999999999999 with parameters: {'lambd': 32.45497684867241, 'sigma': 76.10554428521738, 'k': 5, 'C': 19.995638214122103, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:34:43,934]\u001b[0m Finished trial#77 with value: 0.638 with parameters: {'lambd': 45.71290668785466, 'sigma': 102.89618939491253, 'k': 8, 'C': 22.424368779823794, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:34:51,967]\u001b[0m Finished trial#78 with value: 0.6525 with parameters: {'lambd': 62.36201258136866, 'sigma': 29.859881858598705, 'k': 5, 'C': 26.86103732628736, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:35:00,010]\u001b[0m Finished trial#79 with value: 0.6519999999999999 with parameters: {'lambd': 10.829122619032313, 'sigma': 71.30675776349291, 'k': 5, 'C': 49.45377990706915, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:35:04,617]\u001b[0m Finished trial#80 with value: 0.586 with parameters: {'lambd': 42.08521183895598, 'sigma': 49.48578577273736, 'k': 5, 'C': 24.205020639416393, 'power': 4, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:35:12,738]\u001b[0m Finished trial#81 with value: 0.6525 with parameters: {'lambd': 5.07453318685193, 'sigma': 113.80329029285045, 'k': 5, 'C': 28.700836497745303, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:35:20,872]\u001b[0m Finished trial#82 with value: 0.6525000000000001 with parameters: {'lambd': 12.203732209805368, 'sigma': 60.12948684160469, 'k': 5, 'C': 23.677206842823715, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:35:28,949]\u001b[0m Finished trial#83 with value: 0.6525000000000001 with parameters: {'lambd': 38.67805666179408, 'sigma': 59.579140670093025, 'k': 5, 'C': 20.919015058160195, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:35:37,009]\u001b[0m Finished trial#84 with value: 0.6525 with parameters: {'lambd': 36.6953016926964, 'sigma': 71.03902239629205, 'k': 5, 'C': 25.872162385453436, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:35:45,130]\u001b[0m Finished trial#85 with value: 0.6525000000000001 with parameters: {'lambd': 33.810660637939804, 'sigma': 84.77052161563064, 'k': 5, 'C': 22.119008267434594, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:35:53,307]\u001b[0m Finished trial#86 with value: 0.6519999999999999 with parameters: {'lambd': 34.23750579451796, 'sigma': 63.13826689309451, 'k': 5, 'C': 17.461615656365765, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:01,790]\u001b[0m Finished trial#87 with value: 0.647 with parameters: {'lambd': 18.240032813118646, 'sigma': 90.72304788626784, 'k': 4, 'C': 23.147320368616818, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:06,346]\u001b[0m Finished trial#88 with value: 0.641 with parameters: {'lambd': 80.12863565496112, 'sigma': 54.881713791232364, 'k': 5, 'C': 21.050318168526964, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:14,501]\u001b[0m Finished trial#89 with value: 0.6525 with parameters: {'lambd': 22.07507037965834, 'sigma': 130.5842585750956, 'k': 5, 'C': 30.2280952237582, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:19,095]\u001b[0m Finished trial#90 with value: 0.6405 with parameters: {'lambd': 40.67282028286764, 'sigma': 67.56727316718023, 'k': 5, 'C': 19.52599398022994, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:27,009]\u001b[0m Finished trial#91 with value: 0.6525000000000001 with parameters: {'lambd': 28.955925702131754, 'sigma': 94.52699158906907, 'k': 5, 'C': 23.226587645298906, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:35,013]\u001b[0m Finished trial#92 with value: 0.6525000000000001 with parameters: {'lambd': 30.447839096729563, 'sigma': 95.04697341553882, 'k': 5, 'C': 25.63133339915714, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:43,091]\u001b[0m Finished trial#93 with value: 0.6525 with parameters: {'lambd': 44.40575413032586, 'sigma': 41.79167359772269, 'k': 5, 'C': 27.729181386599375, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:51,175]\u001b[0m Finished trial#94 with value: 0.6525 with parameters: {'lambd': 39.3630504984763, 'sigma': 84.56098585732595, 'k': 5, 'C': 25.983049309352758, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:36:54,233]\u001b[0m Finished trial#95 with value: 0.5415 with parameters: {'lambd': 14.693110042974165, 'sigma': 111.52053449628725, 'k': 5, 'C': 24.876776230698493, 'power': 4, 'kmer_size': 3, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:37:02,261]\u001b[0m Finished trial#96 with value: 0.6525000000000001 with parameters: {'lambd': 48.14444379734041, 'sigma': 60.55084716201148, 'k': 5, 'C': 21.19152632954487, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:37:10,373]\u001b[0m Finished trial#97 with value: 0.6519999999999999 with parameters: {'lambd': 38.02427116159665, 'sigma': 57.12097945523459, 'k': 5, 'C': 20.61433945634072, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:37:18,377]\u001b[0m Finished trial#98 with value: 0.6519999999999999 with parameters: {'lambd': 23.850957059071135, 'sigma': 76.91665374814117, 'k': 5, 'C': 18.53395621506763, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:37:25,267]\u001b[0m Finished trial#99 with value: 0.628 with parameters: {'lambd': 50.15649739210882, 'sigma': 48.252285520750235, 'k': 8, 'C': 21.83322670830218, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:37:33,417]\u001b[0m Finished trial#100 with value: 0.6014999999999999 with parameters: {'lambd': 52.39835064826719, 'sigma': 58.801441067635174, 'k': 5, 'C': 24.037025703479408, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:37:41,381]\u001b[0m Finished trial#101 with value: 0.6525 with parameters: {'lambd': 35.276635145456034, 'sigma': 51.42620710043347, 'k': 5, 'C': 26.973762547150834, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:37:49,411]\u001b[0m Finished trial#102 with value: 0.6525000000000001 with parameters: {'lambd': 26.906042089133454, 'sigma': 88.67259238402207, 'k': 5, 'C': 23.741066868194522, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:37:57,488]\u001b[0m Finished trial#103 with value: 0.6525000000000001 with parameters: {'lambd': 19.674695682776594, 'sigma': 36.22718416741452, 'k': 5, 'C': 21.999616106591745, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:38:05,439]\u001b[0m Finished trial#104 with value: 0.6525000000000001 with parameters: {'lambd': 25.781119570305354, 'sigma': 89.44363907421291, 'k': 5, 'C': 24.15049590553824, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:38:13,446]\u001b[0m Finished trial#105 with value: 0.6525000000000001 with parameters: {'lambd': 20.955162622308688, 'sigma': 38.10706465861303, 'k': 5, 'C': 22.03480288090457, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:38:21,519]\u001b[0m Finished trial#106 with value: 0.6525000000000001 with parameters: {'lambd': 17.228313633642053, 'sigma': 81.15271689345738, 'k': 5, 'C': 24.591303993285056, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:38:26,071]\u001b[0m Finished trial#107 with value: 0.641 with parameters: {'lambd': 7.775095691576761, 'sigma': 23.335757928134004, 'k': 5, 'C': 22.87153962296697, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:38:29,292]\u001b[0m Finished trial#108 with value: 0.592 with parameters: {'lambd': 46.03339311269141, 'sigma': 45.876200739780145, 'k': 5, 'C': 17.042989043321594, 'power': 4, 'kmer_size': 5, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:38:37,361]\u001b[0m Finished trial#109 with value: 0.6519999999999999 with parameters: {'lambd': 29.55751159219114, 'sigma': 74.16286157603662, 'k': 5, 'C': 14.72377434250981, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:38:45,797]\u001b[0m Finished trial#110 with value: 0.647 with parameters: {'lambd': 10.856083829417539, 'sigma': 140.30109052553442, 'k': 4, 'C': 25.361441328045366, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:38:53,740]\u001b[0m Finished trial#111 with value: 0.6525000000000001 with parameters: {'lambd': 48.170597255782496, 'sigma': 124.27377688473125, 'k': 5, 'C': 23.099401523758562, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:01,701]\u001b[0m Finished trial#112 with value: 0.6519999999999999 with parameters: {'lambd': 33.88756103622693, 'sigma': 63.13175727842589, 'k': 5, 'C': 19.335874911695463, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:09,622]\u001b[0m Finished trial#113 with value: 0.6525000000000001 with parameters: {'lambd': 13.774232797161325, 'sigma': 106.66454961173913, 'k': 5, 'C': 22.697021543159746, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:17,591]\u001b[0m Finished trial#114 with value: 0.6519999999999999 with parameters: {'lambd': 31.9093420517753, 'sigma': 95.81579518175486, 'k': 5, 'C': 20.165247863051334, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:25,589]\u001b[0m Finished trial#115 with value: 0.6519999999999999 with parameters: {'lambd': 12.582678922887332, 'sigma': 98.87482797289563, 'k': 5, 'C': 20.378112641513972, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:33,544]\u001b[0m Finished trial#116 with value: 0.6525 with parameters: {'lambd': 43.32903410784194, 'sigma': 116.41817788867952, 'k': 5, 'C': 26.621281440491828, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:36,707]\u001b[0m Finished trial#117 with value: 0.5584999999999999 with parameters: {'lambd': 56.40818155167727, 'sigma': 60.364002719262764, 'k': 5, 'C': 25.767527269646703, 'power': 2, 'kmer_size': 4, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:44,641]\u001b[0m Finished trial#118 with value: 0.6525000000000001 with parameters: {'lambd': 18.309532120721236, 'sigma': 100.6659327312606, 'k': 5, 'C': 24.36293270454123, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:52,625]\u001b[0m Finished trial#119 with value: 0.6525 with parameters: {'lambd': 19.606303845554763, 'sigma': 80.12969951782951, 'k': 5, 'C': 29.187957649672434, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:39:57,223]\u001b[0m Finished trial#120 with value: 0.641 with parameters: {'lambd': 32.310567257829454, 'sigma': 101.52331624417396, 'k': 5, 'C': 18.07257305057313, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:40:05,212]\u001b[0m Finished trial#121 with value: 0.6525000000000001 with parameters: {'lambd': 41.162213619220594, 'sigma': 85.90257211523881, 'k': 5, 'C': 21.538505631735198, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:40:13,183]\u001b[0m Finished trial#122 with value: 0.6525000000000001 with parameters: {'lambd': 24.915663423280627, 'sigma': 106.45299229204505, 'k': 5, 'C': 23.113019647829454, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:40:21,254]\u001b[0m Finished trial#123 with value: 0.6525 with parameters: {'lambd': 28.3976226531651, 'sigma': 87.39393062706357, 'k': 5, 'C': 27.563037265519675, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:40:29,234]\u001b[0m Finished trial#124 with value: 0.6525000000000001 with parameters: {'lambd': 39.16148753617476, 'sigma': 108.96269311265561, 'k': 5, 'C': 23.277892295416006, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:40:37,245]\u001b[0m Finished trial#125 with value: 0.6525000000000001 with parameters: {'lambd': 29.9160766363267, 'sigma': 96.59388926306046, 'k': 5, 'C': 25.25808446651362, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:40:45,426]\u001b[0m Finished trial#126 with value: 0.6525000000000001 with parameters: {'lambd': 29.982924098416255, 'sigma': 91.49946455973694, 'k': 5, 'C': 25.495375763771808, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:40:53,427]\u001b[0m Finished trial#127 with value: 0.6525000000000001 with parameters: {'lambd': 36.672238620601576, 'sigma': 94.98439899142177, 'k': 5, 'C': 25.204758425622177, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:41:01,320]\u001b[0m Finished trial#128 with value: 0.6525 with parameters: {'lambd': 36.76104545682537, 'sigma': 93.15214221847378, 'k': 5, 'C': 26.156031582045426, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:41:08,082]\u001b[0m Finished trial#129 with value: 0.628 with parameters: {'lambd': 15.946472640503206, 'sigma': 42.02790070625474, 'k': 8, 'C': 21.62314729876353, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:41:16,034]\u001b[0m Finished trial#130 with value: 0.6519999999999999 with parameters: {'lambd': 21.752745416366338, 'sigma': 84.35720311761752, 'k': 5, 'C': 43.936383488051355, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:41:24,065]\u001b[0m Finished trial#131 with value: 0.6525000000000001 with parameters: {'lambd': 25.740429721668185, 'sigma': 69.24447400445072, 'k': 5, 'C': 23.84787905035588, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:41:32,157]\u001b[0m Finished trial#132 with value: 0.6525000000000001 with parameters: {'lambd': 34.18631113651241, 'sigma': 78.51262432669716, 'k': 5, 'C': 22.27559477995153, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:41:40,157]\u001b[0m Finished trial#133 with value: 0.6525000000000001 with parameters: {'lambd': 18.768134513454278, 'sigma': 99.89108779146315, 'k': 5, 'C': 24.413478587960178, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:41:48,120]\u001b[0m Finished trial#134 with value: 0.6525000000000001 with parameters: {'lambd': 8.059029301230861, 'sigma': 121.03667554512141, 'k': 5, 'C': 22.402343420048677, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:41:56,070]\u001b[0m Finished trial#135 with value: 0.6525000000000001 with parameters: {'lambd': 2.360059866081018, 'sigma': 55.12839236581061, 'k': 5, 'C': 21.080727368868526, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:42:04,071]\u001b[0m Finished trial#136 with value: 0.6525000000000001 with parameters: {'lambd': 1.7208531398760816, 'sigma': 52.74766475168833, 'k': 5, 'C': 20.900380225976917, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:42:12,096]\u001b[0m Finished trial#137 with value: 0.6519999999999999 with parameters: {'lambd': 27.678785772586867, 'sigma': 94.5204827906876, 'k': 5, 'C': 19.760666961827038, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:42:20,032]\u001b[0m Finished trial#138 with value: 0.6525000000000001 with parameters: {'lambd': 26.446881003370773, 'sigma': 33.96517638942029, 'k': 5, 'C': 23.726048186868116, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:42:28,170]\u001b[0m Finished trial#139 with value: 0.6014999999999999 with parameters: {'lambd': 26.154531728274794, 'sigma': 37.380345078787236, 'k': 5, 'C': 23.82201211599097, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:42:36,065]\u001b[0m Finished trial#140 with value: 0.6525 with parameters: {'lambd': 40.0187594370515, 'sigma': 112.64813597347184, 'k': 5, 'C': 27.069866786452327, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:42:44,009]\u001b[0m Finished trial#141 with value: 0.6525000000000001 with parameters: {'lambd': 22.66614147832802, 'sigma': 38.749705463123064, 'k': 5, 'C': 22.330642508768555, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:42:51,922]\u001b[0m Finished trial#142 with value: 0.6525000000000001 with parameters: {'lambd': 21.752227005858035, 'sigma': 37.5238925188902, 'k': 5, 'C': 22.597091605283218, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:42:59,912]\u001b[0m Finished trial#143 with value: 0.6525000000000001 with parameters: {'lambd': 48.43836494997344, 'sigma': 44.881312533938384, 'k': 5, 'C': 21.000601359830306, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:43:07,918]\u001b[0m Finished trial#144 with value: 0.6519999999999999 with parameters: {'lambd': 49.309757996779204, 'sigma': 44.82015732611143, 'k': 5, 'C': 18.980920875532984, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:43:15,915]\u001b[0m Finished trial#145 with value: 0.6525000000000001 with parameters: {'lambd': 13.884917798906693, 'sigma': 121.8391514638019, 'k': 5, 'C': 24.902726509001013, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:43:24,365]\u001b[0m Finished trial#146 with value: 0.647 with parameters: {'lambd': 13.690373773529526, 'sigma': 125.58502971037177, 'k': 4, 'C': 24.74983232314891, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:43:32,348]\u001b[0m Finished trial#147 with value: 0.6525000000000001 with parameters: {'lambd': 17.033271863846963, 'sigma': 31.518978044646577, 'k': 5, 'C': 22.938423751418142, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:43:40,369]\u001b[0m Finished trial#148 with value: 0.6525000000000001 with parameters: {'lambd': 23.83371474721998, 'sigma': 89.76915410957129, 'k': 5, 'C': 23.639961776775298, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:43:48,412]\u001b[0m Finished trial#149 with value: 0.6525000000000001 with parameters: {'lambd': 28.14568535577424, 'sigma': 89.16071052477528, 'k': 5, 'C': 22.014370818776527, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:43:56,351]\u001b[0m Finished trial#150 with value: 0.6525 with parameters: {'lambd': 20.95654887582849, 'sigma': 89.93909338160407, 'k': 5, 'C': 26.47187167617689, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:44:04,322]\u001b[0m Finished trial#151 with value: 0.6525 with parameters: {'lambd': 45.958303175154, 'sigma': 105.53650500526372, 'k': 5, 'C': 28.30845469927725, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:44:12,269]\u001b[0m Finished trial#152 with value: 0.6525000000000001 with parameters: {'lambd': 11.523505931046008, 'sigma': 102.39562929372023, 'k': 5, 'C': 23.26198386169904, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:44:20,250]\u001b[0m Finished trial#153 with value: 0.6525000000000001 with parameters: {'lambd': 17.484505860146243, 'sigma': 63.47140448739639, 'k': 5, 'C': 24.368284681453336, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:44:28,229]\u001b[0m Finished trial#154 with value: 0.6525000000000001 with parameters: {'lambd': 16.848433978020715, 'sigma': 66.63301557388168, 'k': 5, 'C': 24.37896657593379, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:44:36,198]\u001b[0m Finished trial#155 with value: 0.6525000000000001 with parameters: {'lambd': 34.6487331562086, 'sigma': 97.66283836751344, 'k': 5, 'C': 25.196262457198866, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:44:44,165]\u001b[0m Finished trial#156 with value: 0.6525 with parameters: {'lambd': 31.8116473541876, 'sigma': 78.54483343842297, 'k': 5, 'C': 26.074480312510474, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:44:52,166]\u001b[0m Finished trial#157 with value: 0.6525000000000001 with parameters: {'lambd': 9.271097564756445, 'sigma': 106.00608726123532, 'k': 5, 'C': 23.188293501018666, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:45:00,082]\u001b[0m Finished trial#158 with value: 0.6525000000000001 with parameters: {'lambd': 42.12987653640769, 'sigma': 81.78732557887561, 'k': 5, 'C': 21.574853593558792, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:45:08,008]\u001b[0m Finished trial#159 with value: 0.6525000000000001 with parameters: {'lambd': 41.47966931535203, 'sigma': 109.42056464373819, 'k': 5, 'C': 21.575608317762093, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:45:16,040]\u001b[0m Finished trial#160 with value: 0.6525000000000001 with parameters: {'lambd': 38.70076797053474, 'sigma': 110.1829108156049, 'k': 5, 'C': 22.824294955485346, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:45:24,023]\u001b[0m Finished trial#161 with value: 0.6519999999999999 with parameters: {'lambd': 24.26001165703249, 'sigma': 27.481729877219145, 'k': 5, 'C': 20.352117221358263, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:45:32,158]\u001b[0m Finished trial#162 with value: 0.6525000000000001 with parameters: {'lambd': 23.50994654619355, 'sigma': 30.49674115133986, 'k': 5, 'C': 22.511585930238333, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:45:40,204]\u001b[0m Finished trial#163 with value: 0.6525000000000001 with parameters: {'lambd': 60.23659893962754, 'sigma': 125.26045345542146, 'k': 5, 'C': 24.535320451053405, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:45:48,173]\u001b[0m Finished trial#164 with value: 0.6525000000000001 with parameters: {'lambd': 66.6586672440598, 'sigma': 141.6137155447829, 'k': 5, 'C': 24.556126060067243, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:45:56,261]\u001b[0m Finished trial#165 with value: 0.6525000000000001 with parameters: {'lambd': 14.863302844406567, 'sigma': 85.15814727701355, 'k': 5, 'C': 21.101644526275642, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:46:04,327]\u001b[0m Finished trial#166 with value: 0.6525000000000001 with parameters: {'lambd': 30.414410056998346, 'sigma': 86.54493808090182, 'k': 5, 'C': 23.497486508609295, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:46:12,374]\u001b[0m Finished trial#167 with value: 0.6519999999999999 with parameters: {'lambd': 26.906858365885974, 'sigma': 106.67448086663101, 'k': 5, 'C': 19.308065648755008, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:46:20,329]\u001b[0m Finished trial#168 with value: 0.6525000000000001 with parameters: {'lambd': 34.06871374886457, 'sigma': 69.38950437025345, 'k': 5, 'C': 21.972898775251306, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:46:27,271]\u001b[0m Finished trial#169 with value: 0.628 with parameters: {'lambd': 37.456266204216895, 'sigma': 92.51606671221894, 'k': 8, 'C': 25.51701564989429, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:46:35,224]\u001b[0m Finished trial#170 with value: 0.6525000000000001 with parameters: {'lambd': 17.097063539544905, 'sigma': 34.66221701410606, 'k': 5, 'C': 24.542352102339866, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:46:43,302]\u001b[0m Finished trial#171 with value: 0.6525000000000001 with parameters: {'lambd': 29.58700815059172, 'sigma': 96.54103622353621, 'k': 5, 'C': 25.279709797546445, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:46:51,247]\u001b[0m Finished trial#172 with value: 0.6525 with parameters: {'lambd': 30.363660908499355, 'sigma': 94.15073754640461, 'k': 5, 'C': 27.516395060495142, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:46:59,211]\u001b[0m Finished trial#173 with value: 0.6525000000000001 with parameters: {'lambd': 1.3115966463292965, 'sigma': 55.165427077872884, 'k': 5, 'C': 20.772771415111094, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:47:07,171]\u001b[0m Finished trial#174 with value: 0.6519999999999999 with parameters: {'lambd': 4.113781048878957, 'sigma': 0.5754086339861821, 'k': 5, 'C': 20.21018230566271, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:47:15,127]\u001b[0m Finished trial#175 with value: 0.6525000000000001 with parameters: {'lambd': 6.7001834939611, 'sigma': 74.52760317672531, 'k': 5, 'C': 22.345359061460808, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:47:23,149]\u001b[0m Finished trial#176 with value: 0.6525000000000001 with parameters: {'lambd': 7.5230077074898745, 'sigma': 74.9879369371192, 'k': 5, 'C': 22.340990807579036, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:47:31,207]\u001b[0m Finished trial#177 with value: 0.6525000000000001 with parameters: {'lambd': 2.2327340156619777, 'sigma': 119.68079833104221, 'k': 5, 'C': 21.113107996172715, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:47:39,327]\u001b[0m Finished trial#178 with value: 0.6014999999999999 with parameters: {'lambd': 1.5476391041901243, 'sigma': 116.6282827455955, 'k': 5, 'C': 21.16887849753843, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:47:47,415]\u001b[0m Finished trial#179 with value: 0.6525000000000001 with parameters: {'lambd': 64.49772508927235, 'sigma': 127.37262258033829, 'k': 5, 'C': 23.523843356988944, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:47:55,416]\u001b[0m Finished trial#180 with value: 0.6525000000000001 with parameters: {'lambd': 34.7510942545798, 'sigma': 10.80816342005614, 'k': 5, 'C': 23.761264232990648, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:48:03,495]\u001b[0m Finished trial#181 with value: 0.6525000000000001 with parameters: {'lambd': 10.501650339906295, 'sigma': 13.61197767626998, 'k': 5, 'C': 23.71245841883426, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:48:11,489]\u001b[0m Finished trial#182 with value: 0.6525000000000001 with parameters: {'lambd': 11.071853069481723, 'sigma': 90.78345298595849, 'k': 5, 'C': 23.41042590391294, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:48:19,490]\u001b[0m Finished trial#183 with value: 0.6525000000000001 with parameters: {'lambd': 19.72318864596468, 'sigma': 100.68694226256818, 'k': 5, 'C': 25.752674200280918, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:48:27,427]\u001b[0m Finished trial#184 with value: 0.6525000000000001 with parameters: {'lambd': 20.063280960501206, 'sigma': 98.62393455440026, 'k': 5, 'C': 24.841725779714828, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:48:35,378]\u001b[0m Finished trial#185 with value: 0.6525 with parameters: {'lambd': 26.662384737400707, 'sigma': 103.79700384592351, 'k': 5, 'C': 26.418147079846072, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:48:43,364]\u001b[0m Finished trial#186 with value: 0.6525000000000001 with parameters: {'lambd': 32.552792024111355, 'sigma': 71.65760925879742, 'k': 5, 'C': 25.341642069091932, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:48:51,392]\u001b[0m Finished trial#187 with value: 0.6525 with parameters: {'lambd': 32.77337038658153, 'sigma': 70.90385202537334, 'k': 5, 'C': 25.78334435203633, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:48:59,433]\u001b[0m Finished trial#188 with value: 0.6525000000000001 with parameters: {'lambd': 23.05615845028328, 'sigma': 63.90986368290272, 'k': 5, 'C': 22.508382754478273, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:49:07,377]\u001b[0m Finished trial#189 with value: 0.6525000000000001 with parameters: {'lambd': 22.532848013048675, 'sigma': 64.40385133386846, 'k': 5, 'C': 22.404848393757778, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:49:15,377]\u001b[0m Finished trial#190 with value: 0.6519999999999999 with parameters: {'lambd': 22.303701648221818, 'sigma': 78.23664966820007, 'k': 5, 'C': 19.584663964939782, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:49:23,370]\u001b[0m Finished trial#191 with value: 0.6525000000000001 with parameters: {'lambd': 6.027245870560472, 'sigma': 120.91809164319983, 'k': 5, 'C': 21.834821552704234, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:49:31,434]\u001b[0m Finished trial#192 with value: 0.6525000000000001 with parameters: {'lambd': 28.83626881923951, 'sigma': 92.56751297077655, 'k': 5, 'C': 23.79403198565158, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:49:39,356]\u001b[0m Finished trial#193 with value: 0.6525000000000001 with parameters: {'lambd': 0.23547041236341282, 'sigma': 135.40729718380402, 'k': 5, 'C': 20.67616537713656, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:49:47,291]\u001b[0m Finished trial#194 with value: 0.6525000000000001 with parameters: {'lambd': 48.67763516329164, 'sigma': 38.24721806506909, 'k': 5, 'C': 22.497595877131918, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:49:55,786]\u001b[0m Finished trial#195 with value: 0.647 with parameters: {'lambd': 23.797581996353664, 'sigma': 32.14018724154331, 'k': 4, 'C': 22.67434683076787, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:50:03,828]\u001b[0m Finished trial#196 with value: 0.6525000000000001 with parameters: {'lambd': 11.793974982762357, 'sigma': 98.64831919803916, 'k': 5, 'C': 23.729022822069343, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:50:11,802]\u001b[0m Finished trial#197 with value: 0.6525000000000001 with parameters: {'lambd': 15.187477912332888, 'sigma': 102.4905915997111, 'k': 5, 'C': 23.869925232199293, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 22:50:19,911]\u001b[0m Finished trial#198 with value: 0.6525000000000001 with parameters: {'lambd': 16.1540716080708, 'sigma': 82.8270527486765, 'k': 5, 'C': 24.656636927594228, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#20 with value: 0.6525000000000001.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-e2592cbfb163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 334\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 )\n\u001b[1;32m    336\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-166-e2592cbfb163>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'polynomial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'KernelSVM'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-163-ba1971ee83c4>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(x_data, y_data, model_name, kernel, lambd, C, sigma, k, power)\u001b[0m\n\u001b[1;32m     43\u001b[0m                               \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                               power=power)\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-80a06a324978>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, tol)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Kernel matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         K = self.kernel_function_(\n\u001b[0;32m---> 47\u001b[0;31m             self.X_train, self.X_train, **self.kernel_parameters)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Solve dual problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e25f7751f78e>\u001b[0m in \u001b[0;36mlinear_kernel\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpolynomial_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    lambd = trial.suggest_float('lambd', 1e-5, 100.0)\n",
    "    sigma = trial.suggest_float('sigma', 1e-5, 150)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8])\n",
    "    C =  trial.suggest_float('C', 2,50)\n",
    "    power =  trial.suggest_int('power', 2,5)\n",
    "    kmer_size =  trial.suggest_int('kmer_size', 2,8)\n",
    "    kernel =  trial.suggest_categorical('kernel', ['linear','polynomial'])\n",
    "    \n",
    "    return cross_validate(get_data(kmer_size)[:2000,:],get_label(type=-1),model_name='KernelSVM',C=C,kernel=kernel,lambd=lambd,k=k,sigma=sigma,power=power)\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=500,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_C</th>\n",
       "      <th>params_k</th>\n",
       "      <th>params_kernel</th>\n",
       "      <th>params_kmer_size</th>\n",
       "      <th>params_lambd</th>\n",
       "      <th>params_power</th>\n",
       "      <th>params_sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:03.186034</td>\n",
       "      <td>33.539828</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>3</td>\n",
       "      <td>75.138669</td>\n",
       "      <td>5</td>\n",
       "      <td>62.129271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:03.271313</td>\n",
       "      <td>48.125562</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>3</td>\n",
       "      <td>74.452382</td>\n",
       "      <td>5</td>\n",
       "      <td>81.397731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:03.385556</td>\n",
       "      <td>44.229869</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>4</td>\n",
       "      <td>8.487779</td>\n",
       "      <td>4</td>\n",
       "      <td>3.726981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:03.164807</td>\n",
       "      <td>41.811204</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>5</td>\n",
       "      <td>63.681313</td>\n",
       "      <td>5</td>\n",
       "      <td>120.765910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.5065</td>\n",
       "      <td>00:00:06.830531</td>\n",
       "      <td>28.464968</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>8</td>\n",
       "      <td>66.836020</td>\n",
       "      <td>2</td>\n",
       "      <td>31.253224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:07.985766</td>\n",
       "      <td>21.538506</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>8</td>\n",
       "      <td>41.162214</td>\n",
       "      <td>5</td>\n",
       "      <td>85.902572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.177892</td>\n",
       "      <td>21.645466</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>8</td>\n",
       "      <td>31.957608</td>\n",
       "      <td>3</td>\n",
       "      <td>72.508288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.038127</td>\n",
       "      <td>22.014371</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>8</td>\n",
       "      <td>28.145685</td>\n",
       "      <td>3</td>\n",
       "      <td>89.160711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.104350</td>\n",
       "      <td>24.656637</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>8</td>\n",
       "      <td>16.154072</td>\n",
       "      <td>3</td>\n",
       "      <td>82.827053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>26.935290</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>8</td>\n",
       "      <td>28.211901</td>\n",
       "      <td>4</td>\n",
       "      <td>83.673855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number   value        duration  ...  params_lambd  params_power params_sigma\n",
       "1         1  0.0000 00:00:03.186034  ...     75.138669             5    62.129271\n",
       "4         4  0.0000 00:00:03.271313  ...     74.452382             5    81.397731\n",
       "6         6  0.0000 00:00:03.385556  ...      8.487779             4     3.726981\n",
       "8         8  0.0000 00:00:03.164807  ...     63.681313             5   120.765910\n",
       "46       46  0.5065 00:00:06.830531  ...     66.836020             2    31.253224\n",
       "..      ...     ...             ...  ...           ...           ...          ...\n",
       "121     121  0.6525 00:00:07.985766  ...     41.162214             5    85.902572\n",
       "20       20  0.6525 00:00:08.177892  ...     31.957608             3    72.508288\n",
       "149     149  0.6525 00:00:08.038127  ...     28.145685             3    89.160711\n",
       "198     198  0.6525 00:00:08.104350  ...     16.154072             3    82.827053\n",
       "199     199     NaN             NaT  ...     28.211901             4    83.673855\n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340, 65536) (660, 65536) (1340, 1) (660, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6484848484848484"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test  = get_train_test(get_data(8)[:2000,:],get_label(type=-1).reshape(-1,1),p=0.33)\n",
    "\n",
    "\n",
    "kernel = 'linear'\n",
    "power = 4\n",
    "sigma = 0.00000001\n",
    "C = 2\n",
    "model = KernelSVM(C=C, kernel=kernel, sigma=sigma, power=power)\n",
    "y_pred = model.fit(X_train, y_train.flatten()).predict(X_test)\n",
    "\n",
    "sum(y_pred.flatten()==y_test.flatten())/len(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "def string_kernel(s, t, k=3, delta=0):\n",
    "    \"\"\" Basic string kernel with displacement assuming equal lengths. \"\"\"\n",
    "    L = len(s)\n",
    "    return sum(((s[i:i + k] == t[d + i:d + i + k])\n",
    "               for i, d in it.product(range(L - k + 1), range(-delta, delta + 1))\n",
    "               if i + d + k <= L and i + d >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"ATTTAGCCACA\"\n",
    "t = \"TTTAGGCCGAT\"\n",
    "string_kernel(s, t, k=3, delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def miss(s, t):\n",
    "    \"\"\" Count the number of mismatches between two strings.\"\"\"\n",
    "    return sum((si != sj for si, sj in zip(s, t)))\n",
    "\n",
    "def string_kernel_mismatch(s, t, k=10, delta=1, m=1):\n",
    "    \"\"\" String kernel with displacement and mismatches. \"\"\"\n",
    "    L = len(s)\n",
    "    return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n",
    "                for i, d in it.product(range(L - k + 1), range(-delta, delta + 1))\n",
    "                if i + d + k <= L and i + d >= 0))\n",
    "\n",
    "string_kernel_mismatch(s,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train_.seq.values\n",
    "\n",
    "result = np.zeros((len(data),len(data)))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data)):\n",
    "        result[i][j] = string_kernel_mismatch(data[i],data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = get_data(7)[2000:,:]\n",
    "\n",
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = np.sign(model.predict(X_test_final[i]))\n",
    "    \n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_linear_overfitted.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 184kB 2.9MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 9.0MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 81kB 7.3MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 81kB 8.4MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 112kB 17.4MB/s eta 0:00:01\n",
      "\u001b[?25h  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install cvxopt -q\n",
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import os\n",
    "import optuna\n",
    "import random\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import sklearn\n",
    "\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = pd.read_csv('data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n",
    "y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Fuction will help us get the label \n",
    "\n",
    "- Label will be  0 or 1 if we use type=0\n",
    "- label will be -1 or 1 if we use type=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(type=0):\n",
    "    y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)\n",
    "    if type == 0:\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    else:\n",
    "        y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    \n",
    "get_label(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will return train-val split data using sklearns built in train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y,p):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  seq\n",
       "Id                                                   \n",
       "0   GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THE DATA \n",
    "\n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f03a0bb57f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THE DATA IS PROPORTIONAL DATA \n",
    "\n",
    "y['Bound'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f03a0ec6668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ADDITIONALLY ALL DATA CONTAINS 101 LENGTH SEQUENCES SO THERE WILL BE NO NEED OF PADDING \n",
    "\n",
    "X_train_['Count'] = X_train_.seq.apply(lambda x:len(x))\n",
    "X_train_['Count'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.01086957 0.01086957 0.01086957 0.0326087  0.01086957 0.0326087\n",
      " 0.01086957 0.         0.         0.01086957 0.0326087  0.\n",
      " 0.         0.01086957 0.02173913 0.01086957 0.01086957 0.01086957\n",
      " 0.         0.0326087  0.02173913 0.         0.         0.01086957\n",
      " 0.01086957 0.01086957 0.         0.02173913 0.         0.01086957\n",
      " 0.01086957 0.04347826 0.         0.01086957 0.01086957 0.01086957\n",
      " 0.         0.01086957 0.04347826 0.01086957 0.02173913 0.02173913\n",
      " 0.         0.         0.01086957 0.02173913 0.02173913 0.\n",
      " 0.         0.         0.         0.01086957 0.         0.0326087\n",
      " 0.01086957 0.         0.01086957 0.         0.01086957 0.02173913\n",
      " 0.         0.01086957 0.01086957 0.02173913 0.01086957 0.\n",
      " 0.01086957 0.01086957 0.01086957 0.         0.         0.\n",
      " 0.         0.         0.01086957 0.01086957 0.         0.02173913\n",
      " 0.01086957 0.         0.         0.         0.         0.\n",
      " 0.04347826 0.01086957 0.01086957 0.01086957 0.01086957 0.02173913\n",
      " 0.02173913 0.         0.         0.         0.01086957 0.\n",
      " 0.         0.02173913 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',X_train_mat100[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal encoding DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['A','C','G','T']))\n",
    "\n",
    "def ordinal_encoder(sequence):\n",
    "    integer_encoded = label_encoder.transform(np.array(list(sequence)))\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25\n",
    "    float_encoded[float_encoded == 1] = 0.50\n",
    "    float_encoded[float_encoded == 2] = 0.75\n",
    "    float_encoded[float_encoded == 3] = 1.00 \n",
    "    return float_encoded\n",
    "\n",
    "def get_ordinal_data(x_train):\n",
    "    X_list = []\n",
    "    for i in x_train:\n",
    "        X_list.append(ordinal_encoder(i))\n",
    "    return np.array(X_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.75 0.25 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.75 0.75 0.25 0.75\n",
      " 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.5  0.5  0.5  0.25 0.75 0.25\n",
      " 0.75 0.75 0.5  0.25 0.5  0.5  0.25 0.75 0.25 0.5  1.   0.5  1.   0.75\n",
      " 0.5  0.25 0.75 0.25 0.25 0.5  0.5  0.25 0.5  0.5  0.5  0.25 0.75 0.75\n",
      " 0.5  0.25 1.   1.   0.75 1.   0.75 0.75 0.75 0.75 0.5  1.   0.75 0.5\n",
      " 0.5  0.5  1.   0.75 0.5  0.5  0.25 0.5  0.5  1.   0.75 0.5  1.   0.75\n",
      " 0.75 0.5  0.5  0.75 0.5  1.   0.5  0.5  1.   0.75 0.75 1.   0.75 0.75\n",
      " 0.5  0.25 0.75]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',get_ordinal_data(X_train_.seq.values)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer counting/Spectral Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size=3):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "def get_data(kmer_size):\n",
    "    data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "    train_text = data.seq.values\n",
    "    # X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "    kmer_data = []\n",
    "    for i in train_text:\n",
    "        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))\n",
    "\n",
    "    return np.array(kmer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer / TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_grams(data,n=6):\n",
    "    cv = CountVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X\n",
    "\n",
    "def get_tf_idf_grams(data,n=6):\n",
    "    cv = TfidfVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_count_grams(X_train_.seq.values).shape\n",
    "# get_tf_idf_grams(X_train_.seq.values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=64,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))+(2*(self._lambda/len(self.train_labels ))*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(len(self.train_labels)//self.batch_size):\n",
    "                idx = list(np.random.choice(np.arange(len(self.train_labels)),self.batch_size,replace=False))\n",
    "                data = self.train_data[idx]\n",
    "                label = self.train_labels[idx]\n",
    "\n",
    "                y_pred = self.sigmoid(np.dot(data,self.params))\n",
    "                loss = self.cost(label,y_pred)\n",
    "\n",
    "                gra = self.gradient(label,y_pred,data)\n",
    "                self.params -= self.lr*gra\n",
    "\n",
    "                self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=4,batch_size=64,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_result = cross_validate(X_train_mat100,get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "ordinal_result = cross_validate(get_ordinal_data(X_train_.seq.values),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "kmer_result = cross_validate(get_data(6)[:2000,:],get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "count_result = cross_validate(get_count_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "tfidf_result = cross_validate(get_tf_idf_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_value = {'One Hot':one_hot_result,'Ordinal':ordinal_result,'K-mer':kmer_result,'Count-Vectorizer':count_result,'Tf-idf':tfidf_result}\n",
    "final_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The First Result Shows The Qualty of the data on non optimized logistic regression model this is not the best value this method can achive but it can show us the quality of the data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot === 0.483\n",
      "Ordinal === 0.49499999999999994\n",
      "K-mer === 0.607\n",
      "Count-Vectorizer === 0.624\n",
      "Tf-idf === 0.5189999999999999\n"
     ]
    }
   ],
   "source": [
    "for k,v in final_value.items():\n",
    "    print('{} === {}'.format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Related Experiments +  Kernel Related Experiments\n",
    "\n",
    "We alady implemennted Logistic regression now we will add \n",
    "\n",
    "- Ridge Regression\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2.T)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "            \n",
    "        \n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X,X,**self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,model_name,kernel=None,lambd=0.2,C=3,sigma=0.5,k=5,power=2):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        if model_name == 'KernelRidgeRegression':\n",
    "            model = KernelRidgeRegression(\n",
    "                    kernel=kernel,\n",
    "                    lambd=lambd,\n",
    "                    sigma=sigma,\n",
    "                    power=power\n",
    "                ).fit(x_train, y_train)\n",
    "            result =sum(np.sign(model.predict(x_test))==y_test)/len(y_test)#roc_auc_score(np.sign(model.predict(x_test)),y_test) #\n",
    "        elif model_name == 'logistic':\n",
    "            logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "            logistic.train()\n",
    "\n",
    "            result = logistic.evaluate(x_test,y_test)\n",
    "            \n",
    "        elif model_name == 'KernelSVM':\n",
    "\n",
    "            model = KernelSVM(C=C,\n",
    "                              kernel=kernel,\n",
    "                              lambd=lambd,\n",
    "                              sigma=sigma,\n",
    "                              power=power)\n",
    "            model.fit(x_train, y_train.flatten())\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            result = sum((y_pred.flatten()==y_test.flatten()))/len(y_test)\n",
    "            \n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c97d2b6bf3c421282b2c0e60cd6481d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-31 12:09:39,347]\u001b[0m Finished trial#0 with value: 0.6475 with parameters: {'lambd': 57.29936313868252, 'sigma': 133.83659565536783, 'k': 4, 'C': 37.822963177326265, 'power': 5, 'kmer_size': 8}. Best is trial#0 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:09:44,539]\u001b[0m Finished trial#1 with value: 0.6449999999999999 with parameters: {'lambd': 78.6974069446229, 'sigma': 87.65944090513864, 'k': 5, 'C': 27.710393443214105, 'power': 5, 'kmer_size': 7}. Best is trial#0 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:09:47,631]\u001b[0m Finished trial#2 with value: 0.5565 with parameters: {'lambd': 51.960678287145846, 'sigma': 32.76404723309095, 'k': 4, 'C': 4.941948586863563, 'power': 5, 'kmer_size': 3}. Best is trial#0 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:09:51,463]\u001b[0m Finished trial#3 with value: 0.6255 with parameters: {'lambd': 63.75964634763907, 'sigma': 61.20748185222599, 'k': 5, 'C': 4.347144671030239, 'power': 2, 'kmer_size': 6}. Best is trial#0 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:09:54,692]\u001b[0m Finished trial#4 with value: 0.5805 with parameters: {'lambd': 74.33437542405619, 'sigma': 71.52134726016476, 'k': 5, 'C': 34.31130436002631, 'power': 5, 'kmer_size': 4}. Best is trial#0 with value: 0.6475.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:00,070]\u001b[0m Finished trial#5 with value: 0.6515000000000001 with parameters: {'lambd': 34.22728439484431, 'sigma': 83.9832598466071, 'k': 4, 'C': 45.44423017858394, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:05,295]\u001b[0m Finished trial#6 with value: 0.6425000000000001 with parameters: {'lambd': 59.10163926415514, 'sigma': 104.18841189979972, 'k': 4, 'C': 16.378974868193016, 'power': 5, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:08,420]\u001b[0m Finished trial#7 with value: 0.5705 with parameters: {'lambd': 19.064930185778433, 'sigma': 77.02865268748366, 'k': 4, 'C': 9.778962068819334, 'power': 5, 'kmer_size': 3}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:11,611]\u001b[0m Finished trial#8 with value: 0.589 with parameters: {'lambd': 32.06886415448222, 'sigma': 60.70023701645993, 'k': 4, 'C': 20.773735364171728, 'power': 5, 'kmer_size': 4}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:22,768]\u001b[0m Finished trial#9 with value: 0.646 with parameters: {'lambd': 29.58479353356675, 'sigma': 108.05278898685356, 'k': 4, 'C': 41.97082099527873, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:26,382]\u001b[0m Finished trial#10 with value: 0.529 with parameters: {'lambd': 0.6544975792115437, 'sigma': 4.563649078505151, 'k': 8, 'C': 44.64055151374951, 'power': 3, 'kmer_size': 6}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:35,986]\u001b[0m Finished trial#11 with value: 0.552 with parameters: {'lambd': 93.7958544250831, 'sigma': 149.7904919481347, 'k': 8, 'C': 49.11221258227899, 'power': 3, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:41,394]\u001b[0m Finished trial#12 with value: 0.644 with parameters: {'lambd': 40.02384591803529, 'sigma': 143.1548573406927, 'k': 4, 'C': 36.98073324160221, 'power': 4, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:52,492]\u001b[0m Finished trial#13 with value: 0.647 with parameters: {'lambd': 9.963437404048712, 'sigma': 125.6965587470246, 'k': 4, 'C': 49.81022628410453, 'power': 4, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:10:57,743]\u001b[0m Finished trial#14 with value: 0.6345000000000001 with parameters: {'lambd': 42.56877836383444, 'sigma': 37.16220397525454, 'k': 4, 'C': 32.95832629620581, 'power': 3, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:11:00,632]\u001b[0m Finished trial#15 with value: 0.5795 with parameters: {'lambd': 22.305950215628464, 'sigma': 128.04380802421394, 'k': 8, 'C': 41.343389201044225, 'power': 4, 'kmer_size': 5}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:11:11,977]\u001b[0m Finished trial#16 with value: 0.6485000000000001 with parameters: {'lambd': 70.07346085568591, 'sigma': 100.93858021529905, 'k': 4, 'C': 27.079861281523822, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:11:15,885]\u001b[0m Finished trial#17 with value: 0.6244999999999999 with parameters: {'lambd': 92.00135321025745, 'sigma': 101.03690151729054, 'k': 4, 'C': 27.63475254944127, 'power': 2, 'kmer_size': 6}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:11:21,283]\u001b[0m Finished trial#18 with value: 0.641 with parameters: {'lambd': 72.90151482617945, 'sigma': 91.82402159128644, 'k': 4, 'C': 14.38146842033727, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:11:32,736]\u001b[0m Finished trial#19 with value: 0.6455 with parameters: {'lambd': 45.08375776462292, 'sigma': 113.15478812345567, 'k': 4, 'C': 19.915875730127304, 'power': 3, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:11:35,796]\u001b[0m Finished trial#20 with value: 0.5850000000000001 with parameters: {'lambd': 84.55142115903018, 'sigma': 48.797494290618125, 'k': 8, 'C': 24.449887198056217, 'power': 2, 'kmer_size': 5}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:11:47,002]\u001b[0m Finished trial#21 with value: 0.648 with parameters: {'lambd': 61.21134028753922, 'sigma': 127.13246536257455, 'k': 4, 'C': 37.09374687628815, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:11:58,449]\u001b[0m Finished trial#22 with value: 0.648 with parameters: {'lambd': 67.10746255549557, 'sigma': 117.591783608582, 'k': 4, 'C': 31.706251163561525, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:12:03,979]\u001b[0m Finished trial#23 with value: 0.645 with parameters: {'lambd': 66.98532808834148, 'sigma': 89.64042265844436, 'k': 4, 'C': 29.809587346713478, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:12:15,311]\u001b[0m Finished trial#24 with value: 0.647 with parameters: {'lambd': 48.54741679051735, 'sigma': 139.78716322918805, 'k': 4, 'C': 45.930959177235955, 'power': 3, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:12:20,638]\u001b[0m Finished trial#25 with value: 0.6435000000000001 with parameters: {'lambd': 31.652938942594734, 'sigma': 119.217426554339, 'k': 5, 'C': 23.105903016997395, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:12:24,508]\u001b[0m Finished trial#26 with value: 0.6275000000000001 with parameters: {'lambd': 85.0090866957431, 'sigma': 80.63794038968715, 'k': 4, 'C': 31.44040809330027, 'power': 2, 'kmer_size': 6}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:12:35,685]\u001b[0m Finished trial#27 with value: 0.6475000000000001 with parameters: {'lambd': 69.98316866389365, 'sigma': 93.49415336238732, 'k': 4, 'C': 27.19385161997362, 'power': 3, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:12:41,016]\u001b[0m Finished trial#28 with value: 0.646 with parameters: {'lambd': 53.819794165544955, 'sigma': 115.91279385499392, 'k': 4, 'C': 41.25426228918992, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:12:52,555]\u001b[0m Finished trial#29 with value: 0.645 with parameters: {'lambd': 80.17377703564343, 'sigma': 99.85723787444776, 'k': 4, 'C': 16.882061569536305, 'power': 3, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:04,039]\u001b[0m Finished trial#30 with value: 0.649 with parameters: {'lambd': 39.05337782542519, 'sigma': 68.22403162792365, 'k': 4, 'C': 34.544620418233286, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:15,140]\u001b[0m Finished trial#31 with value: 0.646 with parameters: {'lambd': 41.64637569003762, 'sigma': 73.78375930756603, 'k': 4, 'C': 35.086510984486864, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:26,468]\u001b[0m Finished trial#32 with value: 0.649 with parameters: {'lambd': 24.680582294483965, 'sigma': 61.55858317137891, 'k': 4, 'C': 29.24036462201957, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:31,938]\u001b[0m Finished trial#33 with value: 0.649 with parameters: {'lambd': 21.906535109080036, 'sigma': 62.1802693451255, 'k': 4, 'C': 28.557612445885116, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:37,243]\u001b[0m Finished trial#34 with value: 0.6424999999999998 with parameters: {'lambd': 15.509539209261256, 'sigma': 60.87235618755239, 'k': 5, 'C': 29.786019736681848, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:40,972]\u001b[0m Finished trial#35 with value: 0.6285 with parameters: {'lambd': 24.735416527308466, 'sigma': 46.60245572537018, 'k': 4, 'C': 39.34662640347416, 'power': 2, 'kmer_size': 6}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:46,282]\u001b[0m Finished trial#36 with value: 0.5275000000000001 with parameters: {'lambd': 8.066465117476099, 'sigma': 19.649636665302324, 'k': 5, 'C': 0.27669100520294876, 'power': 3, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:50,089]\u001b[0m Finished trial#37 with value: 0.62 with parameters: {'lambd': 38.21900553083365, 'sigma': 66.42967656559729, 'k': 4, 'C': 46.66107033567166, 'power': 2, 'kmer_size': 6}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:55,574]\u001b[0m Finished trial#38 with value: 0.641 with parameters: {'lambd': 35.17568016184056, 'sigma': 51.943577273116446, 'k': 4, 'C': 35.39176344640508, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:13:58,959]\u001b[0m Finished trial#39 with value: 0.5995 with parameters: {'lambd': 25.205815119094133, 'sigma': 81.70475206648759, 'k': 4, 'C': 22.381311354268803, 'power': 3, 'kmer_size': 5}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:14:04,321]\u001b[0m Finished trial#40 with value: 0.6345000000000001 with parameters: {'lambd': 10.373060307776399, 'sigma': 39.242141439446854, 'k': 4, 'C': 29.58499692386554, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:14:15,687]\u001b[0m Finished trial#41 with value: 0.6465 with parameters: {'lambd': 28.16992894348869, 'sigma': 69.19213082167612, 'k': 4, 'C': 26.545194891963405, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:14:26,931]\u001b[0m Finished trial#42 with value: 0.644 with parameters: {'lambd': 18.228023442305506, 'sigma': 82.00080464873966, 'k': 4, 'C': 26.10685354330856, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:14:38,282]\u001b[0m Finished trial#43 with value: 0.6445000000000001 with parameters: {'lambd': 54.08562338619209, 'sigma': 52.74395126612597, 'k': 4, 'C': 18.79470474845555, 'power': 2, 'kmer_size': 8}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:14:43,638]\u001b[0m Finished trial#44 with value: 0.6495000000000001 with parameters: {'lambd': 35.43071461176121, 'sigma': 58.555304562377664, 'k': 4, 'C': 25.042393750797437, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:14:47,061]\u001b[0m Finished trial#45 with value: 0.6165 with parameters: {'lambd': 35.74735099129254, 'sigma': 63.43724655016108, 'k': 8, 'C': 23.853029625358765, 'power': 2, 'kmer_size': 6}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:14:52,533]\u001b[0m Finished trial#46 with value: 0.6325000000000001 with parameters: {'lambd': 46.03611117018528, 'sigma': 27.250276262909118, 'k': 4, 'C': 33.11828171911014, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:14:57,933]\u001b[0m Finished trial#47 with value: 0.647 with parameters: {'lambd': 2.03431552803972, 'sigma': 58.06030580507414, 'k': 4, 'C': 11.76623846119853, 'power': 3, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:03,043]\u001b[0m Finished trial#48 with value: 0.6399999999999999 with parameters: {'lambd': 20.553233363209007, 'sigma': 73.31946660468168, 'k': 5, 'C': 38.521820449589214, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:06,935]\u001b[0m Finished trial#49 with value: 0.6234999999999999 with parameters: {'lambd': 14.482449959771301, 'sigma': 42.37448219000916, 'k': 4, 'C': 43.66971707032625, 'power': 3, 'kmer_size': 6}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:12,357]\u001b[0m Finished trial#50 with value: 0.6515 with parameters: {'lambd': 28.663062538093655, 'sigma': 55.27647334735712, 'k': 4, 'C': 21.306013296786862, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:17,717]\u001b[0m Finished trial#51 with value: 0.6515000000000001 with parameters: {'lambd': 28.780188809900377, 'sigma': 57.959804626963226, 'k': 4, 'C': 21.336290271017084, 'power': 2, 'kmer_size': 7}. Best is trial#5 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:23,053]\u001b[0m Finished trial#52 with value: 0.6525000000000001 with parameters: {'lambd': 28.983722418352965, 'sigma': 57.36809121219816, 'k': 4, 'C': 21.64458611629817, 'power': 2, 'kmer_size': 7}. Best is trial#52 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:28,241]\u001b[0m Finished trial#53 with value: 0.652 with parameters: {'lambd': 30.819862325036063, 'sigma': 55.00659382614578, 'k': 4, 'C': 21.393927768233127, 'power': 2, 'kmer_size': 7}. Best is trial#52 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:33,544]\u001b[0m Finished trial#54 with value: 0.653 with parameters: {'lambd': 29.346442978065113, 'sigma': 55.940987647384205, 'k': 4, 'C': 21.365762537232836, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:36,945]\u001b[0m Finished trial#55 with value: 0.62 with parameters: {'lambd': 29.744764013894127, 'sigma': 31.580296371516237, 'k': 8, 'C': 20.858451908620708, 'power': 2, 'kmer_size': 6}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:42,425]\u001b[0m Finished trial#56 with value: 0.6525 with parameters: {'lambd': 29.29697671972522, 'sigma': 53.03062946215468, 'k': 4, 'C': 17.693559926924912, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:47,984]\u001b[0m Finished trial#57 with value: 0.653 with parameters: {'lambd': 32.91598653089755, 'sigma': 45.600422249771015, 'k': 4, 'C': 14.611283463193935, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:51,854]\u001b[0m Finished trial#58 with value: 0.6234999999999999 with parameters: {'lambd': 32.04068270331079, 'sigma': 19.600820190945782, 'k': 4, 'C': 14.393373680472935, 'power': 2, 'kmer_size': 6}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:15:57,209]\u001b[0m Finished trial#59 with value: 0.645 with parameters: {'lambd': 49.49987820348584, 'sigma': 45.936021224042946, 'k': 4, 'C': 9.968679361987359, 'power': 4, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:00,961]\u001b[0m Finished trial#60 with value: 0.6204999999999999 with parameters: {'lambd': 33.62551270535817, 'sigma': 35.33658411671442, 'k': 4, 'C': 17.714033230456106, 'power': 2, 'kmer_size': 6}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:06,234]\u001b[0m Finished trial#61 with value: 0.642 with parameters: {'lambd': 26.33943417049883, 'sigma': 42.08482453283165, 'k': 4, 'C': 14.666412317067348, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:11,511]\u001b[0m Finished trial#62 with value: 0.6525 with parameters: {'lambd': 43.65320982407638, 'sigma': 51.24560594081654, 'k': 4, 'C': 18.761176689541312, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:16,957]\u001b[0m Finished trial#63 with value: 0.652 with parameters: {'lambd': 41.7924101539889, 'sigma': 47.431441399286555, 'k': 4, 'C': 12.297911842687052, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:22,372]\u001b[0m Finished trial#64 with value: 0.6465000000000001 with parameters: {'lambd': 45.111884890779784, 'sigma': 50.513785663683464, 'k': 4, 'C': 6.88495087394826, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:27,793]\u001b[0m Finished trial#65 with value: 0.6415 with parameters: {'lambd': 38.687747703179824, 'sigma': 29.897840145851475, 'k': 4, 'C': 12.314058484146749, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:31,079]\u001b[0m Finished trial#66 with value: 0.583 with parameters: {'lambd': 42.665788034684454, 'sigma': 45.53687026692462, 'k': 4, 'C': 19.085692373482896, 'power': 2, 'kmer_size': 4}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:36,427]\u001b[0m Finished trial#67 with value: 0.6355000000000001 with parameters: {'lambd': 56.88265188286985, 'sigma': 24.840287419467277, 'k': 4, 'C': 15.827566595860544, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:41,716]\u001b[0m Finished trial#68 with value: 0.645 with parameters: {'lambd': 37.32469231506248, 'sigma': 39.43476414307679, 'k': 4, 'C': 12.56446266552975, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:46,609]\u001b[0m Finished trial#69 with value: 0.6025 with parameters: {'lambd': 41.37136726641753, 'sigma': 55.37188557839598, 'k': 8, 'C': 7.072606674082973, 'power': 3, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:50,374]\u001b[0m Finished trial#70 with value: 0.628 with parameters: {'lambd': 31.787297325116853, 'sigma': 77.69694803369526, 'k': 4, 'C': 17.749294382334277, 'power': 2, 'kmer_size': 6}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:16:55,604]\u001b[0m Finished trial#71 with value: 0.644 with parameters: {'lambd': 26.713530661117435, 'sigma': 49.57201890693304, 'k': 4, 'C': 22.22952571797744, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:00,943]\u001b[0m Finished trial#72 with value: 0.649 with parameters: {'lambd': 30.03601793851729, 'sigma': 56.685815509504245, 'k': 4, 'C': 15.894583807003235, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:06,331]\u001b[0m Finished trial#73 with value: 0.646 with parameters: {'lambd': 23.183773879137476, 'sigma': 65.22510938413858, 'k': 4, 'C': 19.379641288766994, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:11,652]\u001b[0m Finished trial#74 with value: 0.6435000000000001 with parameters: {'lambd': 48.132336098737184, 'sigma': 35.04582094879524, 'k': 4, 'C': 10.77408339912462, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:16,977]\u001b[0m Finished trial#75 with value: 0.641 with parameters: {'lambd': 33.51548450876447, 'sigma': 86.41527072048123, 'k': 4, 'C': 13.209695923613415, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:22,353]\u001b[0m Finished trial#76 with value: 0.64 with parameters: {'lambd': 19.353267450357894, 'sigma': 42.22091364514327, 'k': 4, 'C': 20.18611317674189, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:26,131]\u001b[0m Finished trial#77 with value: 0.6245 with parameters: {'lambd': 43.54974257734859, 'sigma': 70.49186101075568, 'k': 5, 'C': 17.34114547537656, 'power': 2, 'kmer_size': 6}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:31,464]\u001b[0m Finished trial#78 with value: 0.646 with parameters: {'lambd': 16.254441588058658, 'sigma': 53.0394107829789, 'k': 4, 'C': 22.072824609251423, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:36,850]\u001b[0m Finished trial#79 with value: 0.645 with parameters: {'lambd': 36.92475121322659, 'sigma': 48.627339583934244, 'k': 4, 'C': 23.554694327563993, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:48,256]\u001b[0m Finished trial#80 with value: 0.6435000000000001 with parameters: {'lambd': 51.44267910946235, 'sigma': 44.859095351044, 'k': 4, 'C': 8.684881033059522, 'power': 2, 'kmer_size': 8}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:53,677]\u001b[0m Finished trial#81 with value: 0.651 with parameters: {'lambd': 33.70102916702838, 'sigma': 60.53369269671734, 'k': 4, 'C': 18.339825270052366, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:17:59,112]\u001b[0m Finished trial#82 with value: 0.645 with parameters: {'lambd': 27.52271783462975, 'sigma': 65.65381559390714, 'k': 4, 'C': 16.360135528104188, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:02,516]\u001b[0m Finished trial#83 with value: 0.5525 with parameters: {'lambd': 40.34034029051778, 'sigma': 53.318569701106135, 'k': 4, 'C': 20.457766151943225, 'power': 2, 'kmer_size': 3}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:07,834]\u001b[0m Finished trial#84 with value: 0.6455 with parameters: {'lambd': 23.362155771038047, 'sigma': 57.70306349332197, 'k': 4, 'C': 15.045133817030166, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:13,197]\u001b[0m Finished trial#85 with value: 0.647 with parameters: {'lambd': 30.01442291909885, 'sigma': 69.7261748249118, 'k': 4, 'C': 13.345191595711851, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:24,541]\u001b[0m Finished trial#86 with value: 0.6445 with parameters: {'lambd': 46.825199042283735, 'sigma': 75.92115717395387, 'k': 4, 'C': 25.475151153701443, 'power': 2, 'kmer_size': 8}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:29,790]\u001b[0m Finished trial#87 with value: 0.6365000000000001 with parameters: {'lambd': 39.28537699164524, 'sigma': 37.783887880364894, 'k': 4, 'C': 23.074974011174746, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:33,657]\u001b[0m Finished trial#88 with value: 0.6265 with parameters: {'lambd': 35.35957679222531, 'sigma': 64.07261412704187, 'k': 4, 'C': 24.48392868259262, 'power': 5, 'kmer_size': 6}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:39,124]\u001b[0m Finished trial#89 with value: 0.6495000000000001 with parameters: {'lambd': 33.25645342456167, 'sigma': 94.67766349230845, 'k': 4, 'C': 21.503085515745553, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:44,398]\u001b[0m Finished trial#90 with value: 0.647 with parameters: {'lambd': 31.246701918371933, 'sigma': 86.06661334686596, 'k': 4, 'C': 19.465071213336223, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:49,777]\u001b[0m Finished trial#91 with value: 0.6495000000000001 with parameters: {'lambd': 27.904363602365905, 'sigma': 54.155679922641085, 'k': 4, 'C': 21.289373285092594, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:18:55,025]\u001b[0m Finished trial#92 with value: 0.6495 with parameters: {'lambd': 24.53715901980927, 'sigma': 49.6175641329742, 'k': 4, 'C': 18.284422449231645, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:19:00,242]\u001b[0m Finished trial#93 with value: 0.652 with parameters: {'lambd': 21.855029145775763, 'sigma': 58.896402452786575, 'k': 4, 'C': 22.88583644648303, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:19:05,478]\u001b[0m Finished trial#94 with value: 0.645 with parameters: {'lambd': 22.05415030930064, 'sigma': 59.461689934641875, 'k': 4, 'C': 28.030903343859993, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:19:10,599]\u001b[0m Finished trial#95 with value: 0.6455000000000001 with parameters: {'lambd': 36.70958575567444, 'sigma': 47.04633406493407, 'k': 4, 'C': 23.116901369052748, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:19:20,016]\u001b[0m Finished trial#96 with value: 0.6335 with parameters: {'lambd': 18.429508217281708, 'sigma': 43.97527230541395, 'k': 8, 'C': 25.807976600564366, 'power': 2, 'kmer_size': 8}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:19:25,236]\u001b[0m Finished trial#97 with value: 0.6439999999999999 with parameters: {'lambd': 43.797745677502746, 'sigma': 67.32185064562485, 'k': 5, 'C': 20.411293985926502, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:19:29,084]\u001b[0m Finished trial#98 with value: 0.6285000000000001 with parameters: {'lambd': 25.766853886033452, 'sigma': 72.46372756942472, 'k': 4, 'C': 17.12979786421409, 'power': 2, 'kmer_size': 6}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-31 12:19:34,261]\u001b[0m Finished trial#99 with value: 0.6505 with parameters: {'lambd': 11.253930916663464, 'sigma': 61.533744787703554, 'k': 4, 'C': 24.44708139212889, 'power': 2, 'kmer_size': 7}. Best is trial#54 with value: 0.653.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    lambd = trial.suggest_float('lambd', 1e-5, 100.0)\n",
    "    sigma = trial.suggest_float('sigma', 1e-5, 150)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8])\n",
    "    C =  trial.suggest_float('C', 0.1,50)\n",
    "    power =  trial.suggest_int('power', 2,5)\n",
    "    kmer_size =  trial.suggest_int('kmer_size', 3,8)\n",
    "#     kernel =  trial.suggest_categorical('kernel', ['linear','rbf','gaussian_kernel','polynomial'])\n",
    "#     model_name\n",
    "    \n",
    "    return cross_validate(get_data(kmer_size)[:2000,:],get_label(type=-1),model_name='KernelSVM',C=C,kernel='rbf',lambd=lambd,k=k,sigma=sigma,power=power)\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=100,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_C</th>\n",
       "      <th>params_k</th>\n",
       "      <th>params_kmer_size</th>\n",
       "      <th>params_lambd</th>\n",
       "      <th>params_power</th>\n",
       "      <th>params_sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.813522</td>\n",
       "      <td>8.248775</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17.301090</td>\n",
       "      <td>4</td>\n",
       "      <td>146.609194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.783201</td>\n",
       "      <td>8.919157</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>53.676539</td>\n",
       "      <td>4</td>\n",
       "      <td>149.774884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.757593</td>\n",
       "      <td>1.913072</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>57.461627</td>\n",
       "      <td>4</td>\n",
       "      <td>141.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.851084</td>\n",
       "      <td>9.659551</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>44.494240</td>\n",
       "      <td>4</td>\n",
       "      <td>148.703867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.624978</td>\n",
       "      <td>9.406092</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>48.325640</td>\n",
       "      <td>4</td>\n",
       "      <td>149.884371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.767435</td>\n",
       "      <td>8.055669</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>22.696237</td>\n",
       "      <td>4</td>\n",
       "      <td>144.124837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>00:00:08.438371</td>\n",
       "      <td>10.791498</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>52.239587</td>\n",
       "      <td>4</td>\n",
       "      <td>74.078190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number   value        duration  ...  params_lambd  params_power  params_sigma\n",
       "79      79  0.6525 00:00:08.813522  ...     17.301090             4    146.609194\n",
       "63      63  0.6525 00:00:08.783201  ...     53.676539             4    149.774884\n",
       "64      64  0.6525 00:00:08.757593  ...     57.461627             4    141.798933\n",
       "69      69  0.6525 00:00:08.851084  ...     44.494240             4    148.703867\n",
       "74      74  0.6525 00:00:08.624978  ...     48.325640             4    149.884371\n",
       "71      71  0.6525 00:00:08.767435  ...     22.696237             4    144.124837\n",
       "99      99  0.6525 00:00:08.438371  ...     52.239587             4     74.078190\n",
       "\n",
       "[7 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.sort_values(by=['value']).tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              value\t\tparams_C\tparams_k\tparams_kmer_size\tparams_lambd\tparams_power\tparams_sigma\n",
    "\n",
    "\n",
    "linear  -     0.6520\t   47.102628\t    4\t     7\t    0.756909\t    3\t       15.369069\n",
    "rbf           0.6470\t00:00:04.427092\t9.071834\t5\t7\t77.976361\t4\t3.775633\n",
    "polinomial    0.6585\t00:00:03.992723\t27.187947\t4\t7\t1.418356\t2\n",
    "\n",
    "\n",
    "svm\n",
    "\n",
    "linear        0.6525\t00:00:08.438371\t10.791498\t5\t8\t52.239587\t4\t74.078190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 65536) (20, 65536) (1980, 1) (20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test  = get_train_test(get_data(8)[:2000,:],get_label(type=-1).reshape(-1,1),p=0.01)\n",
    "\n",
    "\n",
    "kernel = 'rbf'\n",
    "power = 3\n",
    "sigma = 12.217523\n",
    "C = 9.839876\n",
    "lambd = 38.202739\n",
    "model = KernelSVM(C=C, kernel=kernel, sigma=sigma,lambd=lambd, power=power)\n",
    "model.fit(X_train, y_train.flatten())\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "sum(y_pred.flatten()==y_test.flatten())/len(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(get_data(8)[:2000,:],get_label(type=-1),\n",
    "               model_name='KernelSVM',\n",
    "               kernel = 'rbf',\n",
    "               k=4,\n",
    "                power = 3,\n",
    "                sigma = 12.217523,\n",
    "                C = 9.839876,\n",
    "                lambd = 38.202739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def miss(s, t):\n",
    "    \"\"\" Count the number of mismatches between two strings.\"\"\"\n",
    "    return sum((si != sj for si, sj in zip(s, t)))\n",
    "\n",
    "def string_kernel_mismatch(s, t, k=10, delta=1, m=1):\n",
    "    \"\"\" String kernel with displacement and mismatches. \"\"\"\n",
    "    L = len(s)\n",
    "    return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n",
    "                for i, d in it.product(range(L - k + 1), range(-delta, delta + 1))\n",
    "                if i + d + k <= L and i + d >= 0))\n",
    "\n",
    "string_kernel_mismatch(s,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-a355b2ec373b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_kernel_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-191-8798ade79624>\u001b[0m in \u001b[0;36mstring_kernel_mismatch\u001b[0;34m(s, t, k, delta, m)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 if i + d + k <= L and i + d >= 0))\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-191-8798ade79624>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     return sum(((miss(s[i:i + k], t[d + i:d + i + k]) <= m)\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 if i + d + k <= L and i + d >= 0))\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstring_kernel_mismatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = get_data(8)[:2000,:]\n",
    "\n",
    "result = np.zeros((len(data),len(data)))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data)):\n",
    "        result[i][j] = string_kernel_mismatch(data[i],data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "        1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,\n",
       "        1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
       "        1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "        1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "        1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "        1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "       -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "        1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "       -1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Bound\n",
       "0    0      1\n",
       "1    1      1\n",
       "2    2      0\n",
       "3    3      0\n",
       "4    4      1\n",
       "5    5      1\n",
       "6    6      1\n",
       "7    7      0\n",
       "8    8      1\n",
       "9    9      1\n",
       "10  10      1\n",
       "11  11      1\n",
       "12  12      1\n",
       "13  13      1\n",
       "14  14      0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final  = model.predict(get_data(8)[2000:,:])\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = X_test_final[i]\n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_rbf-svm.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-145189adb853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msumbission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-80a06a324978>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-164-80a06a324978>\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mK_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_function_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mK_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e25f7751f78e>\u001b[0m in \u001b[0;36mrbf_kernel\u001b[0;34m(X1, X2, sigma)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mX1_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX1_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX2_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "X_test_final = get_data(8)[2000:,:]\n",
    "\n",
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = model.predict(X_test_final[i])\n",
    "    \n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_linear_overfitted.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cvxopt -q\n",
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import os\n",
    "import optuna\n",
    "import random\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import sklearn\n",
    "\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = pd.read_csv('data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Fuction will help us get the label \n",
    "\n",
    "- Label will be  0 or 1 if we use type=0\n",
    "- label will be -1 or 1 if we use type=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(type=0):\n",
    "    y = pd.read_csv('data/Ytr.csv',sep=',',index_col=0)\n",
    "    if type == 0:\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    else:\n",
    "        y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "        y = y.Bound.values\n",
    "        return y\n",
    "    \n",
    "get_label(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will return train-val split data using sklearns built in train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y,p):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  seq\n",
       "Id                                                   \n",
       "0   GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THE DATA \n",
    "\n",
    "X_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f697aecfeb8>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAMV0lEQVR4nO3dbYil5X3H8e+vbk2bBFwfhsXsrl3BbYItlMhgLEIp2ZKoKV1fJGIocZGFfWPapBbqtm+E9o1CqY1QhCVru0IwERtwSSVBVqWUonVMxES3qYON7i4+TOJqHyQkNv++mEsymey67pzxjJn/9wPDue/rvs65r4HlOzf3nDObqkKS1MMvrfUCJEnTY/QlqRGjL0mNGH1JasToS1IjRl+SGtmw1gt4K+edd15t27ZtrZchSb9QHn/88e9X1cyJjr2ro79t2zbm5ubWehmS9AslyXMnO+btHUlqxOhLUiNGX5IaMfqS1IjRl6RGThn9JHcmeTnJd5aMnZPkgSTPjMezx3iS3J5kPsmTSS5Z8pxdY/4zSXa9M9+OJOmtvJ0r/X8Arlg2thc4VFXbgUNjH+BKYPv42gPcAYs/JICbgY8AlwI3v/mDQpI0PaeMflX9M/DKsuGdwIGxfQC4esn4XbXoEWBjkvOBjwMPVNUrVXUceICf/0EiSXqHrfTDWZuq6oWx/SKwaWxvBo4smXd0jJ1sfF3Ytvef1noJ68r3bvnEWi9BWrcm/kRuVVWSVfvvt5LsYfHWEBdccMFqvazUlhclq2c9XJCs9N07L43bNozHl8f4MWDrknlbxtjJxn9OVe2rqtmqmp2ZOeGfjpAkrdBKo38QePMdOLuA+5aMXzfexXMZ8Nq4DfQN4GNJzh6/wP3YGJMkTdEpb+8kuRv4XeC8JEdZfBfOLcA9SXYDzwHXjOn3A1cB88DrwPUAVfVKkr8CHhvz/rKqlv9yWJL0Djtl9Kvq0yc5tOMEcwu44SSvcydw52mtTpK0qvxEriQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRiaKfpI/SfJUku8kuTvJryS5MMmjSeaTfCXJmWPue8b+/Di+bTW+AUnS27fi6CfZDPwxMFtVvwmcAVwL3ArcVlUXAceB3eMpu4HjY/y2MU+SNEWT3t7ZAPxqkg3Ae4EXgI8C947jB4Crx/bOsc84viNJJjy/JOk0rDj6VXUM+GvgeRZj/xrwOPBqVb0xph0FNo/tzcCR8dw3xvxzV3p+SdLpm+T2ztksXr1fCHwAeB9wxaQLSrInyVySuYWFhUlfTpK0xCS3d34P+M+qWqiqHwNfBS4HNo7bPQBbgGNj+xiwFWAcPwv4wfIXrap9VTVbVbMzMzMTLE+StNwk0X8euCzJe8e9+R3A08BDwCfHnF3AfWP74NhnHH+wqmqC80uSTtMk9/QfZfEXst8Evj1eax9wE3BjknkW79nvH0/ZD5w7xm8E9k6wbknSCmw49ZSTq6qbgZuXDT8LXHqCuT8EPjXJ+SRJk/ETuZLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktTIRNFPsjHJvUn+PcnhJL+d5JwkDyR5ZjyePeYmye1J5pM8meSS1fkWJElv16RX+l8Avl5VHwJ+CzgM7AUOVdV24NDYB7gS2D6+9gB3THhuSdJpWnH0k5wF/A6wH6CqflRVrwI7gQNj2gHg6rG9E7irFj0CbExy/opXLkk6bZNc6V8ILAB/n+RbSb6Y5H3Apqp6Ycx5Edg0tjcDR5Y8/+gY+xlJ9iSZSzK3sLAwwfIkSctNEv0NwCXAHVX1YeB/+emtHACqqoA6nRetqn1VNVtVszMzMxMsT5K03CTRPwocrapHx/69LP4QeOnN2zbj8eVx/Biwdcnzt4wxSdKUrDj6VfUicCTJB8fQDuBp4CCwa4ztAu4b2weB68a7eC4DXltyG0iSNAUbJnz+HwFfSnIm8CxwPYs/SO5Jsht4DrhmzL0fuAqYB14fcyVJUzRR9KvqCWD2BId2nGBuATdMcj5J0mT8RK4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEYmjn6SM5J8K8nXxv6FSR5NMp/kK0nOHOPvGfvz4/i2Sc8tSTo9q3Gl/zng8JL9W4Hbquoi4Diwe4zvBo6P8dvGPEnSFE0U/SRbgE8AXxz7AT4K3DumHACuHts7xz7j+I4xX5I0JZNe6f8t8GfAT8b+ucCrVfXG2D8KbB7bm4EjAOP4a2O+JGlKVhz9JL8PvFxVj6/iekiyJ8lckrmFhYXVfGlJam+SK/3LgT9I8j3gyyze1vkCsDHJhjFnC3BsbB8DtgKM42cBP1j+olW1r6pmq2p2ZmZmguVJkpZbcfSr6s+raktVbQOuBR6sqj8EHgI+OabtAu4b2wfHPuP4g1VVKz2/JOn0vRPv078JuDHJPIv37PeP8f3AuWP8RmDvO3BuSdJb2HDqKadWVQ8DD4/tZ4FLTzDnh8CnVuN8kqSV8RO5ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaWXH0k2xN8lCSp5M8leRzY/ycJA8keWY8nj3Gk+T2JPNJnkxyyWp9E5Kkt2eSK/03gD+tqouBy4AbklwM7AUOVdV24NDYB7gS2D6+9gB3THBuSdIKrDj6VfVCVX1zbP83cBjYDOwEDoxpB4Crx/ZO4K5a9AiwMcn5K165JOm0rco9/STbgA8DjwKbquqFcehFYNPY3gwcWfK0o2NMkjQlE0c/yfuBfwQ+X1X/tfRYVRVQp/l6e5LMJZlbWFiYdHmSpCUmin6SX2Yx+F+qqq+O4ZfevG0zHl8e48eArUuevmWM/Yyq2ldVs1U1OzMzM8nyJEnLTPLunQD7gcNV9TdLDh0Edo3tXcB9S8avG+/iuQx4bcltIEnSFGyY4LmXA58Bvp3kiTH2F8AtwD1JdgPPAdeMY/cDVwHzwOvA9ROcW5K0AiuOflX9C5CTHN5xgvkF3LDS80mSJucnciWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JakRoy9JjRh9SWrE6EtSI0Zfkhox+pLUiNGXpEaMviQ1YvQlqRGjL0mNGH1JasToS1IjRl+SGjH6ktSI0ZekRoy+JDVi9CWpEaMvSY0YfUlqxOhLUiNGX5IaMfqS1IjRl6RGjL4kNWL0JamRqUc/yRVJvptkPsneaZ9fkjqbavSTnAH8HXAlcDHw6SQXT3MNktTZtK/0LwXmq+rZqvoR8GVg55TXIEltbZjy+TYDR5bsHwU+snRCkj3AnrH7P0m+O6W1dXAe8P21XsSp5Na1XoHWgP82V9evnezAtKN/SlW1D9i31utYj5LMVdXsWq9DWs5/m9Mz7ds7x4CtS/a3jDFJ0hRMO/qPAduTXJjkTOBa4OCU1yBJbU319k5VvZHks8A3gDOAO6vqqWmuoTlvm+ndyn+bU5KqWus1SJKmxE/kSlIjRl+SGjH6ktTIu+59+lo9ST7E4ieeN4+hY8DBqjq8dquStJa80l+nktzE4p+5CPBv4yvA3f6hO72bJbl+rdewnvnunXUqyX8Av1FVP142fibwVFVtX5uVSW8tyfNVdcFar2O98vbO+vUT4APAc8vGzx/HpDWT5MmTHQI2TXMt3Rj99evzwKEkz/DTP3J3AXAR8Nk1W5W0aBPwceD4svEA/zr95fRh9Nepqvp6kl9n8c9ZL/1F7mNV9X9rtzIJgK8B76+qJ5YfSPLw9JfTh/f0JakR370jSY0YfUlqxOhLUiNGX5IaMfqS1Mj/A1DAsx/0YMj3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THE DATA IS PROPORTIONAL DATA \n",
    "\n",
    "y['Bound'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f697ae61390>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ADDITIONALLY ALL DATA CONTAINS 101 LENGTH SEQUENCES SO THERE WILL BE NO NEED OF PADDING \n",
    "\n",
    "X_train_['Count'] = X_train_.seq.apply(lambda x:len(x))\n",
    "X_train_['Count'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.01086957 0.01086957 0.01086957 0.0326087  0.01086957 0.0326087\n",
      " 0.01086957 0.         0.         0.01086957 0.0326087  0.\n",
      " 0.         0.01086957 0.02173913 0.01086957 0.01086957 0.01086957\n",
      " 0.         0.0326087  0.02173913 0.         0.         0.01086957\n",
      " 0.01086957 0.01086957 0.         0.02173913 0.         0.01086957\n",
      " 0.01086957 0.04347826 0.         0.01086957 0.01086957 0.01086957\n",
      " 0.         0.01086957 0.04347826 0.01086957 0.02173913 0.02173913\n",
      " 0.         0.         0.01086957 0.02173913 0.02173913 0.\n",
      " 0.         0.         0.         0.01086957 0.         0.0326087\n",
      " 0.01086957 0.         0.01086957 0.         0.01086957 0.02173913\n",
      " 0.         0.01086957 0.01086957 0.02173913 0.01086957 0.\n",
      " 0.01086957 0.01086957 0.01086957 0.         0.         0.\n",
      " 0.         0.         0.01086957 0.01086957 0.         0.02173913\n",
      " 0.01086957 0.         0.         0.         0.         0.\n",
      " 0.04347826 0.01086957 0.01086957 0.01086957 0.01086957 0.02173913\n",
      " 0.02173913 0.         0.         0.         0.01086957 0.\n",
      " 0.         0.02173913 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',X_train_mat100[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal encoding DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['A','C','G','T']))\n",
    "\n",
    "def ordinal_encoder(sequence):\n",
    "    integer_encoded = label_encoder.transform(np.array(list(sequence)))\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25\n",
    "    float_encoded[float_encoded == 1] = 0.50\n",
    "    float_encoded[float_encoded == 2] = 0.75\n",
    "    float_encoded[float_encoded == 3] = 1.00 \n",
    "    return float_encoded\n",
    "\n",
    "def get_ordinal_data(x_train):\n",
    "    X_list = []\n",
    "    for i in x_train:\n",
    "        X_list.append(ordinal_encoder(i))\n",
    "    return np.array(X_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence =  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGAACCACCCAGGCATTGTGGGGCTGCCCTGCCACCTGCTGGCCGCTCCTGGTGGCAG\n",
      "scaled version of One Hot Representation = [0.75 0.25 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.75 0.75 0.25 0.75\n",
      " 0.75 0.75 0.75 0.75 0.5  1.   0.75 0.75 0.5  0.5  0.5  0.25 0.75 0.25\n",
      " 0.75 0.75 0.5  0.25 0.5  0.5  0.25 0.75 0.25 0.5  1.   0.5  1.   0.75\n",
      " 0.5  0.25 0.75 0.25 0.25 0.5  0.5  0.25 0.5  0.5  0.5  0.25 0.75 0.75\n",
      " 0.5  0.25 1.   1.   0.75 1.   0.75 0.75 0.75 0.75 0.5  1.   0.75 0.5\n",
      " 0.5  0.5  1.   0.75 0.5  0.5  0.25 0.5  0.5  1.   0.75 0.5  1.   0.75\n",
      " 0.75 0.5  0.5  0.75 0.5  1.   0.5  0.5  1.   0.75 0.75 1.   0.75 0.75\n",
      " 0.5  0.25 0.75]\n"
     ]
    }
   ],
   "source": [
    "print('sequence = ', X_train_.seq.values[0])\n",
    "print('scaled version of One Hot Representation =',get_ordinal_data(X_train_.seq.values)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer counting/Spectral Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size=3):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "def get_data(kmer_size):\n",
    "    data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "    train_text = data.seq.values\n",
    "    # X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "    kmer_data = []\n",
    "    for i in train_text:\n",
    "        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))\n",
    "\n",
    "    return np.array(kmer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer / TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_grams(data,n=6):\n",
    "    cv = CountVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X\n",
    "\n",
    "def get_tf_idf_grams(data,n=6):\n",
    "    cv = TfidfVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_count_grams(X_train_.seq.values).shape\n",
    "# get_tf_idf_grams(X_train_.seq.values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Related Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=64,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))+(2*(self._lambda/len(self.train_labels ))*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(len(self.train_labels)//self.batch_size):\n",
    "                idx = list(np.random.choice(np.arange(len(self.train_labels)),self.batch_size,replace=False))\n",
    "                data = self.train_data[idx]\n",
    "                label = self.train_labels[idx]\n",
    "\n",
    "                y_pred = self.sigmoid(np.dot(data,self.params))\n",
    "                loss = self.cost(label,y_pred)\n",
    "\n",
    "                gra = self.gradient(label,y_pred,data)\n",
    "                self.params -= self.lr*gra\n",
    "\n",
    "                self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=4,batch_size=64,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_result = cross_validate(X_train_mat100,get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "ordinal_result = cross_validate(get_ordinal_data(X_train_.seq.values),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "kmer_result = cross_validate(get_data(6)[:2000,:],get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "count_result = cross_validate(get_count_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)\n",
    "tfidf_result = cross_validate(get_tf_idf_grams(X_train_.seq.values,6),get_label(type=0).reshape(-1,1),k=5,lr=0.01,batch_size=32,lamda=5,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Count-Vectorizer': 0.6005,\n",
       " 'K-mer': 0.6159999999999999,\n",
       " 'One Hot': 0.49499999999999994,\n",
       " 'Ordinal': 0.5135,\n",
       " 'Tf-idf': 0.511}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_value = {'One Hot':one_hot_result,'Ordinal':ordinal_result,'K-mer':kmer_result,'Count-Vectorizer':count_result,'Tf-idf':tfidf_result}\n",
    "final_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The First Result Shows The Qualty of the data on non optimized logistic regression model this is not the best value this method can achive but it can show us the quality of the data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot === 0.49499999999999994\n",
      "Ordinal === 0.5135\n",
      "K-mer === 0.6159999999999999\n",
      "Count-Vectorizer === 0.6005\n",
      "Tf-idf === 0.511\n"
     ]
    }
   ],
   "source": [
    "for k,v in final_value.items():\n",
    "    print('{} === {}'.format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Related Experiments +  Kernel Related Experiments\n",
    "\n",
    "We alady implemennted Logistic regression now we will add \n",
    "\n",
    "- Ridge Regression\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2.T)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "            \n",
    "        \n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X,X,**self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,model,kernel=None,lambd=0.2,sigma=0.5,k=5,power=2):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        if model == 'KernelRidgeRegression':\n",
    "            model = KernelRidgeRegression(\n",
    "                    kernel=kernel,\n",
    "                    lambd=lambd,\n",
    "                    sigma=sigma,\n",
    "                    power=power\n",
    "                ).fit(x_train, y_train)\n",
    "            result =sum(np.sign(model.predict(x_test))==y_test)/len(y_test)#roc_auc_score(np.sign(model.predict(x_test)),y_test) #\n",
    "        elif model == 'logistic':\n",
    "            logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "            logistic.train()\n",
    "\n",
    "            result = logistic.evaluate(x_test,y_test)\n",
    "            \n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(6)[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b484fc138b841e1a6a41a0bc693c89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-30 17:51:51,923]\u001b[0m Finished trial#0 with value: 0.504 with parameters: {'lambd': 35.9121779670735, 'sigma': 37.41698023557889, 'k': 8, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#0 with value: 0.504.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:51:54,252]\u001b[0m Finished trial#1 with value: 0.538 with parameters: {'lambd': 80.38628265833871, 'sigma': 13.323453813820363, 'k': 4, 'power': 3, 'kmer_size': 2, 'kernel': 'polynomial'}. Best is trial#1 with value: 0.538.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:51:56,969]\u001b[0m Finished trial#2 with value: 0.518 with parameters: {'lambd': 57.175019790205404, 'sigma': 130.73687891683582, 'k': 4, 'power': 4, 'kmer_size': 5, 'kernel': 'linear'}. Best is trial#1 with value: 0.538.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:51:59,848]\u001b[0m Finished trial#3 with value: 0.508 with parameters: {'lambd': 40.555530964629405, 'sigma': 10.186641703771878, 'k': 8, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#1 with value: 0.538.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:04,213]\u001b[0m Finished trial#4 with value: 0.644 with parameters: {'lambd': 67.62906415926982, 'sigma': 64.3079430527443, 'k': 8, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:06,930]\u001b[0m Finished trial#5 with value: 0.54 with parameters: {'lambd': 97.67377901240275, 'sigma': 42.88861598842627, 'k': 8, 'power': 3, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:11,807]\u001b[0m Finished trial#6 with value: 0.625 with parameters: {'lambd': 65.69510040416216, 'sigma': 80.33549316597606, 'k': 5, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:14,999]\u001b[0m Finished trial#7 with value: 0.5875 with parameters: {'lambd': 79.64862184145122, 'sigma': 83.42288220461285, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:17,649]\u001b[0m Finished trial#8 with value: 0.48 with parameters: {'lambd': 60.2894645769762, 'sigma': 13.046325098246905, 'k': 8, 'power': 2, 'kmer_size': 5, 'kernel': 'linear'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:20,146]\u001b[0m Finished trial#9 with value: 0.552 with parameters: {'lambd': 32.98835875816826, 'sigma': 40.96310424295597, 'k': 8, 'power': 5, 'kmer_size': 3, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:24,639]\u001b[0m Finished trial#10 with value: 0.636 with parameters: {'lambd': 1.8048647006289684, 'sigma': 22.636659039367213, 'k': 8, 'power': 5, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:29,127]\u001b[0m Finished trial#11 with value: 0.636 with parameters: {'lambd': 12.999763935688838, 'sigma': 27.02807567092276, 'k': 8, 'power': 5, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:33,546]\u001b[0m Finished trial#12 with value: 0.636 with parameters: {'lambd': 10.924395500724717, 'sigma': 26.258651608248986, 'k': 8, 'power': 5, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:36,642]\u001b[0m Finished trial#13 with value: 0.62 with parameters: {'lambd': 1.068845527625463, 'sigma': 75.96025129917479, 'k': 8, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:39,771]\u001b[0m Finished trial#14 with value: 0.584 with parameters: {'lambd': 75.42063152630371, 'sigma': 19.07308704672117, 'k': 8, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:42,250]\u001b[0m Finished trial#15 with value: 0.5475 with parameters: {'lambd': 97.99949454360147, 'sigma': 134.5546641550312, 'k': 5, 'power': 4, 'kmer_size': 3, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:47,406]\u001b[0m Finished trial#16 with value: 0.6 with parameters: {'lambd': 24.035688675181998, 'sigma': 60.916159526670434, 'k': 4, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:49,548]\u001b[0m Finished trial#17 with value: 0.56 with parameters: {'lambd': 47.99270750461096, 'sigma': 21.331551044667975, 'k': 8, 'power': 5, 'kmer_size': 1, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:52,416]\u001b[0m Finished trial#18 with value: 0.58 with parameters: {'lambd': 89.28168448043544, 'sigma': 63.084986326180974, 'k': 8, 'power': 4, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:55,613]\u001b[0m Finished trial#19 with value: 0.62 with parameters: {'lambd': 14.808629721685442, 'sigma': 30.56077315031819, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:52:58,262]\u001b[0m Finished trial#20 with value: 0.582 with parameters: {'lambd': 68.2725851774512, 'sigma': 52.09898039661672, 'k': 4, 'power': 3, 'kmer_size': 4, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:02,708]\u001b[0m Finished trial#21 with value: 0.636 with parameters: {'lambd': 1.8966395731127528, 'sigma': 20.05233201168176, 'k': 8, 'power': 5, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:07,167]\u001b[0m Finished trial#22 with value: 0.636 with parameters: {'lambd': 10.087556209426857, 'sigma': 25.644691020251457, 'k': 8, 'power': 5, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:10,285]\u001b[0m Finished trial#23 with value: 0.6 with parameters: {'lambd': 22.440271589256902, 'sigma': 32.409803181703616, 'k': 8, 'power': 5, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:14,695]\u001b[0m Finished trial#24 with value: 0.648 with parameters: {'lambd': 1.7389703279958046, 'sigma': 16.698532668563008, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:17,501]\u001b[0m Finished trial#25 with value: 0.58 with parameters: {'lambd': 49.94065588597177, 'sigma': 12.308197180244578, 'k': 8, 'power': 4, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:20,659]\u001b[0m Finished trial#26 with value: 0.6 with parameters: {'lambd': 24.44961507665765, 'sigma': 16.28637705894455, 'k': 8, 'power': 4, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:25,067]\u001b[0m Finished trial#27 with value: 0.644 with parameters: {'lambd': 72.30976841206439, 'sigma': 101.50017017803077, 'k': 8, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:28,158]\u001b[0m Finished trial#28 with value: 0.62 with parameters: {'lambd': 72.4300903410967, 'sigma': 99.2504100540574, 'k': 8, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:30,986]\u001b[0m Finished trial#29 with value: 0.568 with parameters: {'lambd': 85.15720746572819, 'sigma': 108.44935503570383, 'k': 8, 'power': 3, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:35,436]\u001b[0m Finished trial#30 with value: 0.648 with parameters: {'lambd': 62.045118421010606, 'sigma': 103.12628380054534, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:39,860]\u001b[0m Finished trial#31 with value: 0.648 with parameters: {'lambd': 59.80688534310253, 'sigma': 106.46132005964915, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:44,276]\u001b[0m Finished trial#32 with value: 0.648 with parameters: {'lambd': 55.53116139127626, 'sigma': 109.9999172872737, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:47,581]\u001b[0m Finished trial#33 with value: 0.612 with parameters: {'lambd': 55.58847581593194, 'sigma': 113.2216087901145, 'k': 4, 'power': 4, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:52,114]\u001b[0m Finished trial#34 with value: 0.648 with parameters: {'lambd': 42.79380119482427, 'sigma': 133.7947693494825, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:54,929]\u001b[0m Finished trial#35 with value: 0.58 with parameters: {'lambd': 35.54521996100695, 'sigma': 148.5967561956763, 'k': 8, 'power': 4, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:53:58,029]\u001b[0m Finished trial#36 with value: 0.556 with parameters: {'lambd': 44.96561781531761, 'sigma': 147.9628258062354, 'k': 8, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:03,224]\u001b[0m Finished trial#37 with value: 0.604 with parameters: {'lambd': 53.29014271899751, 'sigma': 126.50015976650336, 'k': 4, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:05,947]\u001b[0m Finished trial#38 with value: 0.54 with parameters: {'lambd': 40.98410128079952, 'sigma': 47.5395024946833, 'k': 8, 'power': 4, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:10,749]\u001b[0m Finished trial#39 with value: 0.625 with parameters: {'lambd': 30.499120287864528, 'sigma': 88.07237572645887, 'k': 5, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:12,897]\u001b[0m Finished trial#40 with value: 0.588 with parameters: {'lambd': 61.07472601024671, 'sigma': 117.45810800319492, 'k': 8, 'power': 4, 'kmer_size': 1, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:17,329]\u001b[0m Finished trial#41 with value: 0.648 with parameters: {'lambd': 63.522187907173794, 'sigma': 92.50651743316826, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:21,753]\u001b[0m Finished trial#42 with value: 0.648 with parameters: {'lambd': 64.0707551380089, 'sigma': 72.75394104215367, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:24,856]\u001b[0m Finished trial#43 with value: 0.6 with parameters: {'lambd': 57.19684723135991, 'sigma': 73.80341719551977, 'k': 8, 'power': 4, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:29,279]\u001b[0m Finished trial#44 with value: 0.648 with parameters: {'lambd': 44.68377613524496, 'sigma': 92.22009013578476, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:33,700]\u001b[0m Finished trial#45 with value: 0.648 with parameters: {'lambd': 40.779241907251915, 'sigma': 89.24997842332212, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:36,780]\u001b[0m Finished trial#46 with value: 0.56 with parameters: {'lambd': 39.14571709867232, 'sigma': 70.22315605203165, 'k': 8, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:41,247]\u001b[0m Finished trial#47 with value: 0.648 with parameters: {'lambd': 78.9415349912899, 'sigma': 137.14890993546584, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:44,105]\u001b[0m Finished trial#48 with value: 0.58 with parameters: {'lambd': 81.88901495756714, 'sigma': 89.09077209374813, 'k': 8, 'power': 4, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:48,614]\u001b[0m Finished trial#49 with value: 0.648 with parameters: {'lambd': 94.54129321713857, 'sigma': 10.064654258820983, 'k': 8, 'power': 4, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n",
      "\u001b[32m[I 2020-05-30 17:54:51,825]\u001b[0m Finished trial#50 with value: 0.6125 with parameters: {'lambd': 75.41923803018852, 'sigma': 58.330522149563066, 'k': 5, 'power': 5, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.648.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    lambd = trial.suggest_float('lambd', 1e-5, 100.0)\n",
    "    sigma = trial.suggest_loguniform('sigma', 10, 150)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8])\n",
    "    power =  trial.suggest_int('power', 2,5)\n",
    "    kmer_size =  trial.suggest_int('kmer_size', 1,8)\n",
    "    kernel =  trial.suggest_categorical('kernel', ['linear','polynomial'])\n",
    "    \n",
    "    return cross_validate(get_data(kmer_size)[:2000,:],get_label(type=-1),model='KernelRidgeRegression',kernel=kernel,lambd=lambd,k=k,sigma=sigma,power=power)\n",
    "\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=500,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = get_data(7)[2000:,:]\n",
    "\n",
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = np.sign(model.predict(X_test_final[i]))\n",
    "    \n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65.75_linear_overfitted.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

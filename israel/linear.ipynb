{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 184kB 3.4MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 41.1MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 81kB 6.3MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 81kB 8.3MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 61kB 7.3MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 112kB 56.0MB/s eta 0:00:01\n",
      "\u001b[?25h  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mat100 = pd.read_csv('../data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('../data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n",
    "\n",
    "X_test = pd.read_csv('../data/Xte.csv',sep=',',index_col=0).values\n",
    "X_train = pd.read_csv('../data/Xtr.csv',sep=',',index_col=0).values\n",
    "\n",
    "y = pd.read_csv('../data/Ytr.csv',sep=',',index_col=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (2000, 100) y_train (1800, 1)\n",
      "x_train: (2000, 1) y_train (1800, 1)\n",
      "x_test: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train: {} y_train {}'.format(X_train_mat100.shape,y_train.shape))\n",
    "print('x_train: {} y_train {}'.format(X_train.shape,y_train.shape))\n",
    "print('x_test: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340, 100) (1000, 1) (1340, 1) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_mat100 = scale(X_train_mat100)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_mat100, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  accuracy_score\n",
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lr=0.01,batch_size=None,epoch=10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        hassien = np.dot(y_pred.T,(1-y_pred))*np.linalg.inv(np.dot(x.T,x))\n",
    "        return np.dot(hassien,np.dot(x.T,(y_pred-y)))\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            y_pred = self.sigmoid(np.dot(self.train_data,self.params))\n",
    "            loss = self.cost(self.train_labels,y_pred)\n",
    "            \n",
    "            gra = self.gradient(self.train_labels,y_pred,self.train_data)\n",
    "            \n",
    "            self.params -= self.lr*gra #+ np.sum(self.params)/1\n",
    "            \n",
    "            if i%10 == 0 or i == self.epoch-1:\n",
    "                print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result >= 0.5 ] = 1\n",
    "        result[result < 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lr=0.01,batch_size=None,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            y_pred = self.sigmoid(np.dot(self.train_data,self.params))\n",
    "            loss = self.cost(self.train_labels,y_pred)\n",
    "            \n",
    "            gra = self.gradient(self.train_labels,y_pred,self.train_data)\n",
    "            \n",
    "            self.params -= self.lr*gra\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result >= 0.5 ] = 1\n",
    "        result[result < 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,k=5):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "            \n",
    "        logistic = logisticregression(x_train,y_train,lr=lr,epoch=10,print_every=None)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "    return sum(aggrigate_result)/len(aggrigate_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    k =  trial.suggest_int('k', 2, 10,2)\n",
    "    return cross_validate(X_train_mat100, y,lr,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115a4ac517b5400db1ce5cce24308114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-23 14:42:36,783]\u001b[0m Finished trial#0 with value: 0.5695 with parameters: {'lr': 0.0013803755945249333, 'k': 8}. Best is trial#0 with value: 0.5695.\u001b[0m\n",
      "\u001b[32m[I 2020-05-23 14:42:36,894]\u001b[0m Finished trial#1 with value: 0.5675 with parameters: {'lr': 0.002694734190662389, 'k': 8}. Best is trial#0 with value: 0.5695.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-23 14:42:37,053]\u001b[0m Finished trial#2 with value: 0.517 with parameters: {'lr': 0.030849098801601697, 'k': 10}. Best is trial#0 with value: 0.5695.\u001b[0m\n",
      "\u001b[32m[I 2020-05-23 14:42:37,155]\u001b[0m Finished trial#3 with value: 0.55 with parameters: {'lr': 0.05356936408037155, 'k': 4}. Best is trial#0 with value: 0.5695.\u001b[0m\n",
      "\u001b[32m[I 2020-05-23 14:42:37,257]\u001b[0m Finished trial#4 with value: 0.582 with parameters: {'lr': 0.0003072771139391344, 'k': 4}. Best is trial#4 with value: 0.582.\u001b[0m\n",
      "cant vsplit 2000  by  6\n",
      "\u001b[33m[W 2020-05-23 14:42:37,332]\u001b[0m Setting status of trial#5 as TrialState.FAIL because the returned value from the objective function cannot be casted to float. Returned value is: None\u001b[0m\n",
      "\u001b[32m[I 2020-05-23 14:42:37,443]\u001b[0m Finished trial#6 with value: 0.516 with parameters: {'lr': 0.00883605103054329, 'k': 10}. Best is trial#4 with value: 0.582.\u001b[0m\n",
      "\u001b[32m[I 2020-05-23 14:42:37,569]\u001b[0m Finished trial#7 with value: 0.5395000000000001 with parameters: {'lr': 0.0043516166100189225, 'k': 8}. Best is trial#4 with value: 0.582.\u001b[0m\n",
      "\u001b[32m[I 2020-05-23 14:42:37,681]\u001b[0m Finished trial#8 with value: 0.5784999999999999 with parameters: {'lr': 0.0004861737999277526, 'k': 4}. Best is trial#4 with value: 0.582.\u001b[0m\n",
      "cant vsplit 2000  by  6\n",
      "\u001b[33m[W 2020-05-23 14:42:37,753]\u001b[0m Setting status of trial#9 as TrialState.FAIL because the returned value from the objective function cannot be casted to float. Returned value is: None\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross_validate(X_train_mat100, y,0.001,10)\n",
    "\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective, n_trials=10,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_k</th>\n",
       "      <th>params_lr</th>\n",
       "      <th>system_attrs_fail_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>00:00:00.109123</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>00:00:00.153537</td>\n",
       "      <td>10</td>\n",
       "      <td>0.030849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>00:00:00.119214</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>00:00:00.098511</td>\n",
       "      <td>4</td>\n",
       "      <td>0.053569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5675</td>\n",
       "      <td>00:00:00.106884</td>\n",
       "      <td>8</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>00:00:00.155160</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>00:00:00.107135</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>00:00:00.097582</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00.070165</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>Setting status of trial#5 as TrialState.FAIL b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:00:00.067149</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>Setting status of trial#9 as TrialState.FAIL b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number   value  ... params_lr                           system_attrs_fail_reason\n",
       "6       6  0.5160  ...  0.008836                                                NaN\n",
       "2       2  0.5170  ...  0.030849                                                NaN\n",
       "7       7  0.5395  ...  0.004352                                                NaN\n",
       "3       3  0.5500  ...  0.053569                                                NaN\n",
       "1       1  0.5675  ...  0.002695                                                NaN\n",
       "0       0  0.5695  ...  0.001380                                                NaN\n",
       "8       8  0.5785  ...  0.000486                                                NaN\n",
       "4       4  0.5820  ...  0.000307                                                NaN\n",
       "5       5     NaN  ...  0.004174  Setting status of trial#5 as TrialState.FAIL b...\n",
       "9       9     NaN  ...  0.000114  Setting status of trial#9 as TrialState.FAIL b...\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "# df = df.dropna()\n",
    "df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  Loss: 0.6931471805599453\n",
      "Epoch : 1  Loss: 0.6710256163735592\n",
      "Epoch : 2  Loss: 0.6569848839682912\n",
      "Epoch : 3  Loss: 0.6471494677918743\n",
      "Epoch : 4  Loss: 0.6399666752924154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6015151515151516"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test\n",
    "logistic = logisticregression(X_train,y_train,epoch=5,print_every=1,lr=0.000307)\n",
    "logistic.train()\n",
    "        \n",
    "result = logistic.evaluate(X_val,y_val)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumbission = []\n",
    "for i in range(len(X_test_mat100)):\n",
    "    result = logistic.predict(X_test_mat100[i,:])\n",
    "    sumbission.append([i,int(result)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

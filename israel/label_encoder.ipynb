{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 184kB 5.0MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 16.1MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 81kB 10.8MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 112kB 31.0MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s  eta 0:00:01\n",
      "\u001b[?25h  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = pd.read_csv('../data/Xte.csv',sep=',',index_col=0).values\n",
    "X_train = pd.read_csv('../data/Xtr.csv',sep=',',index_col=0).values\n",
    "\n",
    "y = pd.read_csv('../data/Ytr.csv',sep=',',index_col=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 1), (1000, 1))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_n_grams(data1,data2,n):\n",
    "    X_te = []\n",
    "    X = []\n",
    "\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    for i in data1:\n",
    "        sentence = ' '.join(getKmers(i[0], size=n))\n",
    "        X.append(sentence)\n",
    "\n",
    "    for i in data2:\n",
    "        sentence = ' '.join(getKmers(i[0], size=n))\n",
    "        X_te.append(sentence)\n",
    "\n",
    "    \n",
    "    X_later = X+X_te\n",
    "    X = cv.fit_transform(X+X_te).toarray()\n",
    "    \n",
    "    return X\n",
    "# breakS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  5,  8,  1,  9, 12,  1, 10,  5, 13, 19,  2,  0,  2, 11],\n",
       "        [ 2,  3, 10,  2,  7,  5,  1,  7,  5,  9, 23,  8,  3,  2, 12],\n",
       "        [ 3,  6,  4,  3,  4, 16,  8,  9,  8,  7,  9,  5,  1,  8,  7],\n",
       "        [ 4,  4, 10,  0,  7,  8,  4,  6,  7, 10, 20,  4,  1,  3,  6],\n",
       "        [ 4, 12,  4,  3,  9,  9,  2, 10,  1,  5,  4, 10,  9,  5,  9],\n",
       "        [ 4,  6,  6,  0,  6, 16, 10, 10,  4, 13,  7,  4,  2,  6,  5],\n",
       "        [ 4,  2,  9,  2,  4,  5,  0, 11,  4,  9, 11, 10,  5,  4, 15],\n",
       "        [ 7,  4, 10,  5, 10, 13,  0,  9,  6,  8,  8,  2,  3,  6,  6],\n",
       "        [ 1,  1, 12,  0,  3, 18, 16,  3,  9, 18,  7,  4,  1,  3,  2],\n",
       "        [ 3,  4,  7,  5,  6, 13,  4,  7,  6,  7,  8,  9,  4,  6, 11],\n",
       "        [ 9,  4, 18,  2, 13,  7,  0,  6,  7, 10,  6,  4,  3,  6,  3],\n",
       "        [ 3,  5,  6,  4,  7,  8,  3, 15,  4, 11,  5,  3,  4, 10,  9],\n",
       "        [ 8,  6, 12,  3,  8,  2,  2,  7,  9,  5,  7,  7,  4,  6,  7],\n",
       "        [ 8,  4, 11,  4,  7, 12,  0, 10,  9,  9,  7,  2,  2,  4,  9],\n",
       "        [24,  9,  8,  7, 11,  1,  0,  5,  6,  1,  4,  3,  7,  6,  1]]),\n",
       " array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0],\n",
       "        [2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [2, 0, 2, 0, 1, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 1, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0, 0, 1, 0, 1],\n",
       "        [7, 3, 2, 1, 3, 0, 0, 2, 3, 0, 0, 2, 0, 0, 0]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = get_n_grams(X_train,X_test,2)\n",
    "X_4 = get_n_grams(X_train,X_test,4)\n",
    "\n",
    "X_6[:15,:15],X_4[:15,:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (2000, 16) y_train (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train: {} y_train {}'.format(X_2[:2000,:].shape,y.shape))\n",
    "\n",
    "# print('x_train: {} y_train {}'.format(X_train.shape,y.shape))\n",
    "# print('x_test: {}'.format(X_te.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_2= scale(X_2[:2000,:])\n",
    "X_te_2 = scale(X_2[2000:,:])\n",
    "\n",
    "X_tr_4= scale(X_4[:2000,:])\n",
    "X_te_4 = scale(X_4[2000:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_kernel(X, Y):\n",
    "    R = np.zeros((len(X), len(Y)))\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(Y)):\n",
    "            R[i, j] = (np.dot(X[i],Y[j])+1)**3\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = string_kernel(X_tr_2,X_tr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340, 2000) (660, 2000) (1340, 1) (660, 1) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tr, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape,X_val.shape,y_train.shape, y_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=None,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))+(2*self._lambda*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            y_pred = self.sigmoid(np.dot(self.train_data,self.params))\n",
    "            loss = self.cost(self.train_labels,y_pred)\n",
    "            \n",
    "            gra = self.gradient(self.train_labels,y_pred,self.train_data)\n",
    "            \n",
    "            self.params -= self.lr*gra\n",
    "            \n",
    "            self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "#             if self.print_every:\n",
    "#                 if i%self.print_every == 0 or i == self.epoch-1:\n",
    "#                     print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=5,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "            \n",
    "        logistic = logisticregression(x_train,y_train,lamda=lamda,lr=lr,decay=decay,epoch=epoch)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value if value!= None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    lamda = trial.suggest_loguniform('lamda', 0.01, 0.5)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "    epoch =  trial.suggest_int('epoch', 10, 20)\n",
    "    decay = trial.suggest_int('decay', 3, 10)\n",
    "    return cross_validate(X_tr, y,lr=lr,lamda=lamda,k=k,epoch=epoch,decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f016d86a52434dbaac20daf22259af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning:\n",
      "\n",
      "overflow encountered in exp\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-26 09:49:38,809]\u001b[0m Finished trial#0 with value: 0.513 with parameters: {'lr': 0.00025251509426009824, 'lamda': 0.4765764101009703, 'k': 8, 'epoch': 20, 'decay': 3}. Best is trial#0 with value: 0.513.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:38,936]\u001b[0m Finished trial#1 with value: 0.514 with parameters: {'lr': 0.0014729743858833684, 'lamda': 0.04618971369918779, 'k': 10, 'epoch': 11, 'decay': 10}. Best is trial#1 with value: 0.514.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:39,081]\u001b[0m Finished trial#2 with value: 0.5145000000000001 with parameters: {'lr': 0.00112626514949514, 'lamda': 0.1293218044535842, 'k': 10, 'epoch': 18, 'decay': 9}. Best is trial#2 with value: 0.5145000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:39,209]\u001b[0m Finished trial#3 with value: 0.5120000000000001 with parameters: {'lr': 0.000236337480567576, 'lamda': 0.4548669681618339, 'k': 5, 'epoch': 10, 'decay': 5}. Best is trial#2 with value: 0.5145000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:39,348]\u001b[0m Finished trial#4 with value: 0.5105 with parameters: {'lr': 6.277886708171898e-05, 'lamda': 0.13618505172412274, 'k': 4, 'epoch': 16, 'decay': 8}. Best is trial#2 with value: 0.5145000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:39,563]\u001b[0m Finished trial#5 with value: 0.5145000000000001 with parameters: {'lr': 0.009558594070176927, 'lamda': 0.013237327167024996, 'k': 10, 'epoch': 14, 'decay': 9}. Best is trial#2 with value: 0.5145000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:39,705]\u001b[0m Finished trial#6 with value: 0.514 with parameters: {'lr': 0.01045975675694297, 'lamda': 0.0583188366620359, 'k': 10, 'epoch': 14, 'decay': 10}. Best is trial#2 with value: 0.5145000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:39,832]\u001b[0m Finished trial#7 with value: 0.5130000000000001 with parameters: {'lr': 0.0011157091528251107, 'lamda': 0.11457531542099696, 'k': 10, 'epoch': 10, 'decay': 8}. Best is trial#2 with value: 0.5145000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:39,974]\u001b[0m Finished trial#8 with value: 0.5149999999999999 with parameters: {'lr': 0.0021371335543159484, 'lamda': 0.02164878683813239, 'k': 10, 'epoch': 16, 'decay': 3}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:40,115]\u001b[0m Finished trial#9 with value: 0.5135000000000001 with parameters: {'lr': 0.0016077268715395927, 'lamda': 0.038911176065759036, 'k': 5, 'epoch': 19, 'decay': 4}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:40,257]\u001b[0m Finished trial#10 with value: 0.513 with parameters: {'lr': 0.07121937849503251, 'lamda': 0.010739536767170505, 'k': 4, 'epoch': 16, 'decay': 6}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:40,430]\u001b[0m Finished trial#11 with value: 0.5125 with parameters: {'lr': 0.007940340739302526, 'lamda': 0.02247692091225071, 'k': 10, 'epoch': 18, 'decay': 7}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:40,622]\u001b[0m Finished trial#12 with value: 0.513 with parameters: {'lr': 0.0002385019181721991, 'lamda': 0.23413742875102045, 'k': 8, 'epoch': 17, 'decay': 3}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:40,782]\u001b[0m Finished trial#13 with value: 0.511 with parameters: {'lr': 1.1516883175494923e-05, 'lamda': 0.13493302723976602, 'k': 10, 'epoch': 20, 'decay': 6}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:40,924]\u001b[0m Finished trial#14 with value: 0.5130000000000001 with parameters: {'lr': 0.0047427983712574244, 'lamda': 0.02189735378091134, 'k': 10, 'epoch': 14, 'decay': 8}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:41,086]\u001b[0m Finished trial#15 with value: 0.513 with parameters: {'lr': 0.05143236669324108, 'lamda': 0.2557118838262178, 'k': 10, 'epoch': 18, 'decay': 5}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:41,231]\u001b[0m Finished trial#16 with value: 0.5145000000000001 with parameters: {'lr': 5.5339947996070546e-05, 'lamda': 0.08377239628923604, 'k': 10, 'epoch': 12, 'decay': 9}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:41,364]\u001b[0m Finished trial#17 with value: 0.511 with parameters: {'lr': 0.02307233612176278, 'lamda': 0.018145087310590436, 'k': 4, 'epoch': 13, 'decay': 7}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:41,528]\u001b[0m Finished trial#18 with value: 0.5095000000000001 with parameters: {'lr': 0.0027591037410792303, 'lamda': 0.0310491345289866, 'k': 8, 'epoch': 16, 'decay': 4}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:41,694]\u001b[0m Finished trial#19 with value: 0.5089999999999999 with parameters: {'lr': 0.0007254529628998263, 'lamda': 0.26581250434881115, 'k': 5, 'epoch': 18, 'decay': 9}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:41,843]\u001b[0m Finished trial#20 with value: 0.514 with parameters: {'lr': 0.000500838886594748, 'lamda': 0.0811320758154223, 'k': 10, 'epoch': 17, 'decay': 10}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:41,981]\u001b[0m Finished trial#21 with value: 0.5145000000000001 with parameters: {'lr': 3.5127106059652974e-05, 'lamda': 0.09096833822405187, 'k': 10, 'epoch': 12, 'decay': 9}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:42,134]\u001b[0m Finished trial#22 with value: 0.5145000000000001 with parameters: {'lr': 1.0087287191418689e-05, 'lamda': 0.20025279689071254, 'k': 10, 'epoch': 15, 'decay': 9}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:42,279]\u001b[0m Finished trial#23 with value: 0.5130000000000001 with parameters: {'lr': 0.0034591966447848144, 'lamda': 0.21460592526128783, 'k': 10, 'epoch': 15, 'decay': 8}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:42,418]\u001b[0m Finished trial#24 with value: 0.514 with parameters: {'lr': 5.7753413126836906e-05, 'lamda': 0.059015220781692496, 'k': 10, 'epoch': 12, 'decay': 10}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:42,579]\u001b[0m Finished trial#25 with value: 0.5125 with parameters: {'lr': 0.0004336308749703288, 'lamda': 0.17330570140329077, 'k': 10, 'epoch': 17, 'decay': 7}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:42,760]\u001b[0m Finished trial#26 with value: 0.5145000000000001 with parameters: {'lr': 1.2168397037288678e-05, 'lamda': 0.1521275076977385, 'k': 10, 'epoch': 15, 'decay': 9}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:42,913]\u001b[0m Finished trial#27 with value: 0.5105 with parameters: {'lr': 0.00011073998937529585, 'lamda': 0.3280450368805212, 'k': 4, 'epoch': 19, 'decay': 8}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:43,054]\u001b[0m Finished trial#28 with value: 0.513 with parameters: {'lr': 2.4767673130527607e-05, 'lamda': 0.09664662142680681, 'k': 10, 'epoch': 13, 'decay': 5}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:43,215]\u001b[0m Finished trial#29 with value: 0.5095000000000001 with parameters: {'lr': 0.00014229132316032547, 'lamda': 0.4169374129158696, 'k': 8, 'epoch': 20, 'decay': 4}. Best is trial#8 with value: 0.5149999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:43,360]\u001b[0m Finished trial#30 with value: 0.519 with parameters: {'lr': 0.002608797481653593, 'lamda': 0.16242328791044147, 'k': 5, 'epoch': 16, 'decay': 3}. Best is trial#30 with value: 0.519.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:43,512]\u001b[0m Finished trial#31 with value: 0.519 with parameters: {'lr': 0.0022002011861283425, 'lamda': 0.16478607994452024, 'k': 5, 'epoch': 16, 'decay': 3}. Best is trial#30 with value: 0.519.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:43,652]\u001b[0m Finished trial#32 with value: 0.519 with parameters: {'lr': 0.002060825391419347, 'lamda': 0.3352102680610375, 'k': 5, 'epoch': 16, 'decay': 3}. Best is trial#30 with value: 0.519.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:43,826]\u001b[0m Finished trial#33 with value: 0.519 with parameters: {'lr': 0.0020948192936082384, 'lamda': 0.3320272569154683, 'k': 5, 'epoch': 16, 'decay': 3}. Best is trial#30 with value: 0.519.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:43,969]\u001b[0m Finished trial#34 with value: 0.5195000000000001 with parameters: {'lr': 0.005228883929298246, 'lamda': 0.34440462739579464, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:44,116]\u001b[0m Finished trial#35 with value: 0.5195000000000001 with parameters: {'lr': 0.005543813737503149, 'lamda': 0.35634205111968287, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:44,260]\u001b[0m Finished trial#36 with value: 0.516 with parameters: {'lr': 0.021601324684720636, 'lamda': 0.47747404833542373, 'k': 5, 'epoch': 17, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:44,414]\u001b[0m Finished trial#37 with value: 0.5195000000000001 with parameters: {'lr': 0.005585415710521192, 'lamda': 0.39250983275266715, 'k': 5, 'epoch': 19, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:44,583]\u001b[0m Finished trial#38 with value: 0.515 with parameters: {'lr': 0.005597640195572806, 'lamda': 0.4046162629180529, 'k': 5, 'epoch': 19, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:44,731]\u001b[0m Finished trial#39 with value: 0.519 with parameters: {'lr': 0.01505759871729937, 'lamda': 0.3288671912543015, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:44,913]\u001b[0m Finished trial#40 with value: 0.5145000000000001 with parameters: {'lr': 0.018568207242313332, 'lamda': 0.4861312792541168, 'k': 5, 'epoch': 19, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:45,056]\u001b[0m Finished trial#41 with value: 0.519 with parameters: {'lr': 0.004251899952544035, 'lamda': 0.29485764362420425, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:45,204]\u001b[0m Finished trial#42 with value: 0.519 with parameters: {'lr': 0.007313059636503094, 'lamda': 0.17522636233451716, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:45,351]\u001b[0m Finished trial#43 with value: 0.5195000000000001 with parameters: {'lr': 0.012544412641385916, 'lamda': 0.3608458020010614, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:45,508]\u001b[0m Finished trial#44 with value: 0.5105000000000001 with parameters: {'lr': 0.033271163456992214, 'lamda': 0.3800864864508789, 'k': 5, 'epoch': 20, 'decay': 5}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:45,652]\u001b[0m Finished trial#45 with value: 0.515 with parameters: {'lr': 0.010941322574349986, 'lamda': 0.49060498311509276, 'k': 5, 'epoch': 18, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:45,805]\u001b[0m Finished trial#46 with value: 0.5195000000000001 with parameters: {'lr': 0.007354992736691204, 'lamda': 0.19106001411560083, 'k': 5, 'epoch': 19, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:45,991]\u001b[0m Finished trial#47 with value: 0.5185000000000001 with parameters: {'lr': 0.034995980704235215, 'lamda': 0.38300310701647405, 'k': 5, 'epoch': 19, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:46,141]\u001b[0m Finished trial#48 with value: 0.515 with parameters: {'lr': 0.012265048715445256, 'lamda': 0.26524671390483073, 'k': 5, 'epoch': 20, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:46,293]\u001b[0m Finished trial#49 with value: 0.5120000000000001 with parameters: {'lr': 0.0935454355053737, 'lamda': 0.20648851404063653, 'k': 5, 'epoch': 19, 'decay': 5}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:46,446]\u001b[0m Finished trial#50 with value: 0.5195000000000001 with parameters: {'lr': 0.006644200588670809, 'lamda': 0.28996975231931854, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:46,617]\u001b[0m Finished trial#51 with value: 0.5195000000000001 with parameters: {'lr': 0.007316965051111958, 'lamda': 0.24753201907601982, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:46,766]\u001b[0m Finished trial#52 with value: 0.519 with parameters: {'lr': 0.007325763328613413, 'lamda': 0.11371078665110496, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:46,922]\u001b[0m Finished trial#53 with value: 0.5135000000000001 with parameters: {'lr': 0.0012324844804512377, 'lamda': 0.23366748066958354, 'k': 5, 'epoch': 18, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:47,080]\u001b[0m Finished trial#54 with value: 0.5195000000000001 with parameters: {'lr': 0.006258205544940025, 'lamda': 0.2923312227431989, 'k': 5, 'epoch': 19, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:47,230]\u001b[0m Finished trial#55 with value: 0.519 with parameters: {'lr': 0.0040740595495217845, 'lamda': 0.30377104878669225, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:47,382]\u001b[0m Finished trial#56 with value: 0.515 with parameters: {'lr': 0.005575186926804653, 'lamda': 0.2727928644896137, 'k': 5, 'epoch': 19, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:47,553]\u001b[0m Finished trial#57 with value: 0.514 with parameters: {'lr': 0.013271436749279128, 'lamda': 0.41670496538542945, 'k': 8, 'epoch': 20, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:47,703]\u001b[0m Finished trial#58 with value: 0.517 with parameters: {'lr': 0.029957165553751303, 'lamda': 0.23318756337806348, 'k': 4, 'epoch': 18, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:47,861]\u001b[0m Finished trial#59 with value: 0.519 with parameters: {'lr': 0.0033362217652920492, 'lamda': 0.36926899223866483, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:48,017]\u001b[0m Finished trial#60 with value: 0.513 with parameters: {'lr': 0.052212288755177076, 'lamda': 0.4417336652637729, 'k': 5, 'epoch': 19, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:48,171]\u001b[0m Finished trial#61 with value: 0.5195000000000001 with parameters: {'lr': 0.005578491866457945, 'lamda': 0.2944981791318307, 'k': 5, 'epoch': 19, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:48,325]\u001b[0m Finished trial#62 with value: 0.5195000000000001 with parameters: {'lr': 0.0094751989483157, 'lamda': 0.1945740811909449, 'k': 5, 'epoch': 20, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:48,483]\u001b[0m Finished trial#63 with value: 0.519 with parameters: {'lr': 0.009153233317222622, 'lamda': 0.12097244315435371, 'k': 5, 'epoch': 20, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:48,648]\u001b[0m Finished trial#64 with value: 0.519 with parameters: {'lr': 0.001535327419084275, 'lamda': 0.2847018696339384, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:48,800]\u001b[0m Finished trial#65 with value: 0.515 with parameters: {'lr': 0.01696400071545413, 'lamda': 0.23114047465548637, 'k': 5, 'epoch': 19, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:48,954]\u001b[0m Finished trial#66 with value: 0.519 with parameters: {'lr': 0.004892342792386937, 'lamda': 0.1902244679137531, 'k': 5, 'epoch': 20, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:49,128]\u001b[0m Finished trial#67 with value: 0.519 with parameters: {'lr': 0.003098004775150633, 'lamda': 0.3039483690310017, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:49,275]\u001b[0m Finished trial#68 with value: 0.5155000000000001 with parameters: {'lr': 0.009016336357871994, 'lamda': 0.1897186553806669, 'k': 4, 'epoch': 19, 'decay': 5}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:49,435]\u001b[0m Finished trial#69 with value: 0.5095000000000001 with parameters: {'lr': 0.0007194078998231352, 'lamda': 0.14418262720568326, 'k': 8, 'epoch': 20, 'decay': 4}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:49,583]\u001b[0m Finished trial#70 with value: 0.5195000000000001 with parameters: {'lr': 0.024916098134809446, 'lamda': 0.3582488190082947, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:49,730]\u001b[0m Finished trial#71 with value: 0.5195000000000001 with parameters: {'lr': 0.007487370838522846, 'lamda': 0.27774742100193556, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:49,900]\u001b[0m Finished trial#72 with value: 0.5195000000000001 with parameters: {'lr': 0.010844112278176712, 'lamda': 0.24229064957591884, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:50,054]\u001b[0m Finished trial#73 with value: 0.5195000000000001 with parameters: {'lr': 0.01332611972898553, 'lamda': 0.4361607752904318, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#34 with value: 0.5195000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:50,229]\u001b[0m Finished trial#74 with value: 0.52 with parameters: {'lr': 0.0155604694661033, 'lamda': 0.44025808531024724, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:50,383]\u001b[0m Finished trial#75 with value: 0.515 with parameters: {'lr': 0.025559244237925247, 'lamda': 0.26242129250617513, 'k': 5, 'epoch': 19, 'decay': 4}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:50,530]\u001b[0m Finished trial#76 with value: 0.52 with parameters: {'lr': 0.018544617904305397, 'lamda': 0.3514776263999734, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:50,697]\u001b[0m Finished trial#77 with value: 0.515 with parameters: {'lr': 0.020354666504107548, 'lamda': 0.35481201581777405, 'k': 5, 'epoch': 16, 'decay': 4}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:50,852]\u001b[0m Finished trial#78 with value: 0.5185000000000001 with parameters: {'lr': 0.044354866656991655, 'lamda': 0.3021142250571716, 'k': 5, 'epoch': 19, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:51,006]\u001b[0m Finished trial#79 with value: 0.519 with parameters: {'lr': 0.014560769588138796, 'lamda': 0.21257360275500828, 'k': 5, 'epoch': 20, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:51,155]\u001b[0m Finished trial#80 with value: 0.5110000000000001 with parameters: {'lr': 0.0037569322494043957, 'lamda': 0.49651626417976313, 'k': 5, 'epoch': 17, 'decay': 6}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:51,332]\u001b[0m Finished trial#81 with value: 0.519 with parameters: {'lr': 0.026468495185135204, 'lamda': 0.34826377302235845, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:51,476]\u001b[0m Finished trial#82 with value: 0.519 with parameters: {'lr': 0.009276516351702837, 'lamda': 0.3224083718824711, 'k': 5, 'epoch': 17, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:51,650]\u001b[0m Finished trial#83 with value: 0.52 with parameters: {'lr': 0.017921613226795474, 'lamda': 0.3881743063671902, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:51,797]\u001b[0m Finished trial#84 with value: 0.52 with parameters: {'lr': 0.016483682699279252, 'lamda': 0.4258494203092126, 'k': 5, 'epoch': 19, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:51,939]\u001b[0m Finished trial#85 with value: 0.515 with parameters: {'lr': 0.017136837458760767, 'lamda': 0.4446820760302294, 'k': 5, 'epoch': 16, 'decay': 4}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:52,085]\u001b[0m Finished trial#86 with value: 0.5185000000000001 with parameters: {'lr': 0.044110752462522794, 'lamda': 0.40517904594414195, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:52,240]\u001b[0m Finished trial#87 with value: 0.5145000000000001 with parameters: {'lr': 0.07992709045108495, 'lamda': 0.4961396962949608, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:52,404]\u001b[0m Finished trial#88 with value: 0.5125 with parameters: {'lr': 0.019930113087652652, 'lamda': 0.3875546255536792, 'k': 8, 'epoch': 17, 'decay': 4}. Best is trial#74 with value: 0.52.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:52,555]\u001b[0m Finished trial#89 with value: 0.524 with parameters: {'lr': 0.05946273774250857, 'lamda': 0.040288269772501675, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:52,723]\u001b[0m Finished trial#90 with value: 0.524 with parameters: {'lr': 0.05855482118433939, 'lamda': 0.032638445498320214, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:52,872]\u001b[0m Finished trial#91 with value: 0.524 with parameters: {'lr': 0.06634138537768305, 'lamda': 0.03661006823726619, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:53,015]\u001b[0m Finished trial#92 with value: 0.524 with parameters: {'lr': 0.06151136095995981, 'lamda': 0.0357662560350247, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:53,163]\u001b[0m Finished trial#93 with value: 0.524 with parameters: {'lr': 0.061498500290851014, 'lamda': 0.03564054437619287, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:53,311]\u001b[0m Finished trial#94 with value: 0.524 with parameters: {'lr': 0.06455037834577308, 'lamda': 0.037558781292041835, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:53,468]\u001b[0m Finished trial#95 with value: 0.524 with parameters: {'lr': 0.06618805478138548, 'lamda': 0.036166386524847154, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:53,630]\u001b[0m Finished trial#96 with value: 0.524 with parameters: {'lr': 0.06577932042986974, 'lamda': 0.037968622670049745, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:53,777]\u001b[0m Finished trial#97 with value: 0.524 with parameters: {'lr': 0.06518997185050711, 'lamda': 0.03703199260508465, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:53,920]\u001b[0m Finished trial#98 with value: 0.518 with parameters: {'lr': 0.06676085514916415, 'lamda': 0.036627656502434915, 'k': 4, 'epoch': 18, 'decay': 4}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:54,067]\u001b[0m Finished trial#99 with value: 0.524 with parameters: {'lr': 0.09831124493818899, 'lamda': 0.026816910712867313, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:54,211]\u001b[0m Finished trial#100 with value: 0.524 with parameters: {'lr': 0.09758850772553791, 'lamda': 0.02679049170954643, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:54,360]\u001b[0m Finished trial#101 with value: 0.524 with parameters: {'lr': 0.0990562746672094, 'lamda': 0.026387568496996087, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:54,531]\u001b[0m Finished trial#102 with value: 0.524 with parameters: {'lr': 0.06391234277095338, 'lamda': 0.045370664524474386, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:54,690]\u001b[0m Finished trial#103 with value: 0.524 with parameters: {'lr': 0.08406822214109676, 'lamda': 0.053475863032684534, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:54,837]\u001b[0m Finished trial#104 with value: 0.524 with parameters: {'lr': 0.09928971473405959, 'lamda': 0.025387510657026456, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:54,986]\u001b[0m Finished trial#105 with value: 0.518 with parameters: {'lr': 0.09769389535452895, 'lamda': 0.024616683468241037, 'k': 4, 'epoch': 18, 'decay': 4}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:55,133]\u001b[0m Finished trial#106 with value: 0.524 with parameters: {'lr': 0.05221960342108217, 'lamda': 0.017796548956670342, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:55,281]\u001b[0m Finished trial#107 with value: 0.524 with parameters: {'lr': 0.04187314927927315, 'lamda': 0.018583651244594622, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:55,429]\u001b[0m Finished trial#108 with value: 0.524 with parameters: {'lr': 0.040704904699559154, 'lamda': 0.04095962115391338, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:55,605]\u001b[0m Finished trial#109 with value: 0.524 with parameters: {'lr': 0.03943251712839935, 'lamda': 0.033239940793939785, 'k': 4, 'epoch': 19, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:55,770]\u001b[0m Finished trial#110 with value: 0.518 with parameters: {'lr': 0.03646600352781131, 'lamda': 0.03101051623714263, 'k': 4, 'epoch': 19, 'decay': 4}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:55,926]\u001b[0m Finished trial#111 with value: 0.524 with parameters: {'lr': 0.06121500772783003, 'lamda': 0.03322811720038557, 'k': 4, 'epoch': 19, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:56,076]\u001b[0m Finished trial#112 with value: 0.524 with parameters: {'lr': 0.0606545272122642, 'lamda': 0.02983541339110101, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:56,228]\u001b[0m Finished trial#113 with value: 0.524 with parameters: {'lr': 0.058166432540315186, 'lamda': 0.030261633845729802, 'k': 4, 'epoch': 17, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:56,372]\u001b[0m Finished trial#114 with value: 0.524 with parameters: {'lr': 0.07747798013209754, 'lamda': 0.02899051323280419, 'k': 4, 'epoch': 17, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:56,522]\u001b[0m Finished trial#115 with value: 0.524 with parameters: {'lr': 0.08110281411319918, 'lamda': 0.05230499237984469, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:56,682]\u001b[0m Finished trial#116 with value: 0.524 with parameters: {'lr': 0.08602364138575873, 'lamda': 0.05394005183547845, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:56,830]\u001b[0m Finished trial#117 with value: 0.524 with parameters: {'lr': 0.07473572060023635, 'lamda': 0.06117385386901009, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#89 with value: 0.524.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:56,978]\u001b[0m Finished trial#118 with value: 0.526 with parameters: {'lr': 0.04891284041183303, 'lamda': 0.06744397188721539, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:57,127]\u001b[0m Finished trial#119 with value: 0.526 with parameters: {'lr': 0.05152737338011746, 'lamda': 0.06196755961977538, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:57,273]\u001b[0m Finished trial#120 with value: 0.518 with parameters: {'lr': 0.031112784027797602, 'lamda': 0.03593236180964183, 'k': 4, 'epoch': 18, 'decay': 4}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:57,421]\u001b[0m Finished trial#121 with value: 0.524 with parameters: {'lr': 0.09448524529837245, 'lamda': 0.04261018014770607, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:57,566]\u001b[0m Finished trial#122 with value: 0.524 with parameters: {'lr': 0.05206851313986094, 'lamda': 0.017527152381276254, 'k': 4, 'epoch': 17, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:57,741]\u001b[0m Finished trial#123 with value: 0.524 with parameters: {'lr': 0.050810147083017954, 'lamda': 0.04254634341438969, 'k': 4, 'epoch': 17, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:57,888]\u001b[0m Finished trial#124 with value: 0.526 with parameters: {'lr': 0.0485573737250693, 'lamda': 0.07224171844900538, 'k': 4, 'epoch': 17, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:58,038]\u001b[0m Finished trial#125 with value: 0.526 with parameters: {'lr': 0.0967298612358008, 'lamda': 0.07215151401958189, 'k': 4, 'epoch': 18, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:58,196]\u001b[0m Finished trial#126 with value: 0.524 with parameters: {'lr': 0.07144635326687762, 'lamda': 0.06921515446999049, 'k': 4, 'epoch': 19, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:58,350]\u001b[0m Finished trial#127 with value: 0.526 with parameters: {'lr': 0.0967741027846345, 'lamda': 0.06378826828868106, 'k': 4, 'epoch': 19, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:58,490]\u001b[0m Finished trial#128 with value: 0.526 with parameters: {'lr': 0.09802516270497753, 'lamda': 0.06973403039328775, 'k': 4, 'epoch': 14, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:58,630]\u001b[0m Finished trial#129 with value: 0.526 with parameters: {'lr': 0.09991210998672416, 'lamda': 0.07666813675699002, 'k': 4, 'epoch': 13, 'decay': 3}. Best is trial#118 with value: 0.526.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:58,812]\u001b[0m Finished trial#130 with value: 0.5265 with parameters: {'lr': 0.0931002283106271, 'lamda': 0.07747014887281249, 'k': 4, 'epoch': 13, 'decay': 3}. Best is trial#130 with value: 0.5265.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:58,952]\u001b[0m Finished trial#131 with value: 0.526 with parameters: {'lr': 0.09874873857899603, 'lamda': 0.07745575269148237, 'k': 4, 'epoch': 13, 'decay': 3}. Best is trial#130 with value: 0.5265.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:59,093]\u001b[0m Finished trial#132 with value: 0.526 with parameters: {'lr': 0.08480219309486409, 'lamda': 0.07800645822913875, 'k': 4, 'epoch': 13, 'decay': 3}. Best is trial#130 with value: 0.5265.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 09:49:59,241]\u001b[0m Finished trial#133 with value: 0.526 with parameters: {'lr': 0.09959373947681241, 'lamda': 0.07638058992713734, 'k': 4, 'epoch': 13, 'decay': 3}. Best is trial#130 with value: 0.5265.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-c1d569006695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 334\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 )\n\u001b[1;32m    336\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-77-b0a399434a08>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-bb9e1cf411d4>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(x_data, y_data, lr, lamda, epoch, k, decay)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-d891461c6b44>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mgra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-d891461c6b44>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, y, y_pred, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lambda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cross_validate(X_train_mat100, y,0.001,10)\n",
    "\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective, n_trials=200,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_decay</th>\n",
       "      <th>params_epoch</th>\n",
       "      <th>params_k</th>\n",
       "      <th>params_lamda</th>\n",
       "      <th>params_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>00:00:00.235365</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0.368972</td>\n",
       "      <td>0.016493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>00:00:00.218716</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.089794</td>\n",
       "      <td>0.009743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>00:00:00.233999</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>00:00:00.191209</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.034966</td>\n",
       "      <td>0.001303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0.6085</td>\n",
       "      <td>00:00:00.202923</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.189959</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.001447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.191692</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.185681</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.204314</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.187417</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number   value        duration  ...  params_k  params_lamda  params_lr\n",
       "0         0  0.6045 00:00:00.235365  ...        10      0.368972   0.016493\n",
       "29       29  0.6045 00:00:00.218716  ...        10      0.089794   0.009743\n",
       "8         8  0.6065 00:00:00.233999  ...        10      0.013069   0.000233\n",
       "179     179  0.6075 00:00:00.191209  ...        10      0.034966   0.001303\n",
       "57       57  0.6085 00:00:00.202923  ...        10      0.019213   0.001156\n",
       "..      ...     ...             ...  ...       ...           ...        ...\n",
       "97       97  0.6295 00:00:00.189959  ...         4      0.022685   0.001447\n",
       "95       95  0.6295 00:00:00.191692  ...         4      0.040199   0.001438\n",
       "122     122  0.6295 00:00:00.185681  ...         4      0.024073   0.001434\n",
       "83       83  0.6295 00:00:00.204314  ...         4      0.010491   0.001443\n",
       "128     128  0.6295 00:00:00.187417  ...         4      0.050740   0.001383\n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "\n",
    "df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.623"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(X_tr,y,lamda=0.050740,epoch=10,lr=0.050740,k=4,decay=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  Loss: 0.6931471805599453\n",
      "Epoch : 1  Loss: 0.6614940106899204\n",
      "Epoch : 2  Loss: 0.6576564995558486\n",
      "Epoch : 3  Loss: 0.6530411387034815\n",
      "Epoch : 4  Loss: 0.6529215147131578\n",
      "Epoch : 5  Loss: 0.6529162816687935\n",
      "Epoch : 6  Loss: 0.6529161015244107\n",
      "Epoch : 7  Loss: 0.6529160965206913\n",
      "Epoch : 8  Loss: 0.652916096404326\n",
      "Epoch : 9  Loss: 0.6529160964019987\n",
      "0.6313432835820896\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test\n",
    "# logistic = logisticregression(X_train,y_train,lamda=0.362124,epoch=15,print_every=1,lr=0.000254)\n",
    "#\n",
    "logistic = logisticregression(X_train,y_train,lamda=0.05,epoch=10,lr=0.001383,decay=7,print_every=1)\n",
    "logistic.train()\n",
    "        \n",
    "print(logistic.evaluate(X_train,y_train))\n",
    "print(logistic.evaluate(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_mat100 = scale(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_mat100)):\n",
    "    result = logistic.predict(X_test_mat100[i])\n",
    "    sumbission.append([i,int(result)])\n",
    "    result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('test_64_cross_validated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Bound\n",
       "0    0      1\n",
       "1    1      0\n",
       "2    2      0\n",
       "3    3      0\n",
       "4    4      0\n",
       "5    5      1\n",
       "6    6      1\n",
       "7    7      1\n",
       "8    8      1\n",
       "9    9      0\n",
       "10  10      1\n",
       "11  11      1\n",
       "12  12      0\n",
       "13  13      1\n",
       "14  14      1\n",
       "15  15      1\n",
       "16  16      1\n",
       "17  17      1\n",
       "18  18      0\n",
       "19  19      0\n",
       "20  20      1\n",
       "21  21      0\n",
       "22  22      0\n",
       "23  23      0\n",
       "24  24      1\n",
       "25  25      0\n",
       "26  26      0\n",
       "27  27      1\n",
       "28  28      0\n",
       "29  29      1\n",
       "30  30      0\n",
       "31  31      1\n",
       "32  32      0\n",
       "33  33      0\n",
       "34  34      1\n",
       "35  35      1\n",
       "36  36      1\n",
       "37  37      1\n",
       "38  38      0\n",
       "39  39      0\n",
       "40  40      0\n",
       "41  41      1\n",
       "42  42      0\n",
       "43  43      1\n",
       "44  44      1\n",
       "45  45      0\n",
       "46  46      0\n",
       "47  47      0\n",
       "48  48      1\n",
       "49  49      1"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "# clf = make_pipeline(StandardScaler(), SVC(kernel='poly'))\n",
    "# clf.fit(X_train,y_train)\n",
    "# clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-385-c09fdc54d9ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_later\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "X_later.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X_later)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340,) (660,) (1340, 1) (660, 1) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_tr= X[:2000]\n",
    "X_te = X[2000:]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tr, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape,X_val.shape,y_train.shape, y_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gg gg gt tc ct tg gc cc cc cc cc ca ac ca ag gc cc cc cc ct ta ag gc ct tg gt tt tc cc cg gt tc ct tg gt tt ta at ta ag ga at tt tg gc ca aa ac cc cc cc ct tg gt tg gt tg gg ga aa at tg gc ca ag gt tg gt tc cc ct tt tt tt tc cc cc cc ct ta ag gg gg ga ag gt tg gg gg gt tg gt tg gc ca at tg ga ac ct',\n",
       "       'at tg gt tg gt tg gt ta at tt tt ta aa aa aa aa at ta aa aa ac ct tt tt ta ag gt tt tt tt tt tc ct tc cc ct tc ca at ta at tg ga ag gc ct ta ac ca at tc ca at tt tt tt tc cc ct tg gt tt ta ac ca at ta ag ga aa at tt ta aa at ta aa ac cc ct tg ga aa ac ct ta ag ga ag gt tc cc ct ta at tc ct tc ct tg',\n",
       "       'cg gg gc cc cc ct tt tg gg gg gt ta ag gg ga ac ca ag gg gt tt tt tg gc ct tt tt tg gt ta aa at tg gt tc ct tt tc cc ct tc cc cc ca ac ct tc cc ca ac cc cc cg gc cc ct tc cc cc cc ca ag ga ag gg gt ta ac cc cc ct tt ta ac cc ca ag gt tg gt tc ct tc cc ct tg gg ga aa ac cc ct tt tc cc ca ag ga ag ga',\n",
       "       ...,\n",
       "       'ct tc cc ct tc cc cc ca ac ct tt tc ct tt tc cc ct tc cc cc cg gc cc cc cc cc cg gg gc cc cg gc cc cc cc cg gc cc cc cc ca ag gc cg gc cg gc cc cg gc cc cc cg gc cg gt tg gc ct tg gt tg gc cg gt tc ca at tg gg gc cg gt tc ca ac cg gc cc cc ca ac cc cg gg gg gc cc cc cg gc ct tg gc cg gg gg gc cg gg',\n",
       "       'cg gg gc ca ag ga ag gg gc ca ac ct tg gg gc cc cg gc cg ga ag ga ag gg gc ct tc cg gg gc cc cg gg gg ga ag gt tt tc cc cg gc cg gt tc ct tc cc ca at tc cc cg gg gc cc cg gg gg gt ta ag ga aa at tc cg ga ag gc cg gc cc cg ga ag gc cg ga at tc cg gg gc cc cc ca at tg gg gt tt tg gc ct ta ag gg gc cg',\n",
       "       'tt tc cg gc cc cc cc cc cc ca ac cc ca at tg gt tt tc cc ca ag gc cg gc cc ct tc ct tc cc ca ag gc cc ct tc ct tt tc ct tt tc ca ag gc ca ac cc cc cc cc ct tc cg gc cc cc cc cc cc cg ga aa ag ga ac cc cc cc cg ga ac ct tg gc cc cc cc cc cg gc cg gc cc ct tt tc cg gt tg gt tc cg gg ga ag gg ga ag gg'],\n",
       "      dtype='<U299')"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5424242424242425"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                             ('tfidf', TfidfTransformer()),\n",
    "                             ('clf-svm', LogisticRegression(penalty = 'l2'))])\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

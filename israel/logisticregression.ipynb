{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "import optuna\n",
    "import random\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mat100 = pd.read_csv('../data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('../data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n",
    "X_test_ = pd.read_csv('../data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('../data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "y = pd.read_csv('../data/Ytr.csv',sep=',',index_col=0)\n",
    "\n",
    "train_data = pd.concat([X_train_ , y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (2000, 100) y_train (2000, 1)\n",
      "x_test: (1000, 100)\n"
     ]
    }
   ],
   "source": [
    "print('x_train: {} y_train {}'.format(X_train_mat100.shape,y.shape))\n",
    "print('x_test: {}'.format(X_test_mat100.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y,p):\n",
    "    X = scale(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=64,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "#         hassien = np.dot(y_pred.T,(1-y_pred))*np.linalg.pinv(np.dot(x.T,x))\n",
    "#         return np.dot(hassien,np.dot(x.T,(y_pred-y)))+(2*(self._lambda/len(y_pred))*self.params)\n",
    "        return np.dot(x.T,(y_pred-y))+(2*(self._lambda/len(self.train_labels ))*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(len(self.train_labels)//self.batch_size):\n",
    "                idx = list(np.random.choice(np.arange(len(self.train_labels)),self.batch_size,replace=False))\n",
    "                data = self.train_data[idx]\n",
    "                label = self.train_labels[idx]\n",
    "\n",
    "                y_pred = self.sigmoid(np.dot(data,self.params))\n",
    "                loss = self.cost(label,y_pred)\n",
    "\n",
    "                gra = self.gradient(label,y_pred,data)\n",
    "                self.params -= self.lr*gra\n",
    "\n",
    "                self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=4,batch_size=64,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "        \n",
    "        logistic = logisticregression(x_train,y_train,batch_size=batch_size,lamda=lamda,lr=lr,decay=decay,epoch=epoch,print_every=None)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>Bound</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "      <td>1</td>\n",
       "      <td>gagg aggg gggg gggc ggct gctg ctgg tggg gggg g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "      <td>0</td>\n",
       "      <td>cggc ggcc gcct cctg ctgg tggg gggg gggg gggc g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  seq  ...                                              words\n",
       "Id                                                     ...                                                   \n",
       "0   GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...  ...  gagg aggg gggg gggc ggct gctg ctgg tggg gggg g...\n",
       "1   CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...  ...  cggc ggcc gcct cctg ctgg tggg gggg gggg gggc g...\n",
       "\n",
       "[2 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getKmers(sequence, size=4):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]\n",
    "\n",
    "train_data['words'] = train_data.seq.apply(lambda x: ' '.join(getKmers(x)))\n",
    "X_test_['words'] = X_test_.seq.apply(lambda x: ' '.join(getKmers(x)))\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "data = pd.DataFrame(pd.concat([train_data.words,X_test_.words],axis=0))\n",
    "\n",
    "train_text = data.words.values\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(4,4),max_features=1500,min_df=10)\n",
    "X = cv.fit_transform(train_text)\n",
    "X = X.todense()\n",
    "\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6035"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(np.array(X)[:2000,:],y.values,k=5,lr=0.001,batch_size=128,lamda=0.003,epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     lr = trial.suggest_loguniform('lr', 1e-5, 0.1)\n",
    "#     lamda = trial.suggest_loguniform('lamda', 1e-7, 10)\n",
    "#     k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "#     batch_size =  trial.suggest_categorical('batch_size', [32,64,128])\n",
    "#     epoch =  trial.suggest_int('epoch', 100, 500)\n",
    "#     decay = trial.suggest_int('decay', 3, 10)\n",
    "#     return cross_validate(np.array(X)[:2000,:], y.values,lr=lr,lamda=lamda,batch_size=batch_size,k=k,epoch=epoch,decay=decay)\n",
    "# # cross_validate(X_preprocess, y.reshape(-1,1),lr=0.001,epoch=200)\n",
    "\n",
    "# import optuna\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler()\n",
    "# study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# study.optimize(func=objective, n_trials=1000,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "# df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 4096)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.DataFrame(pd.concat([train_data.words,X_test_.words],axis=0))\n",
    "\n",
    "train_text = data.words.values\n",
    "\n",
    "# X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "\n",
    "kmer_data = []\n",
    "for i in train_text:\n",
    "    kmer_data.append(spectral_embedding(i,kmer_size=6))\n",
    "    \n",
    "np.array(kmer_data).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "svd = TruncatedSVD(n_components=400, n_iter=70, random_state=42)\n",
    "new_data = svd.fit_transform(np.array(kmer_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5385"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(np.array(new_data)[:2000,:],y.values,k=5,lr=0.0001,batch_size=32,lamda=0.003,epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9396ac6e22840899cd68825958d977b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-29 01:13:18,783]\u001b[0m Finished trial#0 with value: 0.5295000000000001 with parameters: {'lr': 0.0632916400956607, 'lamda': 0.0011330288033926789, 'k': 10, 'batch_size': 32, 'epoch': 386, 'decay': 4}. Best is trial#0 with value: 0.5295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:20,193]\u001b[0m Finished trial#1 with value: 0.502 with parameters: {'lr': 0.00036941429779485186, 'lamda': 0.004732258941402768, 'k': 5, 'batch_size': 128, 'epoch': 218, 'decay': 10}. Best is trial#0 with value: 0.5295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:26,306]\u001b[0m Finished trial#2 with value: 0.5105 with parameters: {'lr': 0.005134084157862654, 'lamda': 0.0007022446437509935, 'k': 8, 'batch_size': 32, 'epoch': 424, 'decay': 6}. Best is trial#0 with value: 0.5295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:30,232]\u001b[0m Finished trial#3 with value: 0.5425 with parameters: {'lr': 0.001544779709615576, 'lamda': 0.02641552625205524, 'k': 5, 'batch_size': 32, 'epoch': 244, 'decay': 7}. Best is trial#3 with value: 0.5425.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:33,901]\u001b[0m Finished trial#4 with value: 0.5239999999999999 with parameters: {'lr': 0.04478272324381723, 'lamda': 0.0029364526351993874, 'k': 5, 'batch_size': 64, 'epoch': 375, 'decay': 7}. Best is trial#3 with value: 0.5425.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:37,747]\u001b[0m Finished trial#5 with value: 0.518 with parameters: {'lr': 0.00634900034036742, 'lamda': 0.0027568565802964626, 'k': 10, 'batch_size': 32, 'epoch': 252, 'decay': 3}. Best is trial#3 with value: 0.5425.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:44,298]\u001b[0m Finished trial#6 with value: 0.5125 with parameters: {'lr': 1.0884425412003495e-05, 'lamda': 5.680257751834066e-06, 'k': 8, 'batch_size': 32, 'epoch': 462, 'decay': 10}. Best is trial#3 with value: 0.5425.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:49,786]\u001b[0m Finished trial#7 with value: 0.5225 with parameters: {'lr': 2.2915938786163194e-05, 'lamda': 0.2772661084903859, 'k': 10, 'batch_size': 32, 'epoch': 355, 'decay': 3}. Best is trial#3 with value: 0.5425.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:51,283]\u001b[0m Finished trial#8 with value: 0.575 with parameters: {'lr': 0.00011123741742157515, 'lamda': 4.031894921690212e-05, 'k': 4, 'batch_size': 128, 'epoch': 300, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:58,983]\u001b[0m Finished trial#9 with value: 0.5145 with parameters: {'lr': 0.06003668850341371, 'lamda': 1.6929382746673677e-07, 'k': 5, 'batch_size': 32, 'epoch': 449, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:59,719]\u001b[0m Finished trial#10 with value: 0.575 with parameters: {'lr': 8.086051011272396e-05, 'lamda': 1.1304407369480036e-05, 'k': 4, 'batch_size': 128, 'epoch': 124, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:00,417]\u001b[0m Finished trial#11 with value: 0.531 with parameters: {'lr': 8.502719532889534e-05, 'lamda': 1.1447349362482038e-05, 'k': 4, 'batch_size': 128, 'epoch': 120, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:01,176]\u001b[0m Finished trial#12 with value: 0.5589999999999999 with parameters: {'lr': 9.645419546670895e-05, 'lamda': 1.7228413109698663e-05, 'k': 4, 'batch_size': 128, 'epoch': 130, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:02,727]\u001b[0m Finished trial#13 with value: 0.554 with parameters: {'lr': 7.914999043826342e-05, 'lamda': 2.0006540016170916e-07, 'k': 4, 'batch_size': 128, 'epoch': 310, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:03,732]\u001b[0m Finished trial#14 with value: 0.5075000000000001 with parameters: {'lr': 0.0003812860782644816, 'lamda': 7.1060786862306e-05, 'k': 4, 'batch_size': 128, 'epoch': 186, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:05,407]\u001b[0m Finished trial#15 with value: 0.5295 with parameters: {'lr': 2.826006771493286e-05, 'lamda': 1.2821984233982087e-06, 'k': 4, 'batch_size': 128, 'epoch': 311, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:07,180]\u001b[0m Finished trial#16 with value: 0.5445 with parameters: {'lr': 0.0003019987217471261, 'lamda': 0.00013945788727529268, 'k': 4, 'batch_size': 64, 'epoch': 191, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:08,606]\u001b[0m Finished trial#17 with value: 0.5235 with parameters: {'lr': 0.0011737472860821755, 'lamda': 1.1555684958395443e-06, 'k': 4, 'batch_size': 128, 'epoch': 281, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:09,483]\u001b[0m Finished trial#18 with value: 0.528 with parameters: {'lr': 1.0376176980337512e-05, 'lamda': 9.772650890139182e-05, 'k': 4, 'batch_size': 128, 'epoch': 163, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:12,035]\u001b[0m Finished trial#19 with value: 0.53 with parameters: {'lr': 3.9642165326893164e-05, 'lamda': 1.0017501143469832e-06, 'k': 8, 'batch_size': 64, 'epoch': 338, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:13,441]\u001b[0m Finished trial#20 with value: 0.539 with parameters: {'lr': 0.0001859589728418411, 'lamda': 9.119252550819718, 'k': 4, 'batch_size': 128, 'epoch': 267, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:14,069]\u001b[0m Finished trial#21 with value: 0.553 with parameters: {'lr': 8.842809616644369e-05, 'lamda': 1.631805432249667e-05, 'k': 4, 'batch_size': 128, 'epoch': 104, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:14,783]\u001b[0m Finished trial#22 with value: 0.554 with parameters: {'lr': 0.00016840662419327575, 'lamda': 3.95466579638583e-05, 'k': 4, 'batch_size': 128, 'epoch': 123, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:15,629]\u001b[0m Finished trial#23 with value: 0.5055000000000001 with parameters: {'lr': 0.0006054665335590388, 'lamda': 0.0002442153095063557, 'k': 4, 'batch_size': 128, 'epoch': 146, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:16,915]\u001b[0m Finished trial#24 with value: 0.558 with parameters: {'lr': 4.7853700453979647e-05, 'lamda': 3.793467247889592e-06, 'k': 4, 'batch_size': 128, 'epoch': 223, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:17,733]\u001b[0m Finished trial#25 with value: 0.522 with parameters: {'lr': 1.3767136139994911e-05, 'lamda': 2.7981455375969346e-05, 'k': 4, 'batch_size': 128, 'epoch': 150, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:18,354]\u001b[0m Finished trial#26 with value: 0.5235000000000001 with parameters: {'lr': 0.002615490875511397, 'lamda': 2.228325309480463e-06, 'k': 4, 'batch_size': 128, 'epoch': 100, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:19,430]\u001b[0m Finished trial#27 with value: 0.539 with parameters: {'lr': 0.00015848372089481304, 'lamda': 2.7258821735041835e-07, 'k': 4, 'batch_size': 128, 'epoch': 197, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:23,726]\u001b[0m Finished trial#28 with value: 0.5535 with parameters: {'lr': 6.703616323435356e-05, 'lamda': 0.00024367621662474846, 'k': 4, 'batch_size': 64, 'epoch': 496, 'decay': 3}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:25,181]\u001b[0m Finished trial#29 with value: 0.5285 with parameters: {'lr': 0.0006759882191539533, 'lamda': 0.0005709313977751506, 'k': 10, 'batch_size': 128, 'epoch': 335, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:26,594]\u001b[0m Finished trial#30 with value: 0.5295000000000001 with parameters: {'lr': 2.1481573807256335e-05, 'lamda': 7.731515032980205e-06, 'k': 8, 'batch_size': 128, 'epoch': 400, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:27,811]\u001b[0m Finished trial#31 with value: 0.537 with parameters: {'lr': 5.192393350005952e-05, 'lamda': 6.3476285279636065e-06, 'k': 4, 'batch_size': 128, 'epoch': 227, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:29,284]\u001b[0m Finished trial#32 with value: 0.5405 with parameters: {'lr': 0.00012414852456918505, 'lamda': 2.5910652825557494e-06, 'k': 4, 'batch_size': 128, 'epoch': 286, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:30,381]\u001b[0m Finished trial#33 with value: 0.504 with parameters: {'lr': 3.8112354562603355e-05, 'lamda': 5.581508983310256e-07, 'k': 4, 'batch_size': 128, 'epoch': 219, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:31,283]\u001b[0m Finished trial#34 with value: 0.534 with parameters: {'lr': 0.00027440115660225386, 'lamda': 2.9328832914872325e-05, 'k': 4, 'batch_size': 128, 'epoch': 169, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:32,164]\u001b[0m Finished trial#35 with value: 0.5529999999999999 with parameters: {'lr': 1.60698186905249e-05, 'lamda': 4.93892013595567e-06, 'k': 5, 'batch_size': 128, 'epoch': 123, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:33,112]\u001b[0m Finished trial#36 with value: 0.514 with parameters: {'lr': 4.597706319395814e-05, 'lamda': 0.013474656321730533, 'k': 10, 'batch_size': 128, 'epoch': 208, 'decay': 9}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:34,362]\u001b[0m Finished trial#37 with value: 0.5565 with parameters: {'lr': 0.00012478184441692963, 'lamda': 0.000545225980638643, 'k': 4, 'batch_size': 128, 'epoch': 245, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:36,546]\u001b[0m Finished trial#38 with value: 0.522 with parameters: {'lr': 0.026892712609313443, 'lamda': 5.5187168065487016e-05, 'k': 8, 'batch_size': 64, 'epoch': 267, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:39,285]\u001b[0m Finished trial#39 with value: 0.5525 with parameters: {'lr': 0.00024607985833574565, 'lamda': 0.0013682145744994356, 'k': 5, 'batch_size': 32, 'epoch': 171, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:40,084]\u001b[0m Finished trial#40 with value: 0.54 with parameters: {'lr': 0.0005994530490685158, 'lamda': 1.749299196026673e-05, 'k': 4, 'batch_size': 128, 'epoch': 141, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:41,316]\u001b[0m Finished trial#41 with value: 0.539 with parameters: {'lr': 0.00012249101312350363, 'lamda': 0.000875497867669626, 'k': 4, 'batch_size': 128, 'epoch': 235, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:42,633]\u001b[0m Finished trial#42 with value: 0.543 with parameters: {'lr': 0.00011269521071708726, 'lamda': 0.0003589502427554007, 'k': 4, 'batch_size': 128, 'epoch': 250, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:44,178]\u001b[0m Finished trial#43 with value: 0.513 with parameters: {'lr': 2.5671851974469132e-05, 'lamda': 0.07552095299117584, 'k': 4, 'batch_size': 128, 'epoch': 295, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:45,835]\u001b[0m Finished trial#44 with value: 0.5365 with parameters: {'lr': 6.215743121904885e-05, 'lamda': 0.002466783205391313, 'k': 4, 'batch_size': 128, 'epoch': 320, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:51,271]\u001b[0m Finished trial#45 with value: 0.5345000000000001 with parameters: {'lr': 0.00044675180466494433, 'lamda': 0.008034829277630445, 'k': 10, 'batch_size': 32, 'epoch': 357, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:52,563]\u001b[0m Finished trial#46 with value: 0.5469999999999999 with parameters: {'lr': 0.00020714762544684414, 'lamda': 0.00011372456530595206, 'k': 4, 'batch_size': 128, 'epoch': 256, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:53,763]\u001b[0m Finished trial#47 with value: 0.5105 with parameters: {'lr': 3.155578597847728e-05, 'lamda': 3.5592877509134634e-06, 'k': 4, 'batch_size': 128, 'epoch': 239, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:55,047]\u001b[0m Finished trial#48 with value: 0.5700000000000001 with parameters: {'lr': 8.044722556884015e-05, 'lamda': 3.813639478602786e-07, 'k': 5, 'batch_size': 128, 'epoch': 207, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:55,846]\u001b[0m Finished trial#49 with value: 0.5385 with parameters: {'lr': 8.125121761119499e-05, 'lamda': 5.394676685904629e-07, 'k': 5, 'batch_size': 128, 'epoch': 112, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:59,096]\u001b[0m Finished trial#50 with value: 0.517 with parameters: {'lr': 1.898016752820647e-05, 'lamda': 1.4524177111957761e-07, 'k': 5, 'batch_size': 32, 'epoch': 199, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:00,812]\u001b[0m Finished trial#51 with value: 0.5555000000000001 with parameters: {'lr': 5.8261022352718983e-05, 'lamda': 1.3004958032867918e-05, 'k': 5, 'batch_size': 128, 'epoch': 268, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:02,002]\u001b[0m Finished trial#52 with value: 0.5415 with parameters: {'lr': 0.00010794542257056588, 'lamda': 4.7643353747512736e-07, 'k': 5, 'batch_size': 128, 'epoch': 180, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:03,378]\u001b[0m Finished trial#53 with value: 0.5635 with parameters: {'lr': 4.5726284016493235e-05, 'lamda': 2.0751358235679333e-06, 'k': 5, 'batch_size': 128, 'epoch': 213, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:04,356]\u001b[0m Finished trial#54 with value: 0.5439999999999999 with parameters: {'lr': 3.3895458299760385e-05, 'lamda': 1.5785800552895804e-06, 'k': 5, 'batch_size': 128, 'epoch': 139, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:05,723]\u001b[0m Finished trial#55 with value: 0.5495 with parameters: {'lr': 4.585322077448876e-05, 'lamda': 1.1003294113214873e-07, 'k': 5, 'batch_size': 128, 'epoch': 204, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:07,325]\u001b[0m Finished trial#56 with value: 0.5235000000000001 with parameters: {'lr': 1.148962869473803e-05, 'lamda': 8.282738791023858e-07, 'k': 5, 'batch_size': 64, 'epoch': 158, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:08,709]\u001b[0m Finished trial#57 with value: 0.5705 with parameters: {'lr': 8.10228415075201e-05, 'lamda': 3.9282454077588644e-06, 'k': 5, 'batch_size': 128, 'epoch': 216, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:09,916]\u001b[0m Finished trial#58 with value: 0.538 with parameters: {'lr': 8.89453507479397e-05, 'lamda': 9.634629504908627e-06, 'k': 5, 'batch_size': 128, 'epoch': 183, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:10,840]\u001b[0m Finished trial#59 with value: 0.5685 with parameters: {'lr': 0.0001652702378672429, 'lamda': 3.581236001506453e-07, 'k': 5, 'batch_size': 128, 'epoch': 132, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:12,234]\u001b[0m Finished trial#60 with value: 0.513 with parameters: {'lr': 0.0003633218634492064, 'lamda': 2.2180804848320573e-06, 'k': 5, 'batch_size': 128, 'epoch': 213, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:13,104]\u001b[0m Finished trial#61 with value: 0.5415 with parameters: {'lr': 0.00018662096427224663, 'lamda': 2.693991279012081e-07, 'k': 5, 'batch_size': 128, 'epoch': 125, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:14,008]\u001b[0m Finished trial#62 with value: 0.515 with parameters: {'lr': 6.350969461131732e-05, 'lamda': 1.1085339191017714e-06, 'k': 5, 'batch_size': 128, 'epoch': 132, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:14,821]\u001b[0m Finished trial#63 with value: 0.5395 with parameters: {'lr': 0.00016109442391446893, 'lamda': 1.785871328401329e-05, 'k': 5, 'batch_size': 128, 'epoch': 110, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:15,912]\u001b[0m Finished trial#64 with value: 0.5465 with parameters: {'lr': 9.376237185064086e-05, 'lamda': 3.0660179218918104e-07, 'k': 5, 'batch_size': 128, 'epoch': 156, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:17,120]\u001b[0m Finished trial#65 with value: 0.549 with parameters: {'lr': 7.447439659643015e-05, 'lamda': 5.461006959814625e-05, 'k': 5, 'batch_size': 128, 'epoch': 176, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:19,205]\u001b[0m Finished trial#66 with value: 0.5605 with parameters: {'lr': 0.00014725796363864653, 'lamda': 5.374020662833216e-06, 'k': 5, 'batch_size': 128, 'epoch': 328, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:21,352]\u001b[0m Finished trial#67 with value: 0.5334999999999999 with parameters: {'lr': 0.00023699783080962175, 'lamda': 4.8725764694314115e-06, 'k': 5, 'batch_size': 128, 'epoch': 326, 'decay': 3}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:23,402]\u001b[0m Finished trial#68 with value: 0.5085 with parameters: {'lr': 0.0010351088614982244, 'lamda': 1.6930738690631458e-06, 'k': 5, 'batch_size': 128, 'epoch': 306, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:25,617]\u001b[0m Finished trial#69 with value: 0.5395 with parameters: {'lr': 0.0001341686869822063, 'lamda': 1.0069031898819334e-07, 'k': 5, 'batch_size': 128, 'epoch': 351, 'decay': 4}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:28,350]\u001b[0m Finished trial#70 with value: 0.5650000000000001 with parameters: {'lr': 0.00033963104511079527, 'lamda': 7.616530971095714e-06, 'k': 5, 'batch_size': 64, 'epoch': 282, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:32,061]\u001b[0m Finished trial#71 with value: 0.536 with parameters: {'lr': 0.0003540606826391458, 'lamda': 7.2693072680459555e-06, 'k': 5, 'batch_size': 64, 'epoch': 384, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:34,793]\u001b[0m Finished trial#72 with value: 0.5635000000000001 with parameters: {'lr': 0.0004607020289628111, 'lamda': 2.9951757983630606e-06, 'k': 5, 'batch_size': 64, 'epoch': 288, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:37,592]\u001b[0m Finished trial#73 with value: 0.5640000000000001 with parameters: {'lr': 0.0005252519446745035, 'lamda': 2.6079979269063313e-06, 'k': 5, 'batch_size': 64, 'epoch': 296, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:39,840]\u001b[0m Finished trial#74 with value: 0.517 with parameters: {'lr': 0.00046177217753409923, 'lamda': 2.4128604968963163e-05, 'k': 8, 'batch_size': 64, 'epoch': 283, 'decay': 9}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:42,712]\u001b[0m Finished trial#75 with value: 0.492 with parameters: {'lr': 0.0016683272260063788, 'lamda': 7.904492577844647e-07, 'k': 5, 'batch_size': 64, 'epoch': 300, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:45,242]\u001b[0m Finished trial#76 with value: 0.5225000000000001 with parameters: {'lr': 0.0006948248180151175, 'lamda': 3.415843072038099e-06, 'k': 5, 'batch_size': 64, 'epoch': 265, 'decay': 9}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:47,999]\u001b[0m Finished trial#77 with value: 0.5295 with parameters: {'lr': 0.001517190084244765, 'lamda': 3.9997163854629386e-07, 'k': 5, 'batch_size': 64, 'epoch': 278, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:50,800]\u001b[0m Finished trial#78 with value: 0.5180000000000001 with parameters: {'lr': 0.000299861732036808, 'lamda': 3.852544545579221e-05, 'k': 10, 'batch_size': 64, 'epoch': 292, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:53,857]\u001b[0m Finished trial#79 with value: 0.5189999999999999 with parameters: {'lr': 0.0007915199203554433, 'lamda': 1.9021510842525293e-07, 'k': 5, 'batch_size': 64, 'epoch': 317, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:55,987]\u001b[0m Finished trial#80 with value: 0.5335000000000001 with parameters: {'lr': 0.00048143455758006284, 'lamda': 1.1969899071796718e-05, 'k': 5, 'batch_size': 64, 'epoch': 230, 'decay': 9}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:15:58,706]\u001b[0m Finished trial#81 with value: 0.569 with parameters: {'lr': 0.00022522226642422404, 'lamda': 2.3485934028389318e-06, 'k': 5, 'batch_size': 64, 'epoch': 306, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:01,899]\u001b[0m Finished trial#82 with value: 0.562 with parameters: {'lr': 0.0002132261287402184, 'lamda': 3.259878189311765e-06, 'k': 5, 'batch_size': 64, 'epoch': 338, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:04,627]\u001b[0m Finished trial#83 with value: 0.5245 with parameters: {'lr': 0.00026706485157287934, 'lamda': 7.616671163288559e-07, 'k': 5, 'batch_size': 64, 'epoch': 307, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:06,874]\u001b[0m Finished trial#84 with value: 0.5495 with parameters: {'lr': 0.0003396575866021505, 'lamda': 7.229901444174696e-06, 'k': 5, 'batch_size': 64, 'epoch': 256, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:08,874]\u001b[0m Finished trial#85 with value: 0.5345 with parameters: {'lr': 0.0005445287206973609, 'lamda': 1.294380202515499e-06, 'k': 8, 'batch_size': 64, 'epoch': 281, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:11,305]\u001b[0m Finished trial#86 with value: 0.5509999999999999 with parameters: {'lr': 0.00017404980374860935, 'lamda': 9.498548771330697, 'k': 5, 'batch_size': 64, 'epoch': 272, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:13,965]\u001b[0m Finished trial#87 with value: 0.506 with parameters: {'lr': 0.0008542558549941299, 'lamda': 2.5645680113315673e-06, 'k': 5, 'batch_size': 64, 'epoch': 301, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:16,567]\u001b[0m Finished trial#88 with value: 0.5425 with parameters: {'lr': 0.00042325451668698326, 'lamda': 1.0136164440205443e-05, 'k': 5, 'batch_size': 64, 'epoch': 293, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:19,433]\u001b[0m Finished trial#89 with value: 0.5495 with parameters: {'lr': 0.00013386118131951326, 'lamda': 7.54465506137287e-05, 'k': 5, 'batch_size': 64, 'epoch': 315, 'decay': 9}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:21,774]\u001b[0m Finished trial#90 with value: 0.5389999999999999 with parameters: {'lr': 0.00023486091022121194, 'lamda': 1.943375085994425e-05, 'k': 10, 'batch_size': 64, 'epoch': 260, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:25,567]\u001b[0m Finished trial#91 with value: 0.5435000000000001 with parameters: {'lr': 0.00010486304880987264, 'lamda': 1.793795836209383e-06, 'k': 5, 'batch_size': 32, 'epoch': 249, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:28,646]\u001b[0m Finished trial#92 with value: 0.5254999999999999 with parameters: {'lr': 4.320861863399486e-05, 'lamda': 1.9939050459383418, 'k': 5, 'batch_size': 64, 'epoch': 348, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:30,677]\u001b[0m Finished trial#93 with value: 0.5275 with parameters: {'lr': 5.4795847166228424e-05, 'lamda': 6.143944154005033e-07, 'k': 5, 'batch_size': 64, 'epoch': 222, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:32,095]\u001b[0m Finished trial#94 with value: 0.521 with parameters: {'lr': 9.142219875385548e-05, 'lamda': 4.61572214923788e-06, 'k': 5, 'batch_size': 128, 'epoch': 237, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:33,750]\u001b[0m Finished trial#95 with value: 0.5705 with parameters: {'lr': 7.299991603211328e-05, 'lamda': 3.4079184559679945e-07, 'k': 5, 'batch_size': 128, 'epoch': 275, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:36,161]\u001b[0m Finished trial#96 with value: 0.528 with parameters: {'lr': 6.64572733294152e-05, 'lamda': 3.884626602264099e-07, 'k': 5, 'batch_size': 64, 'epoch': 273, 'decay': 8}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:37,825]\u001b[0m Finished trial#97 with value: 0.5449999999999999 with parameters: {'lr': 0.00019264979458155223, 'lamda': 1.642821059109405e-07, 'k': 5, 'batch_size': 128, 'epoch': 287, 'decay': 5}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:39,712]\u001b[0m Finished trial#98 with value: 0.51 with parameters: {'lr': 0.00028291570339338836, 'lamda': 0.0001874359641896163, 'k': 5, 'batch_size': 128, 'epoch': 324, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:44,616]\u001b[0m Finished trial#99 with value: 0.5315000000000001 with parameters: {'lr': 7.178714530051553e-05, 'lamda': 2.350256900399825e-07, 'k': 4, 'batch_size': 32, 'epoch': 310, 'decay': 7}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:46,436]\u001b[0m Finished trial#100 with value: 0.5660000000000001 with parameters: {'lr': 0.00015159738121938896, 'lamda': 1.1337544677684572e-06, 'k': 5, 'batch_size': 128, 'epoch': 290, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:48,248]\u001b[0m Finished trial#101 with value: 0.5505 with parameters: {'lr': 0.00014982723473767805, 'lamda': 1.1532473938889432e-06, 'k': 5, 'batch_size': 128, 'epoch': 293, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:16:49,977]\u001b[0m Finished trial#102 with value: 0.5325 with parameters: {'lr': 8.141589890913176e-05, 'lamda': 2.602189910302477e-06, 'k': 5, 'batch_size': 128, 'epoch': 277, 'decay': 6}. Best is trial#8 with value: 0.575.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-91b2ea59a0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 334\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 )\n\u001b[1;32m    336\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-22-91b2ea59a0c2>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# cross_validate(X_preprocess, y.reshape(-1,1),lr=0.001,epoch=200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-10099b4a71b1>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(x_data, y_data, lr, lamda, epoch, k, batch_size, decay)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1f71cd941415>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 0.1)\n",
    "    lamda = trial.suggest_loguniform('lamda', 1e-7, 10)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "    batch_size =  trial.suggest_categorical('batch_size', [32,64,128])\n",
    "    epoch =  trial.suggest_int('epoch', 100, 500)\n",
    "    decay = trial.suggest_int('decay', 3, 10)\n",
    "    return cross_validate(np.array(new_data)[:2000,:], y.values,lr=lr,lamda=lamda,batch_size=batch_size,k=k,epoch=epoch,decay=decay)\n",
    "# cross_validate(X_preprocess, y.reshape(-1,1),lr=0.001,epoch=200)\n",
    "\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective, n_trials=1000,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamda=1.576611e-06,lr=0.018755,decay=6,epoch=200,batch_size=128,print_every=None\n",
    "\n",
    "\n",
    "list_in = np.array(list(X_train_.flatten())+list(X_test_.flatten()))\n",
    "list_in.astype(type(X_train_))\n",
    "list_in = list_in.reshape(-1,1)\n",
    "list_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DNA sequence as a language, known as k-mer counting\n",
    "def getKmers(sequence, size):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]\n",
    "def get_n_grams(data1,n):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "\n",
    "    cv = CountVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    for i in data1:\n",
    "        sentence = ' '.join(getKmers(i[0], size=n))\n",
    "        X_train.append(sentence)\n",
    "        \n",
    "    X_cocat = X_train\n",
    "    X = cv.fit_transform(X_cocat).toarray()\n",
    "    return X\n",
    "\n",
    "X_preprocess = get_n_grams(X_train_,7)\n",
    "\n",
    "# def objective(trial):\n",
    "#     lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "#     lamda = trial.suggest_loguniform('lamda', 0.01, 0.5)\n",
    "#     k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "#     epoch =  trial.suggest_int('epoch', 10, 20)\n",
    "#     decay = trial.suggest_int('decay', 3, 10)\n",
    "#     return cross_validate(X_preprocess[:2000,:], y,lr=lr,lamda=lamda,k=k,epoch=epoch,decay=decay)\n",
    "\n",
    "cross_validate(X_preprocess[:2000], y,0.001,20,k=5,epoch=10,decay=10)\n",
    "\n",
    "# import optuna\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler()\n",
    "# study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# study.optimize(func=objective, n_trials=100,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "# df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count Vectorizer \n",
    "# def get_count_grams(data1,n):\n",
    "#     cv = CountVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "#     X = cv.fit_transform(data1).toarray()\n",
    "#     return X\n",
    "\n",
    "# X_preprocess = get_n_grams(X_train_.flatten(),8)\n",
    "\n",
    "# # def objective(trial):\n",
    "# #     lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "# #     lamda = trial.suggest_loguniform('lamda', 0.01, 0.5)\n",
    "# #     k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "# #     epoch =  trial.suggest_int('epoch', 10, 20)\n",
    "# #     decay = trial.suggest_int('decay', 3, 10)\n",
    "# #     return cross_validate(X_preprocess, y,lr=lr,lamda=lamda,k=k,epoch=epoch,decay=decay)\n",
    "\n",
    "# cross_validate(X_preprocess[:2000], y,0.0001,20,k=5,epoch=10,decay=10)\n",
    "\n",
    "# # import optuna\n",
    "\n",
    "# # sampler = optuna.samplers.TPESampler()\n",
    "# # study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# # study.optimize(func=objective, n_trials=200,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "# df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(X_preprocess, y,lr=0.004433,lamda=0.432127,k=4,epoch=16,decay=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Vectorizer \n",
    "def get_tf_idf_grams(data1,n):\n",
    "    cv = TfidfVectorizer(analyzer='char',ngram_range=(n,n))\n",
    "    X = cv.fit_transform(data1).toarray()\n",
    "    return X\n",
    "\n",
    "X_preprocess = get_tf_idf_grams(X_train_.flatten(),8)\n",
    "\n",
    "# def objective(trial):\n",
    "#     lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "#     lamda = trial.suggest_loguniform('lamda', 0.01, 0.5)\n",
    "#     k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "#     epoch =  trial.suggest_int('epoch', 10, 20)\n",
    "#     decay = trial.suggest_int('decay', 3, 10)\n",
    "#     return cross_validate(X_preprocess, y,lr=lr,lamda=lamda,k=k,epoch=epoch,decay=decay)\n",
    "\n",
    "cross_validate(X_preprocess[:2000], y,0.001,20,k=5,epoch=10,decay=10)\n",
    "\n",
    "# import optuna\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler()\n",
    "# study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# study.optimize(func=objective, n_trials=100,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "# df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After testing all possible dataset preprocessing type now lets stick to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test(X_preprocess[:2000],y,0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 1500) (600, 1500) (1400, 1) (600, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7957142857142857\n",
      "0.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.631"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_preprocess = get_n_grams(X_train_,8)\n",
    "# X_preprocess.shape\n",
    "\n",
    "# print(cross_validate(X_preprocess[:2000,:], y,lr=0.001,lamda=15,k=4,epoch=16,decay=10))\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(np.array(X)[:2000,:],y.values,0.3)\n",
    "\n",
    "# y,0.001,15,k=5,epoch=10,decay=10)\n",
    "\n",
    "logistic = logisticregression(X_train,y_train,lamda=1.576611e-06,lr=0.018755,decay=6,epoch=200,batch_size=128,print_every=None)\n",
    "logistic.train()\n",
    "        \n",
    "print(logistic.evaluate(X_train,y_train))\n",
    "print(logistic.evaluate(X_test,y_test))\n",
    "cross_validate(np.array(X)[:2000,:], y.values,lamda=1.576611e-06,lr=0.018755,decay=6,epoch=200,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 4096) (600, 4096) (1400, 1) (600, 1)\n",
      "Epoch : 0  Loss: 0.6931471805599454\n",
      "Epoch : 1  Loss: 0.369619629360289\n",
      "Epoch : 2  Loss: 0.24093457515641262\n",
      "Epoch : 3  Loss: 0.23515736618853034\n",
      "Epoch : 4  Loss: 0.2349297795537864\n",
      "Epoch : 5  Loss: 0.23492310904273742\n",
      "Epoch : 6  Loss: 0.23492296082415293\n",
      "Epoch : 7  Loss: 0.23492295817739842\n",
      "Epoch : 8  Loss: 0.23492295813789463\n",
      "Epoch : 9  Loss: 0.2349229581373882\n",
      "0.9664285714285714\n",
      "0.6433333333333333\n"
     ]
    }
   ],
   "source": [
    "X_preprocess = get_count_grams(np.vstack((X_train_,X_test_)).flatten(),6)\n",
    "X_preprocess.shape\n",
    "\n",
    "cross_validate(X_preprocess[:2000,:], y,lr=0.004433,lamda=0.432127,k=4,epoch=16,decay=4)\n",
    "\n",
    "C_count_6 = X_preprocess[2000:,:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(X_preprocess[:2000,:],y,0.3)\n",
    "\n",
    "\n",
    "logistic_count6 = logisticregression(X_train,y_train,lamda=0.455265,epoch=10,print_every=1,lr=0.000407,decay=11)\n",
    "logistic_count6.train()\n",
    "        \n",
    "print(logistic_count6.evaluate(X_train,y_train))\n",
    "print(logistic_count6.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 256) (600, 256) (1400, 1) (600, 1)\n",
      "Epoch : 0  Loss: 0.6931471805599454\n",
      "Epoch : 1  Loss: 0.6286425932017687\n",
      "Epoch : 2  Loss: 0.6042153578172307\n",
      "Epoch : 3  Loss: 0.6027152714606171\n",
      "Epoch : 4  Loss: 0.6026532220481413\n",
      "Epoch : 5  Loss: 0.6026514005159469\n",
      "Epoch : 6  Loss: 0.6026513600396904\n",
      "Epoch : 7  Loss: 0.6026513593169011\n",
      "Epoch : 8  Loss: 0.6026513593061132\n",
      "Epoch : 9  Loss: 0.6026513593059748\n",
      "0.6907142857142857\n",
      "0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_preprocess = get_count_grams(np.vstack((X_train_,X_test_)).flatten(),4)\n",
    "X_preprocess.shape\n",
    "\n",
    "print(cross_validate(X_preprocess[:2000,:], y,lr=0.004433,lamda=0.432127,k=4,epoch=16,decay=7))\n",
    "\n",
    "C_count_4 = X_preprocess[2000:,:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(X_preprocess[:2000,:],y,0.3)\n",
    "\n",
    "\n",
    "logistic_count4 = logisticregression(X_train,y_train,lamda=0.455265,epoch=10,print_every=1,lr=0.000407,decay=11)\n",
    "logistic_count4.train()\n",
    "        \n",
    "print(logistic_count4.evaluate(X_train,y_train))\n",
    "print(logistic_count4.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 256) (600, 256) (1400, 1) (600, 1)\n",
      "Epoch : 0  Loss: 0.6931471805599454\n",
      "Epoch : 1  Loss: 0.6260173199159424\n",
      "Epoch : 2  Loss: 0.6002614260404124\n",
      "Epoch : 3  Loss: 0.598726394674755\n",
      "Epoch : 4  Loss: 0.5986622185693936\n",
      "Epoch : 5  Loss: 0.5986603339307318\n",
      "Epoch : 6  Loss: 0.5986602920517511\n",
      "Epoch : 7  Loss: 0.598660291303913\n",
      "Epoch : 8  Loss: 0.5986602912927511\n",
      "Epoch : 9  Loss: 0.5986602912926081\n",
      "0.7028571428571428\n",
      "0.5966666666666667\n"
     ]
    }
   ],
   "source": [
    "X_preprocess = get_tf_idf_grams(np.vstack((X_train_,X_test_)).flatten(),4)\n",
    "X_preprocess.shape\n",
    "\n",
    "cross_validate(X_preprocess[:2000,:], y,lr=0.004433,lamda=0.432127,k=4,epoch=16,decay=4)\n",
    "\n",
    "C_tf_4 = X_preprocess[2000:,:]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(X_preprocess[:2000,:],y,0.3)\n",
    "\n",
    "\n",
    "logistic_tf4 = logisticregression(X_train,y_train,lamda=0.455265,epoch=10,print_every=1,lr=0.000407,decay=11)\n",
    "logistic_tf4.train()\n",
    "        \n",
    "print(logistic_tf4.evaluate(X_train,y_train))\n",
    "print(logistic_tf4.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 4096) (600, 4096) (1400, 1) (600, 1)\n",
      "Epoch : 0  Loss: 0.6931471805599454\n",
      "Epoch : 1  Loss: 0.3746954683721624\n",
      "Epoch : 2  Loss: 0.23994925474338094\n",
      "Epoch : 3  Loss: 0.23422424550847226\n",
      "Epoch : 4  Loss: 0.23399751150543982\n",
      "Epoch : 5  Loss: 0.23399086485544413\n",
      "Epoch : 6  Loss: 0.23399071716632397\n",
      "Epoch : 7  Loss: 0.2339907145290239\n",
      "Epoch : 8  Loss: 0.2339907144896612\n",
      "Epoch : 9  Loss: 0.23399071448915654\n",
      "0.9635714285714285\n",
      "0.6433333333333333\n"
     ]
    }
   ],
   "source": [
    "X_preprocess = get_tf_idf_grams(np.vstack((X_train_,X_test_)).flatten(),6)\n",
    "X_preprocess.shape\n",
    "\n",
    "cross_validate(X_preprocess[:2000,:], y,lr=0.004433,lamda=0.432127,k=4,epoch=16,decay=7)\n",
    "\n",
    "C_tf_6 = X_preprocess[2000:,:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test(X_preprocess[:2000,:],y,0.3)\n",
    "\n",
    "\n",
    "logistic_tf6 = logisticregression(X_train,y_train,lamda=0.455265,epoch=10,print_every=1,lr=0.000407,decay=11)\n",
    "logistic_tf6.train()\n",
    "        \n",
    "print(logistic_tf6.evaluate(X_train,y_train))\n",
    "print(logistic_tf6.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = scale(np.array(X)[:2000,:])\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = logistic.predict(X_test_final[i])\n",
    "#     r2 = logistic_count6.predict(C_count_6[i])\n",
    "#     r3 = logistic_tf4.predict(C_tf_4[i])\n",
    "#     r4 = logistic_tf6.predict(C_tf_6[i])\n",
    "    \n",
    "    \n",
    "#     votes = [r1[0],r2[0],r3[0],r4[0]]\n",
    "    \n",
    "#     print(Counter(votes))\n",
    "#     print(Counter(votes).most_common(1)[0][0])\n",
    "    \n",
    "#     break\n",
    "#     sumbission.append([i,int(Counter(votes).most_common(1)[0][0])])\n",
    "    \n",
    "    sumbission.append([i,int(r1)])\n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_64.4.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Bound\n",
       "0    0      1\n",
       "1    1      0\n",
       "2    2      1\n",
       "3    3      0\n",
       "4    4      1\n",
       "5    5      1\n",
       "6    6      1\n",
       "7    7      0\n",
       "8    8      1\n",
       "9    9      1\n",
       "10  10      1\n",
       "11  11      0\n",
       "12  12      0\n",
       "13  13      0\n",
       "14  14      0\n",
       "15  15      0\n",
       "16  16      0\n",
       "17  17      0\n",
       "18  18      0\n",
       "19  19      1\n",
       "20  20      1\n",
       "21  21      1\n",
       "22  22      0\n",
       "23  23      1\n",
       "24  24      0\n",
       "25  25      1\n",
       "26  26      1\n",
       "27  27      0\n",
       "28  28      0\n",
       "29  29      0\n",
       "30  30      0\n",
       "31  31      0\n",
       "32  32      0\n",
       "33  33      1\n",
       "34  34      0\n",
       "35  35      0\n",
       "36  36      1\n",
       "37  37      0\n",
       "38  38      1\n",
       "39  39      0\n",
       "40  40      0\n",
       "41  41      0\n",
       "42  42      1\n",
       "43  43      1\n",
       "44  44      0\n",
       "45  45      0\n",
       "46  46      0\n",
       "47  47      1\n",
       "48  48      1\n",
       "49  49      0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

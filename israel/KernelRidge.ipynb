{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 184kB 3.5MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 36.8MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 81kB 8.9MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 112kB 46.5MB/s eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s  eta 0:00:01\n",
      "\u001b[K     |████████████████████████████████| 61kB 7.7MB/s  eta 0:00:01\n",
      "\u001b[?25h  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_ = pd.read_csv('../data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('../data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('../data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('../data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n",
    "y = pd.read_csv('../data/Ytr.csv',sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "y.head()\n",
    "y = y.Bound.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('x_train: {} y_train {}'.format(X_preprocess[:2000,:].shape,y.shape))\n",
    "# print('test: {}'.format(X_preprocess[2000:,:].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_train_test(X,y,p):\n",
    "    X = scale(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel_element_wise(x, y, sigma=1):\n",
    "    K =  np.exp(-np.sum((x-y)**2)/(2*sigma**2))\n",
    "    return K\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "\n",
    "def LevenshteinDistance(str1,str2):\n",
    "    '''\n",
    "    Compute the edit distance between str1 and str2\n",
    "    Param: @(str1): (str) string 1 for the comparison\n",
    "    @(str2): (str) string 2 for the comparison\n",
    "    Return (int) distance\n",
    "    '''\n",
    "    len_s1 = len(str1) +1\n",
    "    len_s2 = len(str2) +1\n",
    "    m = np.zeros((len_s1,len_s2))\n",
    "    for i in range(len_s1):\n",
    "        m[i,0] = i\n",
    "    \n",
    "    for j in range(len_s2):\n",
    "        m[0,j] = j\n",
    "    \n",
    "    for i in range(1,len_s1):\n",
    "        for j in range(1,len_s2):\n",
    "            if str1[i-1]==str2[j-1]:\n",
    "                m[i,j]= min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1])\n",
    "            else:\n",
    "                m[i,j] =min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1]+1)\n",
    "    return m[-1,-1]\n",
    "\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def linear_kernel(X1, X2):\n",
    "    return X1.dot(X2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X,X,**self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,kernel=None,lambd=0.2,sigma=0.5,k=5,power=2):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "            \n",
    "            \n",
    "        model = KernelRidgeRegression(\n",
    "                kernel=kernel,\n",
    "                lambd=lambd,\n",
    "                sigma=sigma,\n",
    "                power=power\n",
    "            ).fit(x_train, y_train)\n",
    "        result = sum(np.sign(model.predict(x_test))==y_test)/len(y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train_ , pd.DataFrame(y)],axis=1)\n",
    "\n",
    "def getKmers(sequence, size=6):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bound\n",
       "Id         \n",
       "0         1\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         1\n",
       "...     ...\n",
       "1995      1\n",
       "1996      0\n",
       "1997      1\n",
       "1998      1\n",
       "1999      1\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_data['words'] = train_data.seq.apply(lambda x: ' '.join(getKmers(x)))\n",
    "X_test_['words'] = X_test_.seq.apply(lambda x: ' '.join(getKmers(x)))\n",
    "train_data.shape\n",
    "\n",
    "data = pd.DataFrame(pd.concat([train_data.words,X_test_.words],axis=0))\n",
    "train_text = data.words.values\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(2,2),max_features=1500,min_df=10,binary=True)\n",
    "X = cv.fit_transform(train_text)\n",
    "X = X.todense()\n",
    "\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-66bcea901b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'polynomial'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-4fdd9e914416>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(x_data, y_data, kernel, lambd, sigma, k, power)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx_data_splitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_data_splitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0maggrigate_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "cross_validate(np.array(X)[:2000,:],y,kernel='polynomial',lambd=0.001,k=4,sigma=0.2,power=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lambd = trial.suggest_loguniform('lambd', 1e-7, 3)\n",
    "    sigma = trial.suggest_loguniform('sigma', 1e-7, 3)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "    power =  trial.suggest_int('power', 2,15)\n",
    "    kernel =  trial.suggest_categorical('kernel', ['linear','rbf','polynomial'])\n",
    "    \n",
    "    return cross_validate(np.array(X)[:2000,:],y,kernel=kernel,lambd=lambd,k=4,sigma=sigma,power=power)\n",
    "\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=1000,show_progress_bar=True)\n",
    "\n",
    "\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 65536)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "\n",
    "train_text = data.seq.values\n",
    "# X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "\n",
    "kmer_data = []\n",
    "for i in train_text:\n",
    "    kmer_data.append(spectral_embedding(i,kmer_size=8))\n",
    "    \n",
    "np.array(kmer_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859e7bc665a34c06b1dacf4563b60ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-29 01:42:30,723]\u001b[0m Finished trial#0 with value: 0.617 with parameters: {'lambd': 0.06702378064927854, 'sigma': 0.0008445163408804387, 'k': 5, 'power': 15, 'kernel': 'polynomial'}. Best is trial#0 with value: 0.617.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:42:35,385]\u001b[0m Finished trial#1 with value: 0.6345000000000001 with parameters: {'lambd': 0.02085639648275362, 'sigma': 3.9040236143315835e-07, 'k': 4, 'power': 3, 'kernel': 'polynomial'}. Best is trial#1 with value: 0.6345000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:42:42,199]\u001b[0m Finished trial#2 with value: 0.0 with parameters: {'lambd': 0.0002530426405211842, 'sigma': 2.3341904470467587e-08, 'k': 4, 'power': 15, 'kernel': 'rbf'}. Best is trial#1 with value: 0.6345000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:42:46,837]\u001b[0m Finished trial#3 with value: 0.6275000000000001 with parameters: {'lambd': 0.034721519700855574, 'sigma': 3.570704065683582e-05, 'k': 8, 'power': 5, 'kernel': 'polynomial'}. Best is trial#1 with value: 0.6345000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:42:51,401]\u001b[0m Finished trial#4 with value: 0.6435 with parameters: {'lambd': 1.751819373131936e-08, 'sigma': 2.406993287459857, 'k': 4, 'power': 5, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:42:58,282]\u001b[0m Finished trial#5 with value: 0.0 with parameters: {'lambd': 0.0006856271826306291, 'sigma': 1.3493376692192772e-06, 'k': 8, 'power': 8, 'kernel': 'rbf'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:02,913]\u001b[0m Finished trial#6 with value: 0.6435 with parameters: {'lambd': 2.982417965063668e-07, 'sigma': 0.179940752586398, 'k': 4, 'power': 15, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:07,449]\u001b[0m Finished trial#7 with value: 0.6435 with parameters: {'lambd': 2.514957272915537e-07, 'sigma': 0.0012724329188281652, 'k': 8, 'power': 13, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:12,169]\u001b[0m Finished trial#8 with value: 0.619 with parameters: {'lambd': 4.728263144597886e-09, 'sigma': 4.0853842902729775e-05, 'k': 4, 'power': 7, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:16,642]\u001b[0m Finished trial#9 with value: 0.6435 with parameters: {'lambd': 7.237001441905045e-05, 'sigma': 0.00014693714143458906, 'k': 4, 'power': 4, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:21,038]\u001b[0m Finished trial#10 with value: 0.6435 with parameters: {'lambd': 2.8527890496679463e-09, 'sigma': 0.7898585315143576, 'k': 5, 'power': 11, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:25,614]\u001b[0m Finished trial#11 with value: 0.6435 with parameters: {'lambd': 7.892826180297335e-07, 'sigma': 2.2542944078468166, 'k': 4, 'power': 11, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:30,108]\u001b[0m Finished trial#12 with value: 0.6435 with parameters: {'lambd': 3.53121148930272e-07, 'sigma': 0.07065988406685783, 'k': 4, 'power': 2, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:34,629]\u001b[0m Finished trial#13 with value: 0.6435 with parameters: {'lambd': 3.996612527604516e-08, 'sigma': 0.08108412296319767, 'k': 4, 'power': 6, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:39,217]\u001b[0m Finished trial#14 with value: 0.6435 with parameters: {'lambd': 5.269954769164818e-06, 'sigma': 0.04840938586491367, 'k': 4, 'power': 10, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:43,804]\u001b[0m Finished trial#15 with value: 0.6435 with parameters: {'lambd': 1.5963436829483033e-09, 'sigma': 2.0313446120743386, 'k': 5, 'power': 2, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:50,730]\u001b[0m Finished trial#16 with value: 0.0 with parameters: {'lambd': 2.1838526044094797e-08, 'sigma': 0.008159557315394054, 'k': 4, 'power': 9, 'kernel': 'rbf'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:55,307]\u001b[0m Finished trial#17 with value: 0.6435 with parameters: {'lambd': 3.64105618648291e-06, 'sigma': 0.01253858620686782, 'k': 4, 'power': 10, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:43:59,835]\u001b[0m Finished trial#18 with value: 0.638 with parameters: {'lambd': 2.9538785882662117, 'sigma': 0.003808225975860715, 'k': 5, 'power': 13, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:04,421]\u001b[0m Finished trial#19 with value: 0.6435 with parameters: {'lambd': 6.559144243922943e-05, 'sigma': 1.6432183860636475e-09, 'k': 5, 'power': 3, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:11,215]\u001b[0m Finished trial#20 with value: 0.0 with parameters: {'lambd': 4.958577470804489e-06, 'sigma': 0.0001730695922741603, 'k': 4, 'power': 8, 'kernel': 'rbf'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:15,795]\u001b[0m Finished trial#21 with value: 0.6435 with parameters: {'lambd': 1.0758224702285431e-09, 'sigma': 0.8329736148188255, 'k': 5, 'power': 12, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:20,438]\u001b[0m Finished trial#22 with value: 0.6435 with parameters: {'lambd': 2.084084544298926e-05, 'sigma': 1.4685659058401333e-09, 'k': 5, 'power': 10, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:25,137]\u001b[0m Finished trial#23 with value: 0.6435 with parameters: {'lambd': 2.169841718645266e-06, 'sigma': 3.3894210910534207e-06, 'k': 5, 'power': 11, 'kernel': 'linear'}. Best is trial#4 with value: 0.6435.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:29,687]\u001b[0m Finished trial#24 with value: 0.644 with parameters: {'lambd': 0.004135424826561912, 'sigma': 1.1883119004976043e-09, 'k': 5, 'power': 13, 'kernel': 'linear'}. Best is trial#24 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:34,253]\u001b[0m Finished trial#25 with value: 0.6435 with parameters: {'lambd': 0.002691383124432004, 'sigma': 1.709776262244301e-09, 'k': 5, 'power': 13, 'kernel': 'linear'}. Best is trial#24 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:38,810]\u001b[0m Finished trial#26 with value: 0.643 with parameters: {'lambd': 0.0030135498231003937, 'sigma': 2.57040828398109e-07, 'k': 5, 'power': 14, 'kernel': 'linear'}. Best is trial#24 with value: 0.644.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:43,380]\u001b[0m Finished trial#27 with value: 0.646 with parameters: {'lambd': 0.4037353719405382, 'sigma': 0.02578764552663403, 'k': 8, 'power': 7, 'kernel': 'linear'}. Best is trial#27 with value: 0.646.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:47,950]\u001b[0m Finished trial#28 with value: 0.644 with parameters: {'lambd': 1.1689869150426289, 'sigma': 1.035942397172566e-08, 'k': 8, 'power': 13, 'kernel': 'linear'}. Best is trial#27 with value: 0.646.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:52,652]\u001b[0m Finished trial#29 with value: 0.619 with parameters: {'lambd': 1.01082920758373, 'sigma': 1.4376082780479076e-08, 'k': 8, 'power': 7, 'kernel': 'polynomial'}. Best is trial#27 with value: 0.646.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:44:57,251]\u001b[0m Finished trial#30 with value: 0.649 with parameters: {'lambd': 0.27138799556177323, 'sigma': 1.4107608052416505e-08, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#30 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:01,814]\u001b[0m Finished trial#31 with value: 0.6475 with parameters: {'lambd': 0.5168359629099115, 'sigma': 1.4127867235859798e-08, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#30 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:06,414]\u001b[0m Finished trial#32 with value: 0.649 with parameters: {'lambd': 0.27684610049961866, 'sigma': 2.5277928913365097e-08, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#30 with value: 0.649.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:11,018]\u001b[0m Finished trial#33 with value: 0.65 with parameters: {'lambd': 0.21119262141905443, 'sigma': 8.625946870830329e-08, 'k': 8, 'power': 15, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:15,814]\u001b[0m Finished trial#34 with value: 0.617 with parameters: {'lambd': 0.19392390430516113, 'sigma': 6.580585187289644e-08, 'k': 8, 'power': 15, 'kernel': 'polynomial'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:20,355]\u001b[0m Finished trial#35 with value: 0.648 with parameters: {'lambd': 0.05141275075730406, 'sigma': 7.129320562930483e-08, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:27,351]\u001b[0m Finished trial#36 with value: 0.0 with parameters: {'lambd': 0.07404650264449646, 'sigma': 1.0128619551495416e-07, 'k': 8, 'power': 14, 'kernel': 'rbf'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:31,950]\u001b[0m Finished trial#37 with value: 0.6465 with parameters: {'lambd': 0.017559730159308076, 'sigma': 2.049772452216597e-06, 'k': 8, 'power': 15, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:36,628]\u001b[0m Finished trial#38 with value: 0.617 with parameters: {'lambd': 0.07108641286413839, 'sigma': 7.696705966221312e-06, 'k': 8, 'power': 15, 'kernel': 'polynomial'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:41,205]\u001b[0m Finished trial#39 with value: 0.646 with parameters: {'lambd': 0.015384898793470176, 'sigma': 6.44606244976933e-09, 'k': 8, 'power': 12, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:45,777]\u001b[0m Finished trial#40 with value: 0.64 with parameters: {'lambd': 2.6744221122178207, 'sigma': 3.639013433542333e-07, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:50,325]\u001b[0m Finished trial#41 with value: 0.649 with parameters: {'lambd': 0.2742234450817689, 'sigma': 4.9662126348250686e-08, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:54,910]\u001b[0m Finished trial#42 with value: 0.6485000000000001 with parameters: {'lambd': 0.14530587613563897, 'sigma': 5.260605547034388e-08, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:45:59,513]\u001b[0m Finished trial#43 with value: 0.648 with parameters: {'lambd': 0.1481856728467578, 'sigma': 4.4820095751525505e-09, 'k': 8, 'power': 12, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:46:04,100]\u001b[0m Finished trial#44 with value: 0.6455 with parameters: {'lambd': 0.011025097585442704, 'sigma': 3.956164101174661e-08, 'k': 8, 'power': 15, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:46:08,717]\u001b[0m Finished trial#45 with value: 0.6495000000000001 with parameters: {'lambd': 0.23799986458982852, 'sigma': 7.936078386980427e-07, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:46:13,291]\u001b[0m Finished trial#46 with value: 0.6435 with parameters: {'lambd': 0.0007195962457183764, 'sigma': 7.514865466465344e-07, 'k': 8, 'power': 15, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:46:20,161]\u001b[0m Finished trial#47 with value: 0.0 with parameters: {'lambd': 1.2050983396546437, 'sigma': 1.1041327920657523e-05, 'k': 8, 'power': 12, 'kernel': 'rbf'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:46:24,717]\u001b[0m Finished trial#48 with value: 0.647 with parameters: {'lambd': 0.3703124559547817, 'sigma': 1.5445634150196523e-07, 'k': 8, 'power': 14, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:46:29,337]\u001b[0m Finished trial#49 with value: 0.6395000000000001 with parameters: {'lambd': 2.6159556660754264, 'sigma': 7.153173328203373e-07, 'k': 8, 'power': 13, 'kernel': 'linear'}. Best is trial#33 with value: 0.65.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    lambd = trial.suggest_loguniform('lambd', 1e-9, 3)\n",
    "    sigma = trial.suggest_loguniform('sigma', 1e-9, 3)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8])\n",
    "    power =  trial.suggest_int('power', 2,15)\n",
    "    kernel =  trial.suggest_categorical('kernel', ['linear','rbf','polynomial'])\n",
    "    \n",
    "    return cross_validate(np.array(kmer_data)[:2000,:],y,kernel=kernel,lambd=lambd,k=4,sigma=sigma,power=power)\n",
    "\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=500,show_progress_bar=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_k</th>\n",
       "      <th>params_kernel</th>\n",
       "      <th>params_lambd</th>\n",
       "      <th>params_power</th>\n",
       "      <th>params_sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:06.809197</td>\n",
       "      <td>4</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.530426e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>2.334190e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:06.865268</td>\n",
       "      <td>8</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.205098e+00</td>\n",
       "      <td>12</td>\n",
       "      <td>1.104133e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:06.875649</td>\n",
       "      <td>8</td>\n",
       "      <td>rbf</td>\n",
       "      <td>6.856272e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>1.349338e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:06.991329</td>\n",
       "      <td>8</td>\n",
       "      <td>rbf</td>\n",
       "      <td>7.404650e-02</td>\n",
       "      <td>14</td>\n",
       "      <td>1.012862e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:06.789282</td>\n",
       "      <td>4</td>\n",
       "      <td>rbf</td>\n",
       "      <td>4.958577e-06</td>\n",
       "      <td>8</td>\n",
       "      <td>1.730696e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>00:00:06.922304</td>\n",
       "      <td>4</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.183853e-08</td>\n",
       "      <td>9</td>\n",
       "      <td>8.159557e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>00:00:04.664926</td>\n",
       "      <td>5</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>6.702378e-02</td>\n",
       "      <td>15</td>\n",
       "      <td>8.445163e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>00:00:04.673783</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>7.108641e-02</td>\n",
       "      <td>15</td>\n",
       "      <td>7.696706e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>00:00:04.793176</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>1.939239e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>6.580585e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>00:00:04.715475</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>4.728263e-09</td>\n",
       "      <td>7</td>\n",
       "      <td>4.085384e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>00:00:04.697334</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>1.010829e+00</td>\n",
       "      <td>7</td>\n",
       "      <td>1.437608e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>00:00:04.633268</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>3.472152e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>3.570704e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6345</td>\n",
       "      <td>00:00:04.658716</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>2.085640e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>3.904024e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>00:00:04.523636</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.953879e+00</td>\n",
       "      <td>13</td>\n",
       "      <td>3.808226e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>00:00:04.615876</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.615956e+00</td>\n",
       "      <td>13</td>\n",
       "      <td>7.153173e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>00:00:04.566496</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.674422e+00</td>\n",
       "      <td>14</td>\n",
       "      <td>3.639013e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.6430</td>\n",
       "      <td>00:00:04.552458</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>3.013550e-03</td>\n",
       "      <td>14</td>\n",
       "      <td>2.570408e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.581921</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.596344e-09</td>\n",
       "      <td>2</td>\n",
       "      <td>2.031345e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.531871</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.514957e-07</td>\n",
       "      <td>13</td>\n",
       "      <td>1.272433e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.626622</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.982418e-07</td>\n",
       "      <td>15</td>\n",
       "      <td>1.799408e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.391411</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.852789e-09</td>\n",
       "      <td>11</td>\n",
       "      <td>7.898585e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.568906</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>7.195962e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>7.514865e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.562294</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.691383e-03</td>\n",
       "      <td>13</td>\n",
       "      <td>1.709776e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.583886</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>5.269955e-06</td>\n",
       "      <td>10</td>\n",
       "      <td>4.840939e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.560072</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.751819e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>2.406993e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.638878</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.084085e-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1.468566e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.575664</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.075822e-09</td>\n",
       "      <td>12</td>\n",
       "      <td>8.329736e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.572059</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>7.892826e-07</td>\n",
       "      <td>11</td>\n",
       "      <td>2.254294e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.581487</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>6.559144e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>1.643218e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.490476</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>3.531211e-07</td>\n",
       "      <td>2</td>\n",
       "      <td>7.065988e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.571988</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>3.641056e-06</td>\n",
       "      <td>10</td>\n",
       "      <td>1.253859e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.516385</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>3.996613e-08</td>\n",
       "      <td>6</td>\n",
       "      <td>8.108412e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.695532</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.169842e-06</td>\n",
       "      <td>11</td>\n",
       "      <td>3.389421e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>00:00:04.469044</td>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>7.237001e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>1.469371e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>00:00:04.544585</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>4.135425e-03</td>\n",
       "      <td>13</td>\n",
       "      <td>1.188312e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>00:00:04.565365</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.168987e+00</td>\n",
       "      <td>13</td>\n",
       "      <td>1.035942e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.6455</td>\n",
       "      <td>00:00:04.583241</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.102510e-02</td>\n",
       "      <td>15</td>\n",
       "      <td>3.956164e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>00:00:04.573319</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.538490e-02</td>\n",
       "      <td>12</td>\n",
       "      <td>6.446062e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>00:00:04.566221</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>4.037354e-01</td>\n",
       "      <td>7</td>\n",
       "      <td>2.578765e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>00:00:04.594113</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.755973e-02</td>\n",
       "      <td>15</td>\n",
       "      <td>2.049772e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>00:00:04.551836</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>3.703125e-01</td>\n",
       "      <td>14</td>\n",
       "      <td>1.544563e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>00:00:04.558520</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>5.168360e-01</td>\n",
       "      <td>14</td>\n",
       "      <td>1.412787e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.6480</td>\n",
       "      <td>00:00:04.535687</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>5.141275e-02</td>\n",
       "      <td>14</td>\n",
       "      <td>7.129321e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.6480</td>\n",
       "      <td>00:00:04.597557</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.481857e-01</td>\n",
       "      <td>12</td>\n",
       "      <td>4.482010e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>00:00:04.580400</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.453059e-01</td>\n",
       "      <td>14</td>\n",
       "      <td>5.260606e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>00:00:04.594872</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.713880e-01</td>\n",
       "      <td>14</td>\n",
       "      <td>1.410761e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>00:00:04.544071</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.742234e-01</td>\n",
       "      <td>14</td>\n",
       "      <td>4.966213e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>00:00:04.595365</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.768461e-01</td>\n",
       "      <td>14</td>\n",
       "      <td>2.527793e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.6495</td>\n",
       "      <td>00:00:04.612678</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.379999e-01</td>\n",
       "      <td>14</td>\n",
       "      <td>7.936078e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>00:00:04.598363</td>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.111926e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>8.625947e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number   value        duration  params_k params_kernel  params_lambd  params_power  params_sigma\n",
       "2        2  0.0000 00:00:06.809197         4           rbf  2.530426e-04            15  2.334190e-08\n",
       "47      47  0.0000 00:00:06.865268         8           rbf  1.205098e+00            12  1.104133e-05\n",
       "5        5  0.0000 00:00:06.875649         8           rbf  6.856272e-04             8  1.349338e-06\n",
       "36      36  0.0000 00:00:06.991329         8           rbf  7.404650e-02            14  1.012862e-07\n",
       "20      20  0.0000 00:00:06.789282         4           rbf  4.958577e-06             8  1.730696e-04\n",
       "16      16  0.0000 00:00:06.922304         4           rbf  2.183853e-08             9  8.159557e-03\n",
       "0        0  0.6170 00:00:04.664926         5    polynomial  6.702378e-02            15  8.445163e-04\n",
       "38      38  0.6170 00:00:04.673783         8    polynomial  7.108641e-02            15  7.696706e-06\n",
       "34      34  0.6170 00:00:04.793176         8    polynomial  1.939239e-01            15  6.580585e-08\n",
       "8        8  0.6190 00:00:04.715475         4    polynomial  4.728263e-09             7  4.085384e-05\n",
       "29      29  0.6190 00:00:04.697334         8    polynomial  1.010829e+00             7  1.437608e-08\n",
       "3        3  0.6275 00:00:04.633268         8    polynomial  3.472152e-02             5  3.570704e-05\n",
       "1        1  0.6345 00:00:04.658716         4    polynomial  2.085640e-02             3  3.904024e-07\n",
       "18      18  0.6380 00:00:04.523636         5        linear  2.953879e+00            13  3.808226e-03\n",
       "49      49  0.6395 00:00:04.615876         8        linear  2.615956e+00            13  7.153173e-07\n",
       "40      40  0.6400 00:00:04.566496         8        linear  2.674422e+00            14  3.639013e-07\n",
       "26      26  0.6430 00:00:04.552458         5        linear  3.013550e-03            14  2.570408e-07\n",
       "15      15  0.6435 00:00:04.581921         5        linear  1.596344e-09             2  2.031345e+00\n",
       "7        7  0.6435 00:00:04.531871         8        linear  2.514957e-07            13  1.272433e-03\n",
       "6        6  0.6435 00:00:04.626622         4        linear  2.982418e-07            15  1.799408e-01\n",
       "10      10  0.6435 00:00:04.391411         5        linear  2.852789e-09            11  7.898585e-01\n",
       "46      46  0.6435 00:00:04.568906         8        linear  7.195962e-04            15  7.514865e-07\n",
       "25      25  0.6435 00:00:04.562294         5        linear  2.691383e-03            13  1.709776e-09\n",
       "14      14  0.6435 00:00:04.583886         4        linear  5.269955e-06            10  4.840939e-02\n",
       "4        4  0.6435 00:00:04.560072         4        linear  1.751819e-08             5  2.406993e+00\n",
       "22      22  0.6435 00:00:04.638878         5        linear  2.084085e-05            10  1.468566e-09\n",
       "21      21  0.6435 00:00:04.575664         5        linear  1.075822e-09            12  8.329736e-01\n",
       "11      11  0.6435 00:00:04.572059         4        linear  7.892826e-07            11  2.254294e+00\n",
       "19      19  0.6435 00:00:04.581487         5        linear  6.559144e-05             3  1.643218e-09\n",
       "12      12  0.6435 00:00:04.490476         4        linear  3.531211e-07             2  7.065988e-02\n",
       "17      17  0.6435 00:00:04.571988         4        linear  3.641056e-06            10  1.253859e-02\n",
       "13      13  0.6435 00:00:04.516385         4        linear  3.996613e-08             6  8.108412e-02\n",
       "23      23  0.6435 00:00:04.695532         5        linear  2.169842e-06            11  3.389421e-06\n",
       "9        9  0.6435 00:00:04.469044         4        linear  7.237001e-05             4  1.469371e-04\n",
       "24      24  0.6440 00:00:04.544585         5        linear  4.135425e-03            13  1.188312e-09\n",
       "28      28  0.6440 00:00:04.565365         8        linear  1.168987e+00            13  1.035942e-08\n",
       "44      44  0.6455 00:00:04.583241         8        linear  1.102510e-02            15  3.956164e-08\n",
       "39      39  0.6460 00:00:04.573319         8        linear  1.538490e-02            12  6.446062e-09\n",
       "27      27  0.6460 00:00:04.566221         8        linear  4.037354e-01             7  2.578765e-02\n",
       "37      37  0.6465 00:00:04.594113         8        linear  1.755973e-02            15  2.049772e-06\n",
       "48      48  0.6470 00:00:04.551836         8        linear  3.703125e-01            14  1.544563e-07\n",
       "31      31  0.6475 00:00:04.558520         8        linear  5.168360e-01            14  1.412787e-08\n",
       "35      35  0.6480 00:00:04.535687         8        linear  5.141275e-02            14  7.129321e-08\n",
       "43      43  0.6480 00:00:04.597557         8        linear  1.481857e-01            12  4.482010e-09\n",
       "42      42  0.6485 00:00:04.580400         8        linear  1.453059e-01            14  5.260606e-08\n",
       "30      30  0.6490 00:00:04.594872         8        linear  2.713880e-01            14  1.410761e-08\n",
       "41      41  0.6490 00:00:04.544071         8        linear  2.742234e-01            14  4.966213e-08\n",
       "32      32  0.6490 00:00:04.595365         8        linear  2.768461e-01            14  2.527793e-08\n",
       "45      45  0.6495 00:00:04.612678         8        linear  2.379999e-01            14  7.936078e-07\n",
       "33      33  0.6500 00:00:04.598363         8        linear  2.111926e-01            15  8.625947e-08"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 65536) (200, 65536) (1800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test(np.array(kmer_data)[:2000,:],y,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KernelRidgeRegression(\n",
    "                kernel='linear',\n",
    "                lambd=2.111926e-01,\n",
    "                sigma=8.625947e-08,\n",
    "                power=15\n",
    "            ).fit(X_train, y_train)\n",
    "result = sum(np.sign(model.predict(X_test))==y_test)/len(y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6485])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(np.array(kmer_data)[:2000,:],y,kernel='linear',k=5,power=15,lambd=2.111926e-01,sigma=8.625947e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Bound\n",
       "0    0      1\n",
       "1    1      1\n",
       "2    2      0\n",
       "3    3      0\n",
       "4    4      1\n",
       "5    5      1\n",
       "6    6      1\n",
       "7    7      0\n",
       "8    8      0\n",
       "9    9      0\n",
       "10  10      1\n",
       "11  11      0\n",
       "12  12      1\n",
       "13  13      0\n",
       "14  14      0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final = np.array(kmer_data)[2000:,:]\n",
    "\n",
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = np.sign(model.predict(X_test_final[i]))\n",
    "    \n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_65_linear_overfitted.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

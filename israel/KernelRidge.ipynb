{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_ = pd.read_csv('../data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('../data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('../data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('../data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n",
    "y = pd.read_csv('../data/Ytr.csv',sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "y.head()\n",
    "y = y.Bound.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('x_train: {} y_train {}'.format(X_preprocess[:2000,:].shape,y.shape))\n",
    "# print('test: {}'.format(X_preprocess[2000:,:].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_train_test(X,y,p):\n",
    "    X = X\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel_element_wise(x, y, sigma=1):\n",
    "    K =  np.exp(-np.sum((x-y)**2)/(2*sigma**2))\n",
    "    return K\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "\n",
    "def LevenshteinDistance(str1,str2):\n",
    "    '''\n",
    "    Compute the edit distance between str1 and str2\n",
    "    Param: @(str1): (str) string 1 for the comparison\n",
    "    @(str2): (str) string 2 for the comparison\n",
    "    Return (int) distance\n",
    "    '''\n",
    "    len_s1 = len(str1) +1\n",
    "    len_s2 = len(str2) +1\n",
    "    m = np.zeros((len_s1,len_s2))\n",
    "    for i in range(len_s1):\n",
    "        m[i,0] = i\n",
    "    \n",
    "    for j in range(len_s2):\n",
    "        m[0,j] = j\n",
    "    \n",
    "    for i in range(1,len_s1):\n",
    "        for j in range(1,len_s2):\n",
    "            if str1[i-1]==str2[j-1]:\n",
    "                m[i,j]= min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1])\n",
    "            else:\n",
    "                m[i,j] =min(m[i-1,j]+1,m[i,j-1]+1,m[i-1,j-1]+1)\n",
    "    return m[-1,-1]\n",
    "\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def linear_kernel(X1, X2):\n",
    "    return X1.dot(X2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "            \n",
    "        \n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression(KernelMethodBase):\n",
    "    '''\n",
    "    Kernel Ridge Regression\n",
    "    '''\n",
    "    def __init__(self, lambd=0.1, **kwargs):\n",
    "        self.lambd = lambd\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelRidgeRegression, self).__init__(**kwargs)\n",
    "\n",
    "    def fit(self, X, y, sample_weights=None):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if sample_weights is not None:\n",
    "            w_sqrt = np.sqrt(sample_weights)\n",
    "            self.X_train = self.X_train * w_sqrt[:, None]\n",
    "            self.y_train = self.y_train * w_sqrt\n",
    "        \n",
    "        A = self.kernel_function_(X,X,**self.kernel_parameters)\n",
    "        A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)],n*self.lambd)\n",
    "        # self.alpha = (K + n lambda I)^-1 y\n",
    "        self.alpha = np.linalg.solve(A , self.y_train)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X,self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,kernel=None,lambd=0.2,sigma=0.5,k=5,power=2):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data.reshape(-1,1),k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "            \n",
    "            \n",
    "        model = KernelRidgeRegression(\n",
    "                kernel=kernel,\n",
    "                lambd=lambd,\n",
    "                sigma=sigma,\n",
    "                power=power\n",
    "            ).fit(x_train, y_train)\n",
    "        result = sum(np.sign(model.predict(x_test))==y_test)/len(y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train_ , pd.DataFrame(y)],axis=1)\n",
    "\n",
    "def getKmers(sequence, size=6):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# train_data['words'] = train_data.seq.apply(lambda x: ' '.join(getKmers(x)))\n",
    "# X_test_['words'] = X_test_.seq.apply(lambda x: ' '.join(getKmers(x)))\n",
    "# train_data.shape\n",
    "\n",
    "# data = pd.DataFrame(pd.concat([train_data.words,X_test_.words],axis=0))\n",
    "# train_text = data.words.values\n",
    "\n",
    "# cv = CountVectorizer(ngram_range=(2,2),max_features=1500,min_df=10,binary=True)\n",
    "# X = cv.fit_transform(train_text)\n",
    "# X = X.todense()\n",
    "\n",
    "\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(np.array(X)[:2000,:],y.values,kernel='polynomial',lambd=0.001,k=4,sigma=0.2,power=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     lambd = trial.suggest_loguniform('lambd', 1e-7, 3)\n",
    "#     sigma = trial.suggest_loguniform('sigma', 1e-7, 3)\n",
    "#     k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "#     power =  trial.suggest_int('power', 2,15)\n",
    "#     kernel =  trial.suggest_categorical('kernel', ['linear','rbf','polynomial'])\n",
    "    \n",
    "#     return cross_validate(np.array(X)[:2000,:],y,kernel=kernel,lambd=lambd,k=4,sigma=sigma,power=power)\n",
    "\n",
    "\n",
    "# # cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "# import optuna\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler()\n",
    "# study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# df = study.optimize(func=objective, n_trials=1000,show_progress_bar=True)\n",
    "\n",
    "\n",
    "# df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "# df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "def get_data(kmer_size):\n",
    "    data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "    train_text = data.seq.values\n",
    "    # X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "    kmer_data = []\n",
    "    for i in train_text:\n",
    "        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))\n",
    "\n",
    "    return np.array(kmer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.638])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(np.array(kmer_data)[:2000,:],y,kernel='polynomial',k=4,power=2,lambd=2,sigma=100)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777e3465f869426b87eb9f5a253bd3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-29 23:08:25,134]\u001b[0m Finished trial#0 with value: 0.5985 with parameters: {'lambd': 10.412036707754451, 'k': 8, 'power': 2, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#0 with value: 0.5985.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:26,910]\u001b[0m Finished trial#1 with value: 0.506 with parameters: {'lambd': 79.54291739979304, 'k': 8, 'power': 1, 'kmer_size': 3, 'kernel': 'linear'}. Best is trial#0 with value: 0.5985.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:28,793]\u001b[0m Finished trial#2 with value: 0.5935 with parameters: {'lambd': 49.49144007745532, 'k': 5, 'power': 2, 'kmer_size': 4, 'kernel': 'polynomial'}. Best is trial#0 with value: 0.5985.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:30,639]\u001b[0m Finished trial#3 with value: 0.5175000000000001 with parameters: {'lambd': 39.93978282193774, 'k': 8, 'power': 5, 'kmer_size': 4, 'kernel': 'linear'}. Best is trial#0 with value: 0.5985.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:33,704]\u001b[0m Finished trial#4 with value: 0.634 with parameters: {'lambd': 29.748120244261116, 'k': 4, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:35,802]\u001b[0m Finished trial#5 with value: 0.584 with parameters: {'lambd': 19.1207316353884, 'k': 8, 'power': 3, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:37,595]\u001b[0m Finished trial#6 with value: 0.515 with parameters: {'lambd': 38.87033176305319, 'k': 8, 'power': 1, 'kmer_size': 3, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:42,562]\u001b[0m Finished trial#7 with value: 0.6225 with parameters: {'lambd': 15.265643796575771, 'k': 8, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:44,584]\u001b[0m Finished trial#8 with value: 0.5855000000000001 with parameters: {'lambd': 53.644675366069684, 'k': 8, 'power': 2, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:46,361]\u001b[0m Finished trial#9 with value: 0.5355000000000001 with parameters: {'lambd': 7.922493387456044, 'k': 8, 'power': 1, 'kmer_size': 3, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:52,522]\u001b[0m Finished trial#10 with value: 0.631 with parameters: {'lambd': 81.139540238372, 'k': 4, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:08:58,738]\u001b[0m Finished trial#11 with value: 0.631 with parameters: {'lambd': 97.58981274368898, 'k': 4, 'power': 5, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:01,800]\u001b[0m Finished trial#12 with value: 0.634 with parameters: {'lambd': 74.37540412153183, 'k': 4, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:04,900]\u001b[0m Finished trial#13 with value: 0.634 with parameters: {'lambd': 70.35705785461718, 'k': 4, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:07,195]\u001b[0m Finished trial#14 with value: 0.6 with parameters: {'lambd': 28.957592005579265, 'k': 4, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#4 with value: 0.634.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:10,284]\u001b[0m Finished trial#15 with value: 0.635 with parameters: {'lambd': 64.26133708840831, 'k': 4, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:11,821]\u001b[0m Finished trial#16 with value: 0.49049999999999994 with parameters: {'lambd': 60.955159302552694, 'k': 5, 'power': 3, 'kmer_size': 1, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:14,855]\u001b[0m Finished trial#17 with value: 0.634 with parameters: {'lambd': 92.26661865385009, 'k': 4, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:17,142]\u001b[0m Finished trial#18 with value: 0.593 with parameters: {'lambd': 98.68097064743003, 'k': 4, 'power': 3, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:19,442]\u001b[0m Finished trial#19 with value: 0.601 with parameters: {'lambd': 28.402334821291984, 'k': 4, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:22,433]\u001b[0m Finished trial#20 with value: 0.631 with parameters: {'lambd': 91.23088500171983, 'k': 5, 'power': 5, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:25,504]\u001b[0m Finished trial#21 with value: 0.635 with parameters: {'lambd': 64.61822572788446, 'k': 4, 'power': 4, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:31,655]\u001b[0m Finished trial#22 with value: 0.631 with parameters: {'lambd': 65.51981935090075, 'k': 4, 'power': 4, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:33,904]\u001b[0m Finished trial#23 with value: 0.5935 with parameters: {'lambd': 87.08402857724448, 'k': 4, 'power': 4, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#15 with value: 0.635.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:36,945]\u001b[0m Finished trial#24 with value: 0.6355 with parameters: {'lambd': 55.6916783206328, 'k': 4, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:43,076]\u001b[0m Finished trial#25 with value: 0.631 with parameters: {'lambd': 54.66654124781029, 'k': 4, 'power': 3, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:45,523]\u001b[0m Finished trial#26 with value: 0.6255000000000001 with parameters: {'lambd': 46.51785490207169, 'k': 4, 'power': 3, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:48,523]\u001b[0m Finished trial#27 with value: 0.6355 with parameters: {'lambd': 61.50006432067315, 'k': 4, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:51,550]\u001b[0m Finished trial#28 with value: 0.6355 with parameters: {'lambd': 59.26844860257653, 'k': 4, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:53,560]\u001b[0m Finished trial#29 with value: 0.607 with parameters: {'lambd': 58.59212402524688, 'k': 5, 'power': 2, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:55,083]\u001b[0m Finished trial#30 with value: 0.4955 with parameters: {'lambd': 42.216728095856, 'k': 4, 'power': 3, 'kmer_size': 1, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:09:58,070]\u001b[0m Finished trial#31 with value: 0.634 with parameters: {'lambd': 69.44938046412126, 'k': 4, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:00,303]\u001b[0m Finished trial#32 with value: 0.594 with parameters: {'lambd': 76.92428840183521, 'k': 4, 'power': 3, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:06,417]\u001b[0m Finished trial#33 with value: 0.631 with parameters: {'lambd': 57.23922646356835, 'k': 4, 'power': 2, 'kmer_size': 8, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:09,418]\u001b[0m Finished trial#34 with value: 0.635 with parameters: {'lambd': 46.748785473768834, 'k': 4, 'power': 3, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:11,672]\u001b[0m Finished trial#35 with value: 0.597 with parameters: {'lambd': 47.76978450404855, 'k': 4, 'power': 3, 'kmer_size': 6, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:13,534]\u001b[0m Finished trial#36 with value: 0.5315 with parameters: {'lambd': 65.07609740320841, 'k': 4, 'power': 2, 'kmer_size': 4, 'kernel': 'linear'}. Best is trial#24 with value: 0.6355.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:19,329]\u001b[0m Finished trial#37 with value: 0.6375 with parameters: {'lambd': 36.681238896451035, 'k': 5, 'power': 3, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#37 with value: 0.6375.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:25,070]\u001b[0m Finished trial#38 with value: 0.6485 with parameters: {'lambd': 34.70406123288049, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#38 with value: 0.6485.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:30,774]\u001b[0m Finished trial#39 with value: 0.6385 with parameters: {'lambd': 36.80256107709114, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#38 with value: 0.6485.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:36,560]\u001b[0m Finished trial#40 with value: 0.6385 with parameters: {'lambd': 37.31350133441188, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#38 with value: 0.6485.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:42,399]\u001b[0m Finished trial#41 with value: 0.639 with parameters: {'lambd': 34.13770828856886, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#38 with value: 0.6485.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:48,278]\u001b[0m Finished trial#42 with value: 0.638 with parameters: {'lambd': 33.24076365225381, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#38 with value: 0.6485.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:54,063]\u001b[0m Finished trial#43 with value: 0.638 with parameters: {'lambd': 21.04483296103272, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#38 with value: 0.6485.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:10:59,828]\u001b[0m Finished trial#44 with value: 0.6535 with parameters: {'lambd': 1.0190843922936565, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:05,583]\u001b[0m Finished trial#45 with value: 0.6465 with parameters: {'lambd': 3.8036866765221795, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:11,284]\u001b[0m Finished trial#46 with value: 0.6495 with parameters: {'lambd': 2.971268624729305, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:12,921]\u001b[0m Finished trial#47 with value: 0.5585 with parameters: {'lambd': 2.524579182536452, 'k': 5, 'power': 1, 'kmer_size': 2, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:18,756]\u001b[0m Finished trial#48 with value: 0.6529999999999999 with parameters: {'lambd': 0.8062804914931192, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:24,573]\u001b[0m Finished trial#49 with value: 0.6495 with parameters: {'lambd': 0.5466662555685918, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:30,337]\u001b[0m Finished trial#50 with value: 0.65 with parameters: {'lambd': 10.959783795331036, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:36,135]\u001b[0m Finished trial#51 with value: 0.6495000000000001 with parameters: {'lambd': 11.049706541540443, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:41,901]\u001b[0m Finished trial#52 with value: 0.6505000000000001 with parameters: {'lambd': 9.196887185939383, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:47,657]\u001b[0m Finished trial#53 with value: 0.6495000000000001 with parameters: {'lambd': 11.561481714941449, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:53,430]\u001b[0m Finished trial#54 with value: 0.6495000000000001 with parameters: {'lambd': 11.109178203641363, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:56,382]\u001b[0m Finished trial#55 with value: 0.6535 with parameters: {'lambd': 20.187206266968506, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#44 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:11:59,360]\u001b[0m Finished trial#56 with value: 0.654 with parameters: {'lambd': 18.58363957507543, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#56 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:02,346]\u001b[0m Finished trial#57 with value: 0.653 with parameters: {'lambd': 19.72161334641348, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#56 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:05,114]\u001b[0m Finished trial#58 with value: 0.632 with parameters: {'lambd': 22.65366106056073, 'k': 8, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#56 with value: 0.654.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:08,063]\u001b[0m Finished trial#59 with value: 0.6540000000000001 with parameters: {'lambd': 16.383105703792296, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#59 with value: 0.6540000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:10,324]\u001b[0m Finished trial#60 with value: 0.611 with parameters: {'lambd': 16.467105927859276, 'k': 5, 'power': 1, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#59 with value: 0.6540000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:13,245]\u001b[0m Finished trial#61 with value: 0.6565000000000001 with parameters: {'lambd': 6.752174907429731, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:16,191]\u001b[0m Finished trial#62 with value: 0.6529999999999999 with parameters: {'lambd': 25.404671855974108, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:19,122]\u001b[0m Finished trial#63 with value: 0.6545000000000001 with parameters: {'lambd': 16.502920373003313, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:22,046]\u001b[0m Finished trial#64 with value: 0.6545000000000001 with parameters: {'lambd': 16.800513083129527, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:24,294]\u001b[0m Finished trial#65 with value: 0.6295 with parameters: {'lambd': 15.554969415774119, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:27,219]\u001b[0m Finished trial#66 with value: 0.6555000000000001 with parameters: {'lambd': 6.477228104286846, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:29,466]\u001b[0m Finished trial#67 with value: 0.6335 with parameters: {'lambd': 5.515994158117309, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:32,141]\u001b[0m Finished trial#68 with value: 0.632 with parameters: {'lambd': 7.171275481836908, 'k': 8, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:34,113]\u001b[0m Finished trial#69 with value: 0.6054999999999999 with parameters: {'lambd': 14.545356638771173, 'k': 5, 'power': 2, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:37,076]\u001b[0m Finished trial#70 with value: 0.6545000000000001 with parameters: {'lambd': 16.851454633161836, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:40,019]\u001b[0m Finished trial#71 with value: 0.6535 with parameters: {'lambd': 24.975871305759767, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:43,006]\u001b[0m Finished trial#72 with value: 0.6535 with parameters: {'lambd': 23.74423823737915, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:46,026]\u001b[0m Finished trial#73 with value: 0.654 with parameters: {'lambd': 17.134513039120353, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:49,084]\u001b[0m Finished trial#74 with value: 0.654 with parameters: {'lambd': 17.160411571452812, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:51,394]\u001b[0m Finished trial#75 with value: 0.6345000000000001 with parameters: {'lambd': 27.03846944417517, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:54,370]\u001b[0m Finished trial#76 with value: 0.6545 with parameters: {'lambd': 13.855310229481553, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:57,296]\u001b[0m Finished trial#77 with value: 0.654 with parameters: {'lambd': 12.482482382792917, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:12:59,575]\u001b[0m Finished trial#78 with value: 0.6319999999999999 with parameters: {'lambd': 6.597229903392337, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:02,501]\u001b[0m Finished trial#79 with value: 0.654 with parameters: {'lambd': 13.565695278849526, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:05,469]\u001b[0m Finished trial#80 with value: 0.6545 with parameters: {'lambd': 14.378714703541268, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:08,386]\u001b[0m Finished trial#81 with value: 0.6545 with parameters: {'lambd': 13.859708339082387, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:10,594]\u001b[0m Finished trial#82 with value: 0.631 with parameters: {'lambd': 30.681024604004108, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#61 with value: 0.6565000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:13,491]\u001b[0m Finished trial#83 with value: 0.6585 with parameters: {'lambd': 9.041981206742873, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:16,390]\u001b[0m Finished trial#84 with value: 0.658 with parameters: {'lambd': 8.034707396181226, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:19,351]\u001b[0m Finished trial#85 with value: 0.658 with parameters: {'lambd': 8.047621244446603, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:22,305]\u001b[0m Finished trial#86 with value: 0.6575 with parameters: {'lambd': 7.667060429963708, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:24,469]\u001b[0m Finished trial#87 with value: 0.61 with parameters: {'lambd': 5.298626079386375, 'k': 8, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:27,449]\u001b[0m Finished trial#88 with value: 0.658 with parameters: {'lambd': 8.487134113240742, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:30,499]\u001b[0m Finished trial#89 with value: 0.649 with parameters: {'lambd': 8.94069136414989, 'k': 5, 'power': 3, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:32,723]\u001b[0m Finished trial#90 with value: 0.6359999999999999 with parameters: {'lambd': 3.701633152266153, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:35,631]\u001b[0m Finished trial#91 with value: 0.6585 with parameters: {'lambd': 9.326735670689303, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:38,540]\u001b[0m Finished trial#92 with value: 0.6585 with parameters: {'lambd': 9.450305420421934, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:41,454]\u001b[0m Finished trial#93 with value: 0.658 with parameters: {'lambd': 8.073717607887252, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:44,344]\u001b[0m Finished trial#94 with value: 0.6585 with parameters: {'lambd': 8.567270106205568, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:47,255]\u001b[0m Finished trial#95 with value: 0.658 with parameters: {'lambd': 8.824235899647922, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:50,160]\u001b[0m Finished trial#96 with value: 0.658 with parameters: {'lambd': 8.864336100282125, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:53,115]\u001b[0m Finished trial#97 with value: 0.6559999999999999 with parameters: {'lambd': 2.5766079008687814, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:55,350]\u001b[0m Finished trial#98 with value: 0.6305 with parameters: {'lambd': 9.145062526916767, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:13:58,279]\u001b[0m Finished trial#99 with value: 0.656 with parameters: {'lambd': 0.3453939912739479, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:00,493]\u001b[0m Finished trial#100 with value: 0.63 with parameters: {'lambd': 9.789427974302615, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:03,412]\u001b[0m Finished trial#101 with value: 0.6565000000000001 with parameters: {'lambd': 4.391524505567707, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:06,326]\u001b[0m Finished trial#102 with value: 0.658 with parameters: {'lambd': 8.264016984377704, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:09,244]\u001b[0m Finished trial#103 with value: 0.655 with parameters: {'lambd': 11.935569576181733, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:12,178]\u001b[0m Finished trial#104 with value: 0.6585 with parameters: {'lambd': 8.667185215825164, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:15,107]\u001b[0m Finished trial#105 with value: 0.656 with parameters: {'lambd': 0.05164986916606118, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:18,033]\u001b[0m Finished trial#106 with value: 0.6580000000000001 with parameters: {'lambd': 10.321483863647188, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:20,942]\u001b[0m Finished trial#107 with value: 0.6559999999999999 with parameters: {'lambd': 2.3747294191309, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:23,181]\u001b[0m Finished trial#108 with value: 0.629 with parameters: {'lambd': 10.553068408322584, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:25,150]\u001b[0m Finished trial#109 with value: 0.6060000000000001 with parameters: {'lambd': 4.611391837363635, 'k': 5, 'power': 3, 'kmer_size': 4, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:28,068]\u001b[0m Finished trial#110 with value: 0.6535 with parameters: {'lambd': 22.030484754830653, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:30,972]\u001b[0m Finished trial#111 with value: 0.658 with parameters: {'lambd': 7.98679599643037, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:33,856]\u001b[0m Finished trial#112 with value: 0.654 with parameters: {'lambd': 12.501603590682368, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:36,764]\u001b[0m Finished trial#113 with value: 0.656 with parameters: {'lambd': 5.608012482963604, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#83 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:39,738]\u001b[0m Finished trial#114 with value: 0.659 with parameters: {'lambd': 9.89046661353822, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:42,691]\u001b[0m Finished trial#115 with value: 0.6585 with parameters: {'lambd': 9.60885887796057, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:44,469]\u001b[0m Finished trial#116 with value: 0.574 with parameters: {'lambd': 10.748255021420004, 'k': 5, 'power': 2, 'kmer_size': 3, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:47,204]\u001b[0m Finished trial#117 with value: 0.631 with parameters: {'lambd': 18.57951238105362, 'k': 8, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:52,882]\u001b[0m Finished trial#118 with value: 0.651 with parameters: {'lambd': 2.5008610442693042, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:55,797]\u001b[0m Finished trial#119 with value: 0.656 with parameters: {'lambd': 5.792496647110056, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:14:58,760]\u001b[0m Finished trial#120 with value: 0.654 with parameters: {'lambd': 12.5779913748093, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:01,706]\u001b[0m Finished trial#121 with value: 0.659 with parameters: {'lambd': 9.736170208790096, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:04,630]\u001b[0m Finished trial#122 with value: 0.6575000000000001 with parameters: {'lambd': 10.880204972398815, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:07,517]\u001b[0m Finished trial#123 with value: 0.6545 with parameters: {'lambd': 14.77570739059962, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:10,418]\u001b[0m Finished trial#124 with value: 0.6565000000000001 with parameters: {'lambd': 6.865464590763937, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:13,342]\u001b[0m Finished trial#125 with value: 0.6585000000000001 with parameters: {'lambd': 9.98138671017603, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:19,020]\u001b[0m Finished trial#126 with value: 0.649 with parameters: {'lambd': 12.666701003679801, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:21,956]\u001b[0m Finished trial#127 with value: 0.6585000000000001 with parameters: {'lambd': 10.150419791736821, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:24,181]\u001b[0m Finished trial#128 with value: 0.6359999999999999 with parameters: {'lambd': 3.6895229955978692, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:27,129]\u001b[0m Finished trial#129 with value: 0.6545 with parameters: {'lambd': 18.905619560378966, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:30,083]\u001b[0m Finished trial#130 with value: 0.658 with parameters: {'lambd': 10.070935838451817, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:33,022]\u001b[0m Finished trial#131 with value: 0.6545 with parameters: {'lambd': 14.664327173532886, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:35,964]\u001b[0m Finished trial#132 with value: 0.6575000000000001 with parameters: {'lambd': 10.669121691615064, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:38,880]\u001b[0m Finished trial#133 with value: 0.6555000000000001 with parameters: {'lambd': 6.027573231088831, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:41,785]\u001b[0m Finished trial#134 with value: 0.6585 with parameters: {'lambd': 9.458576694371358, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:44,707]\u001b[0m Finished trial#135 with value: 0.6585000000000001 with parameters: {'lambd': 10.034583152159069, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:47,623]\u001b[0m Finished trial#136 with value: 0.6545 with parameters: {'lambd': 13.760858880664562, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:49,855]\u001b[0m Finished trial#137 with value: 0.63 with parameters: {'lambd': 12.092254378566082, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:55,607]\u001b[0m Finished trial#138 with value: 0.6525000000000001 with parameters: {'lambd': 1.275790787260016, 'k': 5, 'power': 1, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:15:58,540]\u001b[0m Finished trial#139 with value: 0.657 with parameters: {'lambd': 4.323753910939176, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:01,510]\u001b[0m Finished trial#140 with value: 0.659 with parameters: {'lambd': 9.87375070796665, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:04,502]\u001b[0m Finished trial#141 with value: 0.6585000000000001 with parameters: {'lambd': 10.148997180341784, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:07,453]\u001b[0m Finished trial#142 with value: 0.6535 with parameters: {'lambd': 15.723346693256236, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:10,378]\u001b[0m Finished trial#143 with value: 0.6575000000000001 with parameters: {'lambd': 10.69327228662038, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:13,269]\u001b[0m Finished trial#144 with value: 0.654 with parameters: {'lambd': 12.841598354544631, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:16,161]\u001b[0m Finished trial#145 with value: 0.657 with parameters: {'lambd': 7.011998123637867, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:19,052]\u001b[0m Finished trial#146 with value: 0.658 with parameters: {'lambd': 9.133621465303005, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:21,701]\u001b[0m Finished trial#147 with value: 0.632 with parameters: {'lambd': 5.336437532516575, 'k': 8, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:24,580]\u001b[0m Finished trial#148 with value: 0.6535 with parameters: {'lambd': 42.86269070994054, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:30,281]\u001b[0m Finished trial#149 with value: 0.65 with parameters: {'lambd': 15.395442259989625, 'k': 5, 'power': 2, 'kmer_size': 8, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:33,187]\u001b[0m Finished trial#150 with value: 0.654 with parameters: {'lambd': 18.0157055123886, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:36,163]\u001b[0m Finished trial#151 with value: 0.6585 with parameters: {'lambd': 9.520473991224451, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:39,119]\u001b[0m Finished trial#152 with value: 0.6585000000000001 with parameters: {'lambd': 9.948255327926454, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:42,023]\u001b[0m Finished trial#153 with value: 0.6545000000000001 with parameters: {'lambd': 12.162031873563755, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:43,648]\u001b[0m Finished trial#154 with value: 0.5549999999999999 with parameters: {'lambd': 6.992342602749649, 'k': 5, 'power': 2, 'kmer_size': 2, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:46,551]\u001b[0m Finished trial#155 with value: 0.659 with parameters: {'lambd': 9.74874896959509, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:49,458]\u001b[0m Finished trial#156 with value: 0.6565000000000001 with parameters: {'lambd': 4.469168431028657, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:52,348]\u001b[0m Finished trial#157 with value: 0.6545 with parameters: {'lambd': 14.257286803561188, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:55,226]\u001b[0m Finished trial#158 with value: 0.659 with parameters: {'lambd': 9.873127950940125, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:16:58,102]\u001b[0m Finished trial#159 with value: 0.6504999999999999 with parameters: {'lambd': 52.17390555204555, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:01,066]\u001b[0m Finished trial#160 with value: 0.657 with parameters: {'lambd': 11.391255088665202, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:03,958]\u001b[0m Finished trial#161 with value: 0.657 with parameters: {'lambd': 7.103989390015656, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:06,887]\u001b[0m Finished trial#162 with value: 0.6585 with parameters: {'lambd': 9.596664204984858, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:09,823]\u001b[0m Finished trial#163 with value: 0.6585 with parameters: {'lambd': 9.02154132795015, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:12,715]\u001b[0m Finished trial#164 with value: 0.6545 with parameters: {'lambd': 13.734164434720768, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:15,595]\u001b[0m Finished trial#165 with value: 0.655 with parameters: {'lambd': 6.3276041581620195, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:18,464]\u001b[0m Finished trial#166 with value: 0.6575000000000001 with parameters: {'lambd': 10.689673812006733, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:21,384]\u001b[0m Finished trial#167 with value: 0.658 with parameters: {'lambd': 7.791371145036669, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:23,629]\u001b[0m Finished trial#168 with value: 0.6305 with parameters: {'lambd': 12.686937535755288, 'k': 5, 'power': 2, 'kmer_size': 6, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:26,535]\u001b[0m Finished trial#169 with value: 0.6559999999999999 with parameters: {'lambd': 2.7188075273857972, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:29,454]\u001b[0m Finished trial#170 with value: 0.658 with parameters: {'lambd': 8.841142311701232, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:32,377]\u001b[0m Finished trial#171 with value: 0.6575000000000001 with parameters: {'lambd': 10.78990270800083, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:35,259]\u001b[0m Finished trial#172 with value: 0.6565000000000001 with parameters: {'lambd': 5.062019141683181, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:38,154]\u001b[0m Finished trial#173 with value: 0.6585 with parameters: {'lambd': 9.514664592536034, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:41,088]\u001b[0m Finished trial#174 with value: 0.654 with parameters: {'lambd': 12.342087636268285, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:43,946]\u001b[0m Finished trial#175 with value: 0.6585 with parameters: {'lambd': 9.522924765736715, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:46,851]\u001b[0m Finished trial#176 with value: 0.654 with parameters: {'lambd': 16.058138574599873, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:49,759]\u001b[0m Finished trial#177 with value: 0.655 with parameters: {'lambd': 6.180035976504849, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:52,702]\u001b[0m Finished trial#178 with value: 0.6580000000000001 with parameters: {'lambd': 10.265676439489875, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:55,634]\u001b[0m Finished trial#179 with value: 0.6545 with parameters: {'lambd': 14.091898186074676, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:17:58,563]\u001b[0m Finished trial#180 with value: 0.6575 with parameters: {'lambd': 7.52372259611062, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:01,561]\u001b[0m Finished trial#181 with value: 0.6585 with parameters: {'lambd': 9.611157547448293, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:04,520]\u001b[0m Finished trial#182 with value: 0.6585000000000001 with parameters: {'lambd': 9.988431861113344, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:07,406]\u001b[0m Finished trial#183 with value: 0.6555 with parameters: {'lambd': 11.671057721942962, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:10,301]\u001b[0m Finished trial#184 with value: 0.654 with parameters: {'lambd': 12.417695300034957, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:13,172]\u001b[0m Finished trial#185 with value: 0.6580000000000001 with parameters: {'lambd': 10.367688879125275, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:16,053]\u001b[0m Finished trial#186 with value: 0.657 with parameters: {'lambd': 7.294126642240004, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:18,935]\u001b[0m Finished trial#187 with value: 0.6565000000000001 with parameters: {'lambd': 5.176104508986345, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:21,592]\u001b[0m Finished trial#188 with value: 0.6315000000000001 with parameters: {'lambd': 7.786938254872407, 'k': 8, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:24,461]\u001b[0m Finished trial#189 with value: 0.6565000000000001 with parameters: {'lambd': 3.3186773861305996, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:27,336]\u001b[0m Finished trial#190 with value: 0.6535 with parameters: {'lambd': 15.401750100921028, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:30,249]\u001b[0m Finished trial#191 with value: 0.658 with parameters: {'lambd': 10.07833534351078, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:33,176]\u001b[0m Finished trial#192 with value: 0.658 with parameters: {'lambd': 8.109804015252184, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:36,138]\u001b[0m Finished trial#193 with value: 0.654 with parameters: {'lambd': 12.78425898162265, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:39,128]\u001b[0m Finished trial#194 with value: 0.6585 with parameters: {'lambd': 8.98540019957408, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:42,082]\u001b[0m Finished trial#195 with value: 0.656 with parameters: {'lambd': 5.864416259181492, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:45,023]\u001b[0m Finished trial#196 with value: 0.658 with parameters: {'lambd': 10.044436672825157, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:47,942]\u001b[0m Finished trial#197 with value: 0.6555000000000001 with parameters: {'lambd': 11.801900678188392, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:50,817]\u001b[0m Finished trial#198 with value: 0.6545 with parameters: {'lambd': 14.542059883248445, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:53,722]\u001b[0m Finished trial#199 with value: 0.6585 with parameters: {'lambd': 8.67325935491185, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:56,593]\u001b[0m Finished trial#200 with value: 0.656 with parameters: {'lambd': 4.805115088073325, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:18:59,464]\u001b[0m Finished trial#201 with value: 0.6585 with parameters: {'lambd': 8.648636169248906, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:02,341]\u001b[0m Finished trial#202 with value: 0.657 with parameters: {'lambd': 11.280022388965822, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:05,219]\u001b[0m Finished trial#203 with value: 0.657 with parameters: {'lambd': 7.113675802580477, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:08,081]\u001b[0m Finished trial#204 with value: 0.658 with parameters: {'lambd': 8.741473035989046, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:10,944]\u001b[0m Finished trial#205 with value: 0.6535 with parameters: {'lambd': 13.41389795259089, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:13,836]\u001b[0m Finished trial#206 with value: 0.6585 with parameters: {'lambd': 9.628132647662591, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:16,727]\u001b[0m Finished trial#207 with value: 0.6575000000000001 with parameters: {'lambd': 11.166594870100404, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:19,606]\u001b[0m Finished trial#208 with value: 0.655 with parameters: {'lambd': 6.322815310461417, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:22,465]\u001b[0m Finished trial#209 with value: 0.6519999999999999 with parameters: {'lambd': 84.42241940705547, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:25,427]\u001b[0m Finished trial#210 with value: 0.6515000000000001 with parameters: {'lambd': 10.130129277390528, 'k': 4, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:28,237]\u001b[0m Finished trial#211 with value: 0.6580000000000001 with parameters: {'lambd': 10.546765479665254, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:31,073]\u001b[0m Finished trial#212 with value: 0.6585 with parameters: {'lambd': 8.686702997051656, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:33,921]\u001b[0m Finished trial#213 with value: 0.6575 with parameters: {'lambd': 7.4295528847709935, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:36,821]\u001b[0m Finished trial#214 with value: 0.6535 with parameters: {'lambd': 13.405352998934232, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:39,785]\u001b[0m Finished trial#215 with value: 0.627 with parameters: {'lambd': 11.847524547601807, 'k': 5, 'power': 5, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:42,652]\u001b[0m Finished trial#216 with value: 0.658 with parameters: {'lambd': 8.23454783223159, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:45,502]\u001b[0m Finished trial#217 with value: 0.6415 with parameters: {'lambd': 4.186824571384043, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'linear'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:48,367]\u001b[0m Finished trial#218 with value: 0.6555000000000001 with parameters: {'lambd': 5.969830174484635, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:51,240]\u001b[0m Finished trial#219 with value: 0.6575000000000001 with parameters: {'lambd': 10.62917158756695, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:54,102]\u001b[0m Finished trial#220 with value: 0.658 with parameters: {'lambd': 9.184531717889719, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:56,997]\u001b[0m Finished trial#221 with value: 0.658 with parameters: {'lambd': 9.19369990694, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:19:59,885]\u001b[0m Finished trial#222 with value: 0.6585 with parameters: {'lambd': 9.401887068634606, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:02,773]\u001b[0m Finished trial#223 with value: 0.654 with parameters: {'lambd': 12.90235692069458, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:05,699]\u001b[0m Finished trial#224 with value: 0.658 with parameters: {'lambd': 7.932252236727603, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:08,614]\u001b[0m Finished trial#225 with value: 0.657 with parameters: {'lambd': 11.28310875134295, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:11,492]\u001b[0m Finished trial#226 with value: 0.655 with parameters: {'lambd': 6.214805620960541, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:14,370]\u001b[0m Finished trial#227 with value: 0.6585 with parameters: {'lambd': 9.06009816968571, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:17,262]\u001b[0m Finished trial#228 with value: 0.6545 with parameters: {'lambd': 13.847950708692496, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:20,114]\u001b[0m Finished trial#229 with value: 0.6585 with parameters: {'lambd': 8.940308994660345, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:22,956]\u001b[0m Finished trial#230 with value: 0.6565000000000001 with parameters: {'lambd': 6.721539876419431, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:25,817]\u001b[0m Finished trial#231 with value: 0.6565 with parameters: {'lambd': 11.444477495456372, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:28,685]\u001b[0m Finished trial#232 with value: 0.659 with parameters: {'lambd': 9.844111865376718, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:31,583]\u001b[0m Finished trial#233 with value: 0.658 with parameters: {'lambd': 9.26917476153622, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:34,435]\u001b[0m Finished trial#234 with value: 0.6555000000000001 with parameters: {'lambd': 11.806133679737497, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:37,318]\u001b[0m Finished trial#235 with value: 0.6575 with parameters: {'lambd': 7.370242076503145, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:40,202]\u001b[0m Finished trial#236 with value: 0.658 with parameters: {'lambd': 8.010784302601444, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:43,079]\u001b[0m Finished trial#237 with value: 0.6585000000000001 with parameters: {'lambd': 9.975815439259128, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:45,956]\u001b[0m Finished trial#238 with value: 0.6565000000000001 with parameters: {'lambd': 4.559447298635133, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:47,936]\u001b[0m Finished trial#239 with value: 0.6054999999999999 with parameters: {'lambd': 13.357928570863223, 'k': 5, 'power': 2, 'kmer_size': 5, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:50,796]\u001b[0m Finished trial#240 with value: 0.6575000000000001 with parameters: {'lambd': 10.753984399540483, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:53,654]\u001b[0m Finished trial#241 with value: 0.6585000000000001 with parameters: {'lambd': 10.215645690254108, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:56,483]\u001b[0m Finished trial#242 with value: 0.6580000000000001 with parameters: {'lambd': 10.255774955207366, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:20:59,345]\u001b[0m Finished trial#243 with value: 0.654 with parameters: {'lambd': 12.474256881013135, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:02,179]\u001b[0m Finished trial#244 with value: 0.6575 with parameters: {'lambd': 7.4574537950705295, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:05,044]\u001b[0m Finished trial#245 with value: 0.659 with parameters: {'lambd': 9.841367986855587, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:07,665]\u001b[0m Finished trial#246 with value: 0.6325000000000001 with parameters: {'lambd': 15.763203084096865, 'k': 8, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:10,548]\u001b[0m Finished trial#247 with value: 0.6585 with parameters: {'lambd': 8.53621050914236, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:13,408]\u001b[0m Finished trial#248 with value: 0.655 with parameters: {'lambd': 11.992976804949219, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:16,287]\u001b[0m Finished trial#249 with value: 0.6580000000000001 with parameters: {'lambd': 10.339022639932503, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:19,184]\u001b[0m Finished trial#250 with value: 0.6545 with parameters: {'lambd': 14.250606142968156, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:22,089]\u001b[0m Finished trial#251 with value: 0.656 with parameters: {'lambd': 5.62801609248475, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:24,996]\u001b[0m Finished trial#252 with value: 0.657 with parameters: {'lambd': 11.369857626730044, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:27,887]\u001b[0m Finished trial#253 with value: 0.6555000000000001 with parameters: {'lambd': 6.606001401631935, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 23:21:30,813]\u001b[0m Finished trial#254 with value: 0.658 with parameters: {'lambd': 7.705839106894462, 'k': 5, 'power': 2, 'kmer_size': 7, 'kernel': 'polynomial'}. Best is trial#114 with value: 0.659.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    lambd = trial.suggest_float('lambd', 1e-2, 100.0)\n",
    "#     sigma = trial.suggest_loguniform('sigma', 10, 150)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8])\n",
    "    power =  trial.suggest_int('power', 1,5)\n",
    "    kmer_size =  trial.suggest_int('kmer_size', 1,8)\n",
    "    kernel =  trial.suggest_categorical('kernel', ['linear','polynomial'])\n",
    "    \n",
    "    return cross_validate(get_data(kmer_size)[:2000,:],y,kernel=kernel,lambd=lambd,k=k,sigma=3,power=power)\n",
    "\n",
    "\n",
    "# cross_validate(X_train_mat100, y,lamda=0.01,k=4)\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "df = study.optimize(func=objective, n_trials=500,show_progress_bar=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_k</th>\n",
       "      <th>params_kernel</th>\n",
       "      <th>params_lambd</th>\n",
       "      <th>params_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>00:00:02.410745</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>273</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>00:00:02.412150</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>235</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>00:00:02.377848</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>00:00:02.484421</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>00:00:02.481802</td>\n",
       "      <td>8</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>382</td>\n",
       "      <td>0.6545</td>\n",
       "      <td>00:00:03.752672</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>450</td>\n",
       "      <td>0.6545</td>\n",
       "      <td>00:00:03.752491</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>00:00:03.686736</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>340</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>00:00:03.718721</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number   value        duration  params_k params_kernel  params_lambd  params_power\n",
       "76       76  0.5645 00:00:02.410745         8    polynomial            51             1\n",
       "273     273  0.5875 00:00:02.412150         8    polynomial             6             1\n",
       "235     235  0.5925 00:00:02.377848         8    polynomial             5             1\n",
       "138     138  0.6000 00:00:02.484421         8    polynomial             3             1\n",
       "185     185  0.6000 00:00:02.481802         8    polynomial             3             1\n",
       "..      ...     ...             ...       ...           ...           ...           ...\n",
       "382     382  0.6545 00:00:03.752672         4    polynomial             9             2\n",
       "450     450  0.6545 00:00:03.752491         4    polynomial            10             2\n",
       "337     337  0.6550 00:00:03.686736         4    polynomial             3             2\n",
       "340     340  0.6555 00:00:03.718721         4    polynomial             1             2\n",
       "451     451     NaN             NaT         4    polynomial            14             2\n",
       "\n",
       "[452 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340, 65536) (660, 65536) (1340,) (660,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test(np.array(kmer_data)[:2000,:],y,0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6712121212121213"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KernelRidgeRegression(\n",
    "                kernel='polynomial',\n",
    "                lambd=0.0001,\n",
    "                sigma=50,\n",
    "                power=2\n",
    "            ).fit(X_train, y_train)\n",
    "result = sum(np.sign(model.predict(X_test))==y_test)/len(y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6555])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(np.array(kmer_data)[:2000,:],y,kernel='polynomial',k=4,power=2,lambd=1,sigma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Bound\n",
       "0    0      1\n",
       "1    1      1\n",
       "2    2      0\n",
       "3    3      0\n",
       "4    4      1\n",
       "5    5      1\n",
       "6    6      0\n",
       "7    7      0\n",
       "8    8      1\n",
       "9    9      1\n",
       "10  10      1\n",
       "11  11      1\n",
       "12  12      1\n",
       "13  13      0\n",
       "14  14      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final = np.array(kmer_data)[2000:,:]\n",
    "\n",
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_final)):\n",
    "    r1 = np.sign(model.predict(X_test_final[i]))\n",
    "    \n",
    "    if r1 == 1:\n",
    "        sumbission.append([i,int(r1)])\n",
    "    elif r1 == -1:\n",
    "        sumbission.append([i,0])\n",
    "    else:\n",
    "        print('problem')\n",
    "        \n",
    "    \n",
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('cv_655_linear_overfitted.csv',index=False)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

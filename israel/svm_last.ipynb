{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cvxopt -q\n",
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "cvxopt.solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test_ = pd.read_csv('../data/Xte.csv',sep=',',index_col=0)\n",
    "X_train_ = pd.read_csv('../data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "X_test_mat100 = pd.read_csv('../data/Xte_mat100.csv',sep=' ',header=None).values\n",
    "X_train_mat100 = pd.read_csv('../data/Xtr_mat100.csv',sep=' ',header=None).values\n",
    "\n",
    "y = pd.read_csv('../data/Ytr.csv',sep=',',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, ...,  1,  1,  1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "y.head()\n",
    "y = y.Bound.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y,p):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=p, random_state=42)\n",
    "    print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def getKmers(sequence, size=6):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]\n",
    "\n",
    "def base2int(c):\n",
    "    return {'a':0,'c':1,'g':2,'t':3}.get(c,0)\n",
    "\n",
    "def index(kmer):\n",
    "    base_idx = np.array([base2int(base) for base in kmer])\n",
    "    multiplier = 4** np.arange(len(kmer))\n",
    "    kmer_idx = multiplier.dot(base_idx)\n",
    "    return kmer_idx\n",
    "    \n",
    "    \n",
    "def spectral_embedding(sequence,kmer_size=3):\n",
    "    kmers = getKmers(sequence,kmer_size)\n",
    "    kmer_idxs = [index(kmer) for kmer in kmers]\n",
    "    one_hot_vector = np.zeros(4**kmer_size)\n",
    "    \n",
    "    for kmer_idx in kmer_idxs:\n",
    "        one_hot_vector[kmer_idx] += 1\n",
    "    return one_hot_vector\n",
    "\n",
    "\n",
    "def get_data(kmer_size):\n",
    "    data = pd.DataFrame(pd.concat([X_train_.seq,X_test_.seq],axis=0))\n",
    "    train_text = data.seq.values\n",
    "    # X_train_['kmers'] = X_train_.seq.apply(lambda x:list(spectral_embedding(x,kmer_size=3)))\n",
    "    kmer_data = []\n",
    "    for i in train_text:\n",
    "        kmer_data.append(spectral_embedding(i,kmer_size=kmer_size))\n",
    "\n",
    "    return np.array(kmer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel_element_wise(x, y, sigma=1):\n",
    "    K =  np.exp(-np.sum((x-y)**2)/(2*sigma**2))\n",
    "    return K\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=5.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "def polynomial_kernel(X1, X2, power=2):\n",
    "    return np.power((1 + linear_kernel(X1, X2)),power)\n",
    "\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    X2_norm = np.sum(X2 ** 2, axis = -1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis = -1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "def linear_kernel(X1, X2):\n",
    "    return X1.dot(X2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelMethodBase(object):\n",
    "    '''\n",
    "    Base class for kernel methods models\n",
    "    \n",
    "    Methods\n",
    "    ----\n",
    "    fit\n",
    "    predict\n",
    "    '''\n",
    "    kernels_ = {\n",
    "        'linear': linear_kernel,\n",
    "        'polynomial': polynomial_kernel,\n",
    "        'rbf': rbf_kernel,\n",
    "        'gaussian':gaussian_kernel\n",
    "    }\n",
    "    def __init__(self, kernel='linear', **kwargs):\n",
    "        self.kernel_name = kernel\n",
    "        self.kernel_function_ = self.kernels_[kernel]\n",
    "        self.kernel_parameters = self.get_kernel_parameters(**kwargs)\n",
    "        \n",
    "    def get_kernel_parameters(self, **kwargs):\n",
    "        params = {}\n",
    "        if self.kernel_name == 'rbf' or self.kernel_name == 'gaussian':\n",
    "            params['sigma'] = kwargs.get('sigma', None)\n",
    "        if self.kernel_name == 'polynomial':\n",
    "            params['power'] = kwargs.get('power', None)\n",
    "            \n",
    "        \n",
    "        return params\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cvxopt_qp(P, q, G, h, A, b):\n",
    "#     P = .5 * (P + P.T)\n",
    "#     cvx_matrices = [\n",
    "#         cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "#     ]\n",
    "#     #cvxopt.solvers.options['show_progress'] = False\n",
    "#     solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "#     return np.array(solution['x']).flatten()\n",
    "\n",
    "# solve_qp = cvxopt_qp\n",
    "\n",
    "\n",
    "# def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
    "#     n = K.shape[0]\n",
    "#     assert (len(y) == n)\n",
    "        \n",
    "#     # Dual formulation, soft margin\n",
    "#     # P = np.diag(y) @ K @ np.diag(y)\n",
    "#     P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "#     # As a regularization, we add epsilon * identity to P\n",
    "#     eps = 1e-12\n",
    "#     P += eps * np.eye(n)\n",
    "#     q = - np.ones(n)\n",
    "#     G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "#     h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "#     A = y[np.newaxis, :]\n",
    "#     b = np.array([0.])\n",
    "#     return P, q, G, h, A.astype(float), b\n",
    "\n",
    "# K = linear_kernel(X_train, X_train)\n",
    "# alphas = solve_qp(*svm_dual_soft_to_qp_kernel(K, y_train, C=1.))\n",
    "\n",
    "\n",
    "# class KernelSVM(KernelMethodBase):\n",
    "#     '''\n",
    "#     Kernel SVM Classification\n",
    "    \n",
    "#     Methods\n",
    "#     ----\n",
    "#     fit\n",
    "#     predict\n",
    "#     '''\n",
    "#     def __init__(self, C=0.1, **kwargs):\n",
    "#         self.C = C\n",
    "#         # Python 3: replace the following line by\n",
    "#         # super().__init__(**kwargs)\n",
    "#         super(KernelSVM, self).__init__(**kwargs)\n",
    "\n",
    "#     def fit(self, X, y, tol=1e-8):\n",
    "#         n, p = X.shape\n",
    "#         assert (n == len(y))\n",
    "    \n",
    "#         self.X_train = X\n",
    "#         self.y_train = y\n",
    "        \n",
    "#         # Kernel matrix\n",
    "#         K = self.kernel_function_(\n",
    "#             self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "#         # Solve dual problem\n",
    "#         self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "#         # Compute support vectors and bias b\n",
    "#         sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "#         self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "#         self.bias = self.bias.mean()\n",
    "\n",
    "#         self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "#         return self\n",
    "        \n",
    "#     def decision_function(self, X):\n",
    "#         K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "#         return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return np.sign(self.decision_function(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 4096) (600, 4096) (1400,) (600,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6583333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class KernelSVM(KernelMethodBase):\n",
    "    def __init__(self, C=0.1, **kwargs):\n",
    "        self.C = C\n",
    "        # Python 3: replace the following line by\n",
    "        # super().__init__(**kwargs)\n",
    "        super(KernelSVM, self).__init__(**kwargs)\n",
    "        \n",
    "    def cvxopt_qp(self,P, q, G, h, A, b):\n",
    "        P = .5 * (P + P.T)\n",
    "        cvx_matrices = [\n",
    "            cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "        ]\n",
    "        #cvxopt.solvers.options['show_progress'] = False\n",
    "        solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "        return np.array(solution['x']).flatten()\n",
    "    \n",
    "    def svm_dual_soft_to_qp_kernel(self,K, y, C=1):\n",
    "        n = K.shape[0]\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        # Dual formulation, soft margin\n",
    "        # P = np.diag(y) @ K @ np.diag(y)\n",
    "        P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "        # As a regularization, we add epsilon * identity to P\n",
    "        eps = 1e-12\n",
    "        P += eps * np.eye(n)\n",
    "        q = - np.ones(n)\n",
    "        G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "        h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "        A = y[np.newaxis, :]\n",
    "        b = np.array([0.])\n",
    "        return P, q, G, h, A.astype(float), b\n",
    "\n",
    "\n",
    "    def fit(self, X, y, tol=1e-8):\n",
    "        n, p = X.shape\n",
    "        assert (n == len(y))\n",
    "    \n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        # Kernel matrix\n",
    "        K = self.kernel_function_(\n",
    "            self.X_train, self.X_train, **self.kernel_parameters)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = self.cvxopt_qp(*self.svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha > tol), (self.C - self.alpha > tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha * y)\n",
    "        self.bias = self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        K_x = self.kernel_function_(X, self.X_train, **self.kernel_parameters)\n",
    "        return K_x.dot(self.alpha * self.y_train) + self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(self.decision_function(X))\n",
    "    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = get_train_test(get_data(6)[:2000,:],y,p=0.3)\n",
    "\n",
    "\n",
    "kernel = 'polynomial'\n",
    "power = 2\n",
    "sigma = 5.\n",
    "C = 10.\n",
    "model = KernelSVM(C=C, kernel=kernel, sigma=sigma, power=power)\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "sum(y_pred==y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 4096) (600, 4096) (1400,) (600,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6583333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, ..., -1,  1,  1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = pd.read_csv('../data/Xte.csv',sep=',',index_col=0).values\n",
    "X_train = pd.read_csv('../data/Xtr.csv',sep=',',index_col=0).values\n",
    "\n",
    "y = pd.read_csv('../data/Ytr.csv',sep=',',index_col=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 1), (1000, 1))"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "\n",
    "cv = CountVectorizer()\n",
    "for i in X_train:\n",
    "    sentence = ' '.join(getKmers(i[0], size=2))\n",
    "    X.append(sentence)\n",
    "    \n",
    "X_te = []\n",
    "\n",
    "\n",
    "for i in X_test:\n",
    "    sentence = ' '.join(getKmers(i[0], size=2))\n",
    "    X_te.append(sentence)\n",
    "\n",
    "X = cv.fit_transform(X+X_te).toarray()\n",
    "# break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (2000, 16) y_train (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train: {} y_train {}'.format(X[:2000,:].shape,y.shape))\n",
    "\n",
    "# print('x_train: {} y_train {}'.format(X_train.shape,y.shape))\n",
    "# print('x_test: {}'.format(X_te.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340, 16) (660, 16) (1340, 1) (660, 1) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_tr= scale(X[:2000,:])\n",
    "X_te = scale(X[2000:,:])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tr, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape,X_val.shape,y_train.shape, y_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticregression():\n",
    "    def __init__(self,train_data,train_labels,lamda=0.2,lr=0.01,decay=10,batch_size=None,epoch=10,print_every = 10):\n",
    "        dummy_once = np.ones((len(train_data),1))\n",
    "        self.train_data = np.hstack((dummy_once,train_data))\n",
    "        self.train_labels = train_labels\n",
    "        \n",
    "        self.params = np.zeros((len(self.train_data[0]),1))\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.print_every = print_every\n",
    "        self._lambda = lamda\n",
    "        self.decay = decay\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def cost(self,y,y_pred):\n",
    "        return -np.mean(y*np.log(y_pred)+(1-y)*np.log(1-y_pred))\n",
    "    \n",
    "    def gradient(self,y,y_pred,x):\n",
    "        return np.dot(x.T,(y_pred-y))+(2*self._lambda*self.params)\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            y_pred = self.sigmoid(np.dot(self.train_data,self.params))\n",
    "            loss = self.cost(self.train_labels,y_pred)\n",
    "            \n",
    "            gra = self.gradient(self.train_labels,y_pred,self.train_data)\n",
    "            \n",
    "            self.params -= self.lr*gra\n",
    "            \n",
    "            self.lr *= (1. / (1. + self.decay * i))\n",
    "            \n",
    "            if self.print_every:\n",
    "                if i%self.print_every == 0 or i == self.epoch-1:\n",
    "                    print('Epoch : {}  Loss: {}'.format(i,loss))\n",
    "    def predict(self,test_data):\n",
    "        result = self.sigmoid(np.dot(test_data,self.params[1:])+self.params[0])\n",
    "        result[result > 0.5 ] = 1\n",
    "        result[result <= 0.5 ] = 0\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self,test_data,labels):\n",
    "        accuracy = accuracy_score(self.predict(test_data),labels)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=5,decay=10):\n",
    "    if len(x_data)%k != 0:\n",
    "        print('cant vsplit',len(x_data),' by ',k)\n",
    "        return\n",
    "    \n",
    "    x_data_splitted = np.vsplit(x_data,k)\n",
    "    y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "    aggrigate_result = []\n",
    "    for i in range(len(x_data_splitted)):\n",
    "        train = []\n",
    "        test = []\n",
    "        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "        x_test = x_data_splitted[i]\n",
    "        y_test = y_data_splitted[i]\n",
    "        for item in items:\n",
    "            if len(train) == 0:\n",
    "                x_train = x_data_splitted[item]\n",
    "                y_train = y_data_splitted[item]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "            \n",
    "        logistic = logisticregression(x_train,y_train,lamda=lamda,lr=lr,decay=decay,epoch=epoch)\n",
    "        logistic.train()\n",
    "        \n",
    "        result = logistic.evaluate(x_test,y_test)\n",
    "        aggrigate_result.append(result)\n",
    "        \n",
    "        value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "    return value if value!= None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    lamda = trial.suggest_loguniform('lamda', 0.01, 0.5)\n",
    "    k =  trial.suggest_categorical('k', [4,5,8,10])\n",
    "    epoch =  trial.suggest_int('epoch', 10, 20)\n",
    "    decay = trial.suggest_int('decay', 3, 10)\n",
    "    return cross_validate(X_tr, y,lr=lr,lamda=lamda,k=k,epoch=epoch,decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fe1b8e92c7402ca6bf8fa2357e1744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-25 20:47:33,395]\u001b[0m Finished trial#0 with value: 0.6045 with parameters: {'lr': 0.01649253233594149, 'lamda': 0.36897164878015126, 'k': 10, 'epoch': 19, 'decay': 8}. Best is trial#0 with value: 0.6045.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:33,595]\u001b[0m Finished trial#1 with value: 0.6245 with parameters: {'lr': 1.7769572471647115e-05, 'lamda': 0.05278192749801375, 'k': 4, 'epoch': 16, 'decay': 8}. Best is trial#1 with value: 0.6245.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:33,818]\u001b[0m Finished trial#2 with value: 0.614 with parameters: {'lr': 2.0668987174148333e-05, 'lamda': 0.023056782989366083, 'k': 8, 'epoch': 20, 'decay': 9}. Best is trial#1 with value: 0.6245.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:34,039]\u001b[0m Finished trial#3 with value: 0.614 with parameters: {'lr': 3.874152905085708e-05, 'lamda': 0.010067497058614145, 'k': 8, 'epoch': 16, 'decay': 9}. Best is trial#1 with value: 0.6245.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:34,230]\u001b[0m Finished trial#4 with value: 0.6154999999999999 with parameters: {'lr': 0.00031497518882394736, 'lamda': 0.01708022900743641, 'k': 8, 'epoch': 12, 'decay': 8}. Best is trial#1 with value: 0.6245.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:34,425]\u001b[0m Finished trial#5 with value: 0.6235 with parameters: {'lr': 0.0007361519000285039, 'lamda': 0.047102753305138946, 'k': 4, 'epoch': 15, 'decay': 4}. Best is trial#1 with value: 0.6245.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:34,629]\u001b[0m Finished trial#6 with value: 0.6205 with parameters: {'lr': 0.0035671559882171347, 'lamda': 0.04278085654579171, 'k': 5, 'epoch': 16, 'decay': 4}. Best is trial#1 with value: 0.6245.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:34,824]\u001b[0m Finished trial#7 with value: 0.6275 with parameters: {'lr': 0.004360697790934184, 'lamda': 0.09647342781647629, 'k': 4, 'epoch': 15, 'decay': 9}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:35,062]\u001b[0m Finished trial#8 with value: 0.6064999999999999 with parameters: {'lr': 0.00023295451970695692, 'lamda': 0.013069060209128756, 'k': 10, 'epoch': 19, 'decay': 10}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:35,262]\u001b[0m Finished trial#9 with value: 0.613 with parameters: {'lr': 0.052725856169306674, 'lamda': 0.21661947945456403, 'k': 8, 'epoch': 13, 'decay': 4}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:35,453]\u001b[0m Finished trial#10 with value: 0.626 with parameters: {'lr': 0.004442941825532957, 'lamda': 0.13778406861857478, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#7 with value: 0.6275.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning:\n",
      "\n",
      "overflow encountered in exp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-25 20:47:35,643]\u001b[0m Finished trial#11 with value: 0.6255000000000001 with parameters: {'lr': 0.005502896969874503, 'lamda': 0.13820595968601468, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:35,837]\u001b[0m Finished trial#12 with value: 0.6234999999999999 with parameters: {'lr': 0.08821116894760933, 'lamda': 0.11398047120491855, 'k': 4, 'epoch': 13, 'decay': 6}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:36,027]\u001b[0m Finished trial#13 with value: 0.625 with parameters: {'lr': 0.003592286286081175, 'lamda': 0.09960611239538093, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:36,247]\u001b[0m Finished trial#14 with value: 0.6245 with parameters: {'lr': 0.00990923468470102, 'lamda': 0.2511488906110466, 'k': 4, 'epoch': 14, 'decay': 7}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:36,433]\u001b[0m Finished trial#15 with value: 0.6159999999999999 with parameters: {'lr': 0.0013528692316793754, 'lamda': 0.17698827132092254, 'k': 5, 'epoch': 11, 'decay': 5}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:36,648]\u001b[0m Finished trial#16 with value: 0.624 with parameters: {'lr': 0.031216237271781227, 'lamda': 0.0781063182750711, 'k': 4, 'epoch': 17, 'decay': 10}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:36,846]\u001b[0m Finished trial#17 with value: 0.626 with parameters: {'lr': 0.0010568444699411992, 'lamda': 0.38865316790436466, 'k': 4, 'epoch': 14, 'decay': 3}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:37,060]\u001b[0m Finished trial#18 with value: 0.6095 with parameters: {'lr': 0.0001043236132128186, 'lamda': 0.47193535058609304, 'k': 10, 'epoch': 14, 'decay': 3}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:37,296]\u001b[0m Finished trial#19 with value: 0.6154999999999999 with parameters: {'lr': 0.001348479843522254, 'lamda': 0.340949021056856, 'k': 5, 'epoch': 18, 'decay': 3}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:37,494]\u001b[0m Finished trial#20 with value: 0.6265 with parameters: {'lr': 0.0005067606403570922, 'lamda': 0.024807015209225177, 'k': 4, 'epoch': 14, 'decay': 9}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:37,691]\u001b[0m Finished trial#21 with value: 0.627 with parameters: {'lr': 0.0004621935128006236, 'lamda': 0.027468176903212856, 'k': 4, 'epoch': 14, 'decay': 9}. Best is trial#7 with value: 0.6275.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:37,894]\u001b[0m Finished trial#22 with value: 0.6285000000000001 with parameters: {'lr': 0.00035115590611788805, 'lamda': 0.030710782909473263, 'k': 4, 'epoch': 15, 'decay': 9}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:38,105]\u001b[0m Finished trial#23 with value: 0.623 with parameters: {'lr': 8.592711478312667e-05, 'lamda': 0.03127967721683852, 'k': 4, 'epoch': 15, 'decay': 10}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:38,310]\u001b[0m Finished trial#24 with value: 0.6244999999999999 with parameters: {'lr': 0.00015129523791196508, 'lamda': 0.057701176704063745, 'k': 4, 'epoch': 17, 'decay': 9}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:38,509]\u001b[0m Finished trial#25 with value: 0.6265000000000001 with parameters: {'lr': 0.0020437367901773133, 'lamda': 0.03365861951795124, 'k': 4, 'epoch': 13, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:38,709]\u001b[0m Finished trial#26 with value: 0.627 with parameters: {'lr': 0.00047301366965002867, 'lamda': 0.0738866244782787, 'k': 4, 'epoch': 12, 'decay': 7}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:38,902]\u001b[0m Finished trial#27 with value: 0.623 with parameters: {'lr': 5.1996854279161145e-05, 'lamda': 0.07333822937998265, 'k': 4, 'epoch': 12, 'decay': 7}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:39,110]\u001b[0m Finished trial#28 with value: 0.625 with parameters: {'lr': 0.00024900404859927417, 'lamda': 0.01930578012995807, 'k': 4, 'epoch': 15, 'decay': 10}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:39,332]\u001b[0m Finished trial#29 with value: 0.6045 with parameters: {'lr': 0.009743360223489268, 'lamda': 0.08979381574075343, 'k': 10, 'epoch': 17, 'decay': 7}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:39,561]\u001b[0m Finished trial#30 with value: 0.6214999999999999 with parameters: {'lr': 0.002093130006546658, 'lamda': 0.035693916618320345, 'k': 5, 'epoch': 16, 'decay': 9}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:39,764]\u001b[0m Finished trial#31 with value: 0.626 with parameters: {'lr': 0.0006235107412163232, 'lamda': 0.060294408718766665, 'k': 4, 'epoch': 12, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:39,962]\u001b[0m Finished trial#32 with value: 0.628 with parameters: {'lr': 0.00041297517645634134, 'lamda': 0.027091007305578448, 'k': 4, 'epoch': 13, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:40,152]\u001b[0m Finished trial#33 with value: 0.624 with parameters: {'lr': 0.00016014998383214526, 'lamda': 0.044456071728558304, 'k': 4, 'epoch': 11, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:40,343]\u001b[0m Finished trial#34 with value: 0.6275000000000001 with parameters: {'lr': 0.0003702997340302378, 'lamda': 0.013581282640882889, 'k': 4, 'epoch': 13, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:40,568]\u001b[0m Finished trial#35 with value: 0.614 with parameters: {'lr': 3.467128719751842e-05, 'lamda': 0.01005855700858628, 'k': 8, 'epoch': 13, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:40,767]\u001b[0m Finished trial#36 with value: 0.6265 with parameters: {'lr': 0.002066898403354002, 'lamda': 0.017238991461620324, 'k': 4, 'epoch': 15, 'decay': 9}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:40,976]\u001b[0m Finished trial#37 with value: 0.628 with parameters: {'lr': 0.00034123987250722783, 'lamda': 0.011880814060382765, 'k': 4, 'epoch': 16, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:41,207]\u001b[0m Finished trial#38 with value: 0.609 with parameters: {'lr': 0.00037144155498217867, 'lamda': 0.012441113556618833, 'k': 10, 'epoch': 16, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:41,428]\u001b[0m Finished trial#39 with value: 0.614 with parameters: {'lr': 1.3371401478511419e-05, 'lamda': 0.012607567249083181, 'k': 8, 'epoch': 18, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:41,651]\u001b[0m Finished trial#40 with value: 0.624 with parameters: {'lr': 0.0007680894568736407, 'lamda': 0.021187589321355615, 'k': 4, 'epoch': 11, 'decay': 7}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:41,868]\u001b[0m Finished trial#41 with value: 0.624 with parameters: {'lr': 0.00023784673550818707, 'lamda': 0.015126154847628493, 'k': 4, 'epoch': 16, 'decay': 9}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:42,072]\u001b[0m Finished trial#42 with value: 0.6234999999999999 with parameters: {'lr': 0.00011835812678694903, 'lamda': 0.01081810925041348, 'k': 4, 'epoch': 16, 'decay': 9}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:42,284]\u001b[0m Finished trial#43 with value: 0.624 with parameters: {'lr': 6.039499115302426e-05, 'lamda': 0.016320625066468773, 'k': 4, 'epoch': 15, 'decay': 10}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:42,481]\u001b[0m Finished trial#44 with value: 0.6245 with parameters: {'lr': 0.0009073636566390793, 'lamda': 0.023285611448954937, 'k': 4, 'epoch': 13, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:42,712]\u001b[0m Finished trial#45 with value: 0.626 with parameters: {'lr': 0.00027305268770660713, 'lamda': 0.014669259787206868, 'k': 4, 'epoch': 14, 'decay': 9}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:42,924]\u001b[0m Finished trial#46 with value: 0.624 with parameters: {'lr': 0.00017292487419289337, 'lamda': 0.04795323328755316, 'k': 4, 'epoch': 15, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:43,144]\u001b[0m Finished trial#47 with value: 0.6114999999999999 with parameters: {'lr': 0.007309775951566696, 'lamda': 0.03683149504033507, 'k': 8, 'epoch': 14, 'decay': 7}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:43,352]\u001b[0m Finished trial#48 with value: 0.6255000000000001 with parameters: {'lr': 0.018330099649152058, 'lamda': 0.029030268181445492, 'k': 4, 'epoch': 16, 'decay': 9}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:43,556]\u001b[0m Finished trial#49 with value: 0.6134999999999999 with parameters: {'lr': 0.0003464149077697877, 'lamda': 0.1153347856972987, 'k': 5, 'epoch': 17, 'decay': 10}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:43,778]\u001b[0m Finished trial#50 with value: 0.6285 with parameters: {'lr': 0.0015554699987131448, 'lamda': 0.011419253573788236, 'k': 4, 'epoch': 13, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:43,979]\u001b[0m Finished trial#51 with value: 0.6285 with parameters: {'lr': 0.001563215629767272, 'lamda': 0.011075133895729452, 'k': 4, 'epoch': 13, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:44,173]\u001b[0m Finished trial#52 with value: 0.6285 with parameters: {'lr': 0.0015724378146682533, 'lamda': 0.01020926231485372, 'k': 4, 'epoch': 12, 'decay': 8}. Best is trial#22 with value: 0.6285000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:44,366]\u001b[0m Finished trial#53 with value: 0.629 with parameters: {'lr': 0.0014019379397919225, 'lamda': 0.010912420974984353, 'k': 4, 'epoch': 12, 'decay': 8}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:44,561]\u001b[0m Finished trial#54 with value: 0.6285 with parameters: {'lr': 0.001542869713736636, 'lamda': 0.011059134316259376, 'k': 4, 'epoch': 12, 'decay': 7}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:44,785]\u001b[0m Finished trial#55 with value: 0.628 with parameters: {'lr': 0.0027729908284331375, 'lamda': 0.010863049056778828, 'k': 4, 'epoch': 11, 'decay': 7}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:44,980]\u001b[0m Finished trial#56 with value: 0.629 with parameters: {'lr': 0.001382541476423856, 'lamda': 0.018631090473799555, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:45,186]\u001b[0m Finished trial#57 with value: 0.6085 with parameters: {'lr': 0.001155683000701849, 'lamda': 0.019213489549834893, 'k': 10, 'epoch': 11, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:45,380]\u001b[0m Finished trial#58 with value: 0.6275 with parameters: {'lr': 0.002822087679234614, 'lamda': 0.018335123139159838, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:45,575]\u001b[0m Finished trial#59 with value: 0.626 with parameters: {'lr': 0.0048970549045288265, 'lamda': 0.014281085366069628, 'k': 4, 'epoch': 12, 'decay': 5}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:45,759]\u001b[0m Finished trial#60 with value: 0.625 with parameters: {'lr': 0.0006162818848562156, 'lamda': 0.010254190291126064, 'k': 4, 'epoch': 10, 'decay': 5}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:45,987]\u001b[0m Finished trial#61 with value: 0.629 with parameters: {'lr': 0.001508256842986231, 'lamda': 0.011791187429759528, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:46,184]\u001b[0m Finished trial#62 with value: 0.629 with parameters: {'lr': 0.0016264756650550569, 'lamda': 0.011663870597608043, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:46,380]\u001b[0m Finished trial#63 with value: 0.628 with parameters: {'lr': 0.0027092081730911914, 'lamda': 0.01554626236024492, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:46,576]\u001b[0m Finished trial#64 with value: 0.6255000000000001 with parameters: {'lr': 0.000904963239074703, 'lamda': 0.012856642469662677, 'k': 4, 'epoch': 12, 'decay': 5}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:46,772]\u001b[0m Finished trial#65 with value: 0.625 with parameters: {'lr': 0.003486433799104909, 'lamda': 0.02148638318502336, 'k': 4, 'epoch': 13, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:47,004]\u001b[0m Finished trial#66 with value: 0.6265000000000001 with parameters: {'lr': 0.0017824844269213407, 'lamda': 0.017226768804858225, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:47,196]\u001b[0m Finished trial#67 with value: 0.6285000000000001 with parameters: {'lr': 0.0011209780191896006, 'lamda': 0.013309974620346965, 'k': 4, 'epoch': 11, 'decay': 5}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:47,382]\u001b[0m Finished trial#68 with value: 0.6134999999999999 with parameters: {'lr': 0.0009888465328231006, 'lamda': 0.013702966581173533, 'k': 5, 'epoch': 11, 'decay': 4}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:47,565]\u001b[0m Finished trial#69 with value: 0.6255 with parameters: {'lr': 0.0005720836366777159, 'lamda': 0.020160568140867374, 'k': 4, 'epoch': 10, 'decay': 5}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:47,761]\u001b[0m Finished trial#70 with value: 0.6245 with parameters: {'lr': 0.006260971141493081, 'lamda': 0.024302211837711005, 'k': 4, 'epoch': 11, 'decay': 4}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:47,968]\u001b[0m Finished trial#71 with value: 0.6285 with parameters: {'lr': 0.0012526788405332518, 'lamda': 0.010017996186953797, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:48,158]\u001b[0m Finished trial#72 with value: 0.629 with parameters: {'lr': 0.001134998015553415, 'lamda': 0.01011029512908569, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:48,364]\u001b[0m Finished trial#73 with value: 0.6285000000000001 with parameters: {'lr': 0.0011824142620677342, 'lamda': 0.01232124595819542, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:48,547]\u001b[0m Finished trial#74 with value: 0.624 with parameters: {'lr': 0.000742576510062652, 'lamda': 0.012789277017951437, 'k': 4, 'epoch': 11, 'decay': 5}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:48,733]\u001b[0m Finished trial#75 with value: 0.6244999999999999 with parameters: {'lr': 0.002290350215182055, 'lamda': 0.016523604773738487, 'k': 4, 'epoch': 10, 'decay': 5}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:48,924]\u001b[0m Finished trial#76 with value: 0.625 with parameters: {'lr': 0.003604422582051705, 'lamda': 0.01440966145959531, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:49,158]\u001b[0m Finished trial#77 with value: 0.6124999999999999 with parameters: {'lr': 0.0011173186680664205, 'lamda': 0.011978228827333497, 'k': 8, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:49,366]\u001b[0m Finished trial#78 with value: 0.6094999999999999 with parameters: {'lr': 0.0007375871752694906, 'lamda': 0.016010711953144532, 'k': 10, 'epoch': 11, 'decay': 5}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:49,560]\u001b[0m Finished trial#79 with value: 0.6265 with parameters: {'lr': 0.0005495039671653619, 'lamda': 0.013444037434908638, 'k': 4, 'epoch': 14, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:49,757]\u001b[0m Finished trial#80 with value: 0.6255000000000001 with parameters: {'lr': 0.0008367241551076072, 'lamda': 0.01798505210533286, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:49,950]\u001b[0m Finished trial#81 with value: 0.628 with parameters: {'lr': 0.0012637102250325463, 'lamda': 0.011540855289122489, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:50,175]\u001b[0m Finished trial#82 with value: 0.6275000000000001 with parameters: {'lr': 0.001953742636028593, 'lamda': 0.011903711719183573, 'k': 4, 'epoch': 13, 'decay': 7}. Best is trial#53 with value: 0.629.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:50,384]\u001b[0m Finished trial#83 with value: 0.6295000000000001 with parameters: {'lr': 0.0014425899765042967, 'lamda': 0.010491272752205275, 'k': 4, 'epoch': 11, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:50,567]\u001b[0m Finished trial#84 with value: 0.626 with parameters: {'lr': 0.002331953321567385, 'lamda': 0.010004335381697297, 'k': 4, 'epoch': 11, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:50,760]\u001b[0m Finished trial#85 with value: 0.625 with parameters: {'lr': 0.003491531585651953, 'lamda': 0.014722150540984696, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:50,949]\u001b[0m Finished trial#86 with value: 0.6265 with parameters: {'lr': 0.001017412290794925, 'lamda': 0.013536575740372038, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:51,140]\u001b[0m Finished trial#87 with value: 0.627 with parameters: {'lr': 0.00045546221422091104, 'lamda': 0.012494159920932781, 'k': 4, 'epoch': 11, 'decay': 5}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:51,339]\u001b[0m Finished trial#88 with value: 0.6144999999999999 with parameters: {'lr': 0.0006428981829279778, 'lamda': 0.01013635551135319, 'k': 5, 'epoch': 13, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:51,529]\u001b[0m Finished trial#89 with value: 0.6275 with parameters: {'lr': 0.0012994855313061423, 'lamda': 0.03867224529127161, 'k': 4, 'epoch': 12, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:51,712]\u001b[0m Finished trial#90 with value: 0.629 with parameters: {'lr': 0.0016217265989076635, 'lamda': 0.022285641087804755, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:51,904]\u001b[0m Finished trial#91 with value: 0.6275 with parameters: {'lr': 0.0017191410137636165, 'lamda': 0.0213858705084728, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:52,098]\u001b[0m Finished trial#92 with value: 0.628 with parameters: {'lr': 0.0025972930842243407, 'lamda': 0.02762037811902544, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:52,321]\u001b[0m Finished trial#93 with value: 0.629 with parameters: {'lr': 0.0014724732862101645, 'lamda': 0.025656330297606694, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:52,512]\u001b[0m Finished trial#94 with value: 0.627 with parameters: {'lr': 0.0019720884824915527, 'lamda': 0.03225876076767067, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:52,707]\u001b[0m Finished trial#95 with value: 0.6295000000000001 with parameters: {'lr': 0.0014379439714802573, 'lamda': 0.040198903433266577, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:52,893]\u001b[0m Finished trial#96 with value: 0.626 with parameters: {'lr': 0.0039650862931764575, 'lamda': 0.026101292349932574, 'k': 4, 'epoch': 10, 'decay': 5}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:53,086]\u001b[0m Finished trial#97 with value: 0.6295000000000001 with parameters: {'lr': 0.0014473335489520317, 'lamda': 0.022684618368199475, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:53,276]\u001b[0m Finished trial#98 with value: 0.629 with parameters: {'lr': 0.0014731682342166152, 'lamda': 0.02342755565473469, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:53,473]\u001b[0m Finished trial#99 with value: 0.6095 with parameters: {'lr': 0.0029764559928711267, 'lamda': 0.039934148759764365, 'k': 8, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:53,654]\u001b[0m Finished trial#100 with value: 0.6255 with parameters: {'lr': 0.0008787475493045931, 'lamda': 0.022696929595509802, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:53,842]\u001b[0m Finished trial#101 with value: 0.6285 with parameters: {'lr': 0.0015763229061241141, 'lamda': 0.029920652769600698, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:54,045]\u001b[0m Finished trial#102 with value: 0.6295000000000001 with parameters: {'lr': 0.0014428267418908325, 'lamda': 0.026111536192850702, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:54,232]\u001b[0m Finished trial#103 with value: 0.625 with parameters: {'lr': 0.0023176510910136072, 'lamda': 0.025936341476076163, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:54,429]\u001b[0m Finished trial#104 with value: 0.6285000000000001 with parameters: {'lr': 0.0016961933928158258, 'lamda': 0.03437718028383601, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:54,609]\u001b[0m Finished trial#105 with value: 0.629 with parameters: {'lr': 0.001417831471632007, 'lamda': 0.0235164193354978, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:54,809]\u001b[0m Finished trial#106 with value: 0.609 with parameters: {'lr': 0.0009694894959501743, 'lamda': 0.055090079740158046, 'k': 10, 'epoch': 11, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:54,997]\u001b[0m Finished trial#107 with value: 0.6275 with parameters: {'lr': 0.001309474297048215, 'lamda': 0.02242999619439056, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:55,177]\u001b[0m Finished trial#108 with value: 0.6265000000000001 with parameters: {'lr': 0.0048746544615924986, 'lamda': 0.020026525109437136, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:55,369]\u001b[0m Finished trial#109 with value: 0.6255 with parameters: {'lr': 0.0031563870871068626, 'lamda': 0.019073476942778552, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:55,564]\u001b[0m Finished trial#110 with value: 0.6255000000000001 with parameters: {'lr': 0.0021123301767426625, 'lamda': 0.0644690681706726, 'k': 4, 'epoch': 11, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:55,754]\u001b[0m Finished trial#111 with value: 0.627 with parameters: {'lr': 0.001772744169653368, 'lamda': 0.02888013756315386, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:55,941]\u001b[0m Finished trial#112 with value: 0.629 with parameters: {'lr': 0.0013772401509334266, 'lamda': 0.03192196211466835, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:56,135]\u001b[0m Finished trial#113 with value: 0.6245 with parameters: {'lr': 0.0007034545890483746, 'lamda': 0.024529139101697035, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:56,321]\u001b[0m Finished trial#114 with value: 0.629 with parameters: {'lr': 0.0014590084440181368, 'lamda': 0.02377435355537812, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:56,519]\u001b[0m Finished trial#115 with value: 0.6275000000000001 with parameters: {'lr': 0.0010839660087669724, 'lamda': 0.031400101898270506, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:56,704]\u001b[0m Finished trial#116 with value: 0.625 with parameters: {'lr': 0.0009430757825354616, 'lamda': 0.03336259809149146, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:56,888]\u001b[0m Finished trial#117 with value: 0.6265 with parameters: {'lr': 0.002416557120689594, 'lamda': 0.041157343273977715, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:57,082]\u001b[0m Finished trial#118 with value: 0.627 with parameters: {'lr': 0.0018435140818382502, 'lamda': 0.020552980979700763, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:57,269]\u001b[0m Finished trial#119 with value: 0.6155 with parameters: {'lr': 0.0013743479998238094, 'lamda': 0.04546264687356348, 'k': 5, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:57,479]\u001b[0m Finished trial#120 with value: 0.6255000000000001 with parameters: {'lr': 0.0008293248174425618, 'lamda': 0.027954986453345237, 'k': 4, 'epoch': 13, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:57,719]\u001b[0m Finished trial#121 with value: 0.6285000000000001 with parameters: {'lr': 0.0011178188133482815, 'lamda': 0.026054663609497937, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:57,909]\u001b[0m Finished trial#122 with value: 0.6295000000000001 with parameters: {'lr': 0.0014339384156363505, 'lamda': 0.024072750835108275, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:58,101]\u001b[0m Finished trial#123 with value: 0.625 with parameters: {'lr': 0.002064807056872814, 'lamda': 0.02393427137517897, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:58,285]\u001b[0m Finished trial#124 with value: 0.6285 with parameters: {'lr': 0.0014909670532947126, 'lamda': 0.02263379094914623, 'k': 4, 'epoch': 10, 'decay': 5}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:58,494]\u001b[0m Finished trial#125 with value: 0.6244999999999999 with parameters: {'lr': 0.0007532362968733046, 'lamda': 0.017860548788725245, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:58,709]\u001b[0m Finished trial#126 with value: 0.6275 with parameters: {'lr': 0.002822495917357463, 'lamda': 0.03680665902178208, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:58,903]\u001b[0m Finished trial#127 with value: 0.6285000000000001 with parameters: {'lr': 0.0016834528200769762, 'lamda': 0.025654476906777402, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:59,094]\u001b[0m Finished trial#128 with value: 0.6295000000000001 with parameters: {'lr': 0.0013827632952455916, 'lamda': 0.05074006355176755, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:59,275]\u001b[0m Finished trial#129 with value: 0.629 with parameters: {'lr': 0.0013879859219650755, 'lamda': 0.030224898830149546, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:59,468]\u001b[0m Finished trial#130 with value: 0.629 with parameters: {'lr': 0.0011444413619803814, 'lamda': 0.051110052250627105, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:59,652]\u001b[0m Finished trial#131 with value: 0.627 with parameters: {'lr': 0.0019786020583110356, 'lamda': 0.04905860672078854, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:47:59,849]\u001b[0m Finished trial#132 with value: 0.6265000000000001 with parameters: {'lr': 0.0010056362652657133, 'lamda': 0.06530781958961648, 'k': 4, 'epoch': 11, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:00,037]\u001b[0m Finished trial#133 with value: 0.6265 with parameters: {'lr': 0.002424095191025439, 'lamda': 0.021317491720231056, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:00,236]\u001b[0m Finished trial#134 with value: 0.629 with parameters: {'lr': 0.0014243235672411405, 'lamda': 0.03606327727795598, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:00,428]\u001b[0m Finished trial#135 with value: 0.6115 with parameters: {'lr': 0.0017667993600885147, 'lamda': 0.045018391138688434, 'k': 8, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:00,621]\u001b[0m Finished trial#136 with value: 0.6265 with parameters: {'lr': 0.0005546551388959409, 'lamda': 0.02969428540259687, 'k': 4, 'epoch': 12, 'decay': 5}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:00,833]\u001b[0m Finished trial#137 with value: 0.629 with parameters: {'lr': 0.0011951461329275529, 'lamda': 0.05018286631790988, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:01,026]\u001b[0m Finished trial#138 with value: 0.609 with parameters: {'lr': 0.0008405283571561133, 'lamda': 0.028710324996610342, 'k': 10, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:01,263]\u001b[0m Finished trial#139 with value: 0.6285000000000001 with parameters: {'lr': 0.0011774554029793894, 'lamda': 0.05427415521687549, 'k': 4, 'epoch': 20, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:01,450]\u001b[0m Finished trial#140 with value: 0.6255000000000001 with parameters: {'lr': 0.002174689153428529, 'lamda': 0.0242147194328381, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:01,634]\u001b[0m Finished trial#141 with value: 0.628 with parameters: {'lr': 0.001264201565304103, 'lamda': 0.03192709714203876, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:01,833]\u001b[0m Finished trial#142 with value: 0.629 with parameters: {'lr': 0.0016426515864396973, 'lamda': 0.011133629823477743, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:02,029]\u001b[0m Finished trial#143 with value: 0.6285000000000001 with parameters: {'lr': 0.0017018947799984012, 'lamda': 0.01074119185412677, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:02,224]\u001b[0m Finished trial#144 with value: 0.628 with parameters: {'lr': 0.0026918506893574105, 'lamda': 0.04190831070004954, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:02,414]\u001b[0m Finished trial#145 with value: 0.6265000000000001 with parameters: {'lr': 0.000996254224457342, 'lamda': 0.019651064561364635, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:02,598]\u001b[0m Finished trial#146 with value: 0.6295000000000001 with parameters: {'lr': 0.0014424578734684044, 'lamda': 0.08262894121803543, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:02,781]\u001b[0m Finished trial#147 with value: 0.6245 with parameters: {'lr': 0.0007207315563976014, 'lamda': 0.021858400285062838, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:02,996]\u001b[0m Finished trial#148 with value: 0.6265 with parameters: {'lr': 0.0010426326250795248, 'lamda': 0.09008400119608981, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:03,184]\u001b[0m Finished trial#149 with value: 0.629 with parameters: {'lr': 0.0013526483849144678, 'lamda': 0.03437673754781706, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:03,383]\u001b[0m Finished trial#150 with value: 0.6255 with parameters: {'lr': 0.0008586284849542127, 'lamda': 0.060796676349162165, 'k': 4, 'epoch': 13, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:03,588]\u001b[0m Finished trial#151 with value: 0.627 with parameters: {'lr': 0.0019851356394207614, 'lamda': 0.03882811873264756, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:03,777]\u001b[0m Finished trial#152 with value: 0.6285 with parameters: {'lr': 0.0012250862511285787, 'lamda': 0.07842371107576437, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:03,971]\u001b[0m Finished trial#153 with value: 0.629 with parameters: {'lr': 0.00147367670996039, 'lamda': 0.09639401963470204, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:04,163]\u001b[0m Finished trial#154 with value: 0.629 with parameters: {'lr': 0.0013769307615072355, 'lamda': 0.08084055268058706, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:04,349]\u001b[0m Finished trial#155 with value: 0.625 with parameters: {'lr': 0.0020981651618445355, 'lamda': 0.11184371371689561, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:04,553]\u001b[0m Finished trial#156 with value: 0.62 with parameters: {'lr': 0.0033038047116007445, 'lamda': 0.06609530944217464, 'k': 5, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:04,745]\u001b[0m Finished trial#157 with value: 0.629 with parameters: {'lr': 0.0015293644429416123, 'lamda': 0.09185034537260452, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:04,945]\u001b[0m Finished trial#158 with value: 0.626 with parameters: {'lr': 0.001828852290597517, 'lamda': 0.09724044147380602, 'k': 4, 'epoch': 12, 'decay': 5}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:05,175]\u001b[0m Finished trial#159 with value: 0.6255 with parameters: {'lr': 0.0009542689425627293, 'lamda': 0.027723268577274262, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:05,370]\u001b[0m Finished trial#160 with value: 0.627 with parameters: {'lr': 0.0024348179506107448, 'lamda': 0.03307489524991219, 'k': 4, 'epoch': 10, 'decay': 8}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:05,557]\u001b[0m Finished trial#161 with value: 0.6275 with parameters: {'lr': 0.0013057340254211483, 'lamda': 0.03639097765945982, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:05,740]\u001b[0m Finished trial#162 with value: 0.6285000000000001 with parameters: {'lr': 0.00113572715150102, 'lamda': 0.025832048724190322, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:05,931]\u001b[0m Finished trial#163 with value: 0.6275000000000001 with parameters: {'lr': 0.0010719689591307667, 'lamda': 0.05778162998187315, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:06,145]\u001b[0m Finished trial#164 with value: 0.628 with parameters: {'lr': 0.0012462141310557332, 'lamda': 0.043436324933873526, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:06,337]\u001b[0m Finished trial#165 with value: 0.629 with parameters: {'lr': 0.0014865954717212793, 'lamda': 0.04853148050004528, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:06,540]\u001b[0m Finished trial#166 with value: 0.626 with parameters: {'lr': 0.0017536729296244939, 'lamda': 0.023798514486948676, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:06,737]\u001b[0m Finished trial#167 with value: 0.629 with parameters: {'lr': 0.0015325100239350728, 'lamda': 0.05060232702555365, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:06,923]\u001b[0m Finished trial#168 with value: 0.6285 with parameters: {'lr': 0.0015762593314622856, 'lamda': 0.10752048775574281, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:07,111]\u001b[0m Finished trial#169 with value: 0.626 with parameters: {'lr': 0.0006573939720584876, 'lamda': 0.011414113019644253, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:07,339]\u001b[0m Finished trial#170 with value: 0.613 with parameters: {'lr': 0.000886039749767332, 'lamda': 0.030033872409725968, 'k': 8, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:07,540]\u001b[0m Finished trial#171 with value: 0.6295 with parameters: {'lr': 0.0013565407048128776, 'lamda': 0.08281329637461685, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:07,732]\u001b[0m Finished trial#172 with value: 0.6265 with parameters: {'lr': 0.0019893624855903996, 'lamda': 0.0805694930324899, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:07,924]\u001b[0m Finished trial#173 with value: 0.6285000000000001 with parameters: {'lr': 0.001143304535118087, 'lamda': 0.05091890512180139, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:08,122]\u001b[0m Finished trial#174 with value: 0.6285000000000001 with parameters: {'lr': 0.0011273334616852464, 'lamda': 0.07124905810821662, 'k': 4, 'epoch': 12, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:08,319]\u001b[0m Finished trial#175 with value: 0.626 with parameters: {'lr': 0.0017543563430119865, 'lamda': 0.0394669287926103, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:08,508]\u001b[0m Finished trial#176 with value: 0.628 with parameters: {'lr': 0.0013149551934742776, 'lamda': 0.0469501954041829, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:08,707]\u001b[0m Finished trial#177 with value: 0.625 with parameters: {'lr': 0.0023241401051769446, 'lamda': 0.08528906742354901, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:08,896]\u001b[0m Finished trial#178 with value: 0.6285000000000001 with parameters: {'lr': 0.0016848333158451226, 'lamda': 0.05226845534751547, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:09,092]\u001b[0m Finished trial#179 with value: 0.6074999999999999 with parameters: {'lr': 0.0013025459768175787, 'lamda': 0.03496559144248357, 'k': 10, 'epoch': 10, 'decay': 8}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:09,282]\u001b[0m Finished trial#180 with value: 0.6255 with parameters: {'lr': 0.000876624616514411, 'lamda': 0.07138940179849128, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:09,496]\u001b[0m Finished trial#181 with value: 0.6265 with parameters: {'lr': 0.001966054740568263, 'lamda': 0.01076168990728445, 'k': 4, 'epoch': 12, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:09,693]\u001b[0m Finished trial#182 with value: 0.629 with parameters: {'lr': 0.0014211805508359836, 'lamda': 0.03017548531657922, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:09,878]\u001b[0m Finished trial#183 with value: 0.626 with parameters: {'lr': 0.0009774301070859075, 'lamda': 0.030624609274759844, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:10,068]\u001b[0m Finished trial#184 with value: 0.629 with parameters: {'lr': 0.0014104804922320194, 'lamda': 0.08100256656132461, 'k': 4, 'epoch': 11, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:10,257]\u001b[0m Finished trial#185 with value: 0.629 with parameters: {'lr': 0.001471402481232804, 'lamda': 0.02791131961595719, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:10,448]\u001b[0m Finished trial#186 with value: 0.6295000000000001 with parameters: {'lr': 0.0014876196506670193, 'lamda': 0.02586350687547564, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:10,644]\u001b[0m Finished trial#187 with value: 0.6285 with parameters: {'lr': 0.001585301132251829, 'lamda': 0.10201337258177258, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:10,837]\u001b[0m Finished trial#188 with value: 0.6255 with parameters: {'lr': 0.0022777319441503697, 'lamda': 0.02048022321264494, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:11,027]\u001b[0m Finished trial#189 with value: 0.627 with parameters: {'lr': 0.0018139949750330495, 'lamda': 0.08757441987735325, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:11,244]\u001b[0m Finished trial#190 with value: 0.6244999999999999 with parameters: {'lr': 0.0007855009236158334, 'lamda': 0.03263543742793729, 'k': 4, 'epoch': 19, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:11,448]\u001b[0m Finished trial#191 with value: 0.6234999999999999 with parameters: {'lr': 0.0893376181847384, 'lamda': 0.09472561746476545, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:11,644]\u001b[0m Finished trial#192 with value: 0.628 with parameters: {'lr': 0.0011074079669067735, 'lamda': 0.057369677543682635, 'k': 4, 'epoch': 11, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:11,836]\u001b[0m Finished trial#193 with value: 0.629 with parameters: {'lr': 0.0016517647910742703, 'lamda': 0.12402089616055043, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:12,031]\u001b[0m Finished trial#194 with value: 0.6275 with parameters: {'lr': 0.0012918168879148158, 'lamda': 0.10073394981383846, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:12,229]\u001b[0m Finished trial#195 with value: 0.629 with parameters: {'lr': 0.0011815296767122175, 'lamda': 0.2694788400445591, 'k': 4, 'epoch': 10, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:12,438]\u001b[0m Finished trial#196 with value: 0.626 with parameters: {'lr': 0.0010247078415337029, 'lamda': 0.024062502069684858, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:12,669]\u001b[0m Finished trial#197 with value: 0.629 with parameters: {'lr': 0.001403394654447212, 'lamda': 0.07610009436794944, 'k': 4, 'epoch': 11, 'decay': 7}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:12,868]\u001b[0m Finished trial#198 with value: 0.628 with parameters: {'lr': 0.0027162911160444653, 'lamda': 0.025781508914953687, 'k': 4, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-25 20:48:13,070]\u001b[0m Finished trial#199 with value: 0.618 with parameters: {'lr': 0.001840981591297415, 'lamda': 0.02270555862200727, 'k': 5, 'epoch': 10, 'decay': 6}. Best is trial#83 with value: 0.6295000000000001.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross_validate(X_train_mat100, y,0.001,10)\n",
    "\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective, n_trials=200,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_decay</th>\n",
       "      <th>params_epoch</th>\n",
       "      <th>params_k</th>\n",
       "      <th>params_lamda</th>\n",
       "      <th>params_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>00:00:00.235365</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0.368972</td>\n",
       "      <td>0.016493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>00:00:00.218716</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.089794</td>\n",
       "      <td>0.009743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>00:00:00.233999</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>00:00:00.191209</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.034966</td>\n",
       "      <td>0.001303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0.6085</td>\n",
       "      <td>00:00:00.202923</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.189959</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.001447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.191692</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>122</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.185681</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.204314</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>00:00:00.187417</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number   value        duration  ...  params_k  params_lamda  params_lr\n",
       "0         0  0.6045 00:00:00.235365  ...        10      0.368972   0.016493\n",
       "29       29  0.6045 00:00:00.218716  ...        10      0.089794   0.009743\n",
       "8         8  0.6065 00:00:00.233999  ...        10      0.013069   0.000233\n",
       "179     179  0.6075 00:00:00.191209  ...        10      0.034966   0.001303\n",
       "57       57  0.6085 00:00:00.202923  ...        10      0.019213   0.001156\n",
       "..      ...     ...             ...  ...       ...           ...        ...\n",
       "97       97  0.6295 00:00:00.189959  ...         4      0.022685   0.001447\n",
       "95       95  0.6295 00:00:00.191692  ...         4      0.040199   0.001438\n",
       "122     122  0.6295 00:00:00.185681  ...         4      0.024073   0.001434\n",
       "83       83  0.6295 00:00:00.204314  ...         4      0.010491   0.001443\n",
       "128     128  0.6295 00:00:00.187417  ...         4      0.050740   0.001383\n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "\n",
    "df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.623"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(X_tr,y,lamda=0.050740,epoch=10,lr=0.050740,k=4,decay=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  Loss: 0.6931471805599453\n",
      "Epoch : 1  Loss: 0.6614940106899204\n",
      "Epoch : 2  Loss: 0.6576564995558486\n",
      "Epoch : 3  Loss: 0.6530411387034815\n",
      "Epoch : 4  Loss: 0.6529215147131578\n",
      "Epoch : 5  Loss: 0.6529162816687935\n",
      "Epoch : 6  Loss: 0.6529161015244107\n",
      "Epoch : 7  Loss: 0.6529160965206913\n",
      "Epoch : 8  Loss: 0.652916096404326\n",
      "Epoch : 9  Loss: 0.6529160964019987\n",
      "0.6313432835820896\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test\n",
    "# logistic = logisticregression(X_train,y_train,lamda=0.362124,epoch=15,print_every=1,lr=0.000254)\n",
    "#\n",
    "logistic = logisticregression(X_train,y_train,lamda=0.05,epoch=10,lr=0.001383,decay=7,print_every=1)\n",
    "logistic.train()\n",
    "        \n",
    "print(logistic.evaluate(X_train,y_train))\n",
    "print(logistic.evaluate(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_mat100 = scale(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sumbission = []\n",
    "for i in range(len(X_test_mat100)):\n",
    "    result = logistic.predict(X_test_mat100[i])\n",
    "    sumbission.append([i,int(result)])\n",
    "    result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sumbission\n",
    "df = pd.DataFrame(sumbission)\n",
    "df.columns = ['Id','Bound']\n",
    "df.to_csv('test_64_cross_validated.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Bound\n",
       "0    0      1\n",
       "1    1      0\n",
       "2    2      0\n",
       "3    3      0\n",
       "4    4      0\n",
       "5    5      1\n",
       "6    6      1\n",
       "7    7      1\n",
       "8    8      1\n",
       "9    9      0\n",
       "10  10      1\n",
       "11  11      1\n",
       "12  12      0\n",
       "13  13      1\n",
       "14  14      1\n",
       "15  15      1\n",
       "16  16      1\n",
       "17  17      1\n",
       "18  18      0\n",
       "19  19      0\n",
       "20  20      1\n",
       "21  21      0\n",
       "22  22      0\n",
       "23  23      0\n",
       "24  24      1\n",
       "25  25      0\n",
       "26  26      0\n",
       "27  27      1\n",
       "28  28      0\n",
       "29  29      1\n",
       "30  30      0\n",
       "31  31      1\n",
       "32  32      0\n",
       "33  33      0\n",
       "34  34      1\n",
       "35  35      1\n",
       "36  36      1\n",
       "37  37      1\n",
       "38  38      0\n",
       "39  39      0\n",
       "40  40      0\n",
       "41  41      1\n",
       "42  42      0\n",
       "43  43      1\n",
       "44  44      1\n",
       "45  45      0\n",
       "46  46      0\n",
       "47  47      0\n",
       "48  48      1\n",
       "49  49      1"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5787878787878787"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# linear, poly, rbf, sigmoid, precomputed\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='poly'))\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5545454545454546"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty = 'l2')\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

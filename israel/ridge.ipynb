{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import optuna\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = pd.read_csv('../data/Xte.csv',sep=',',index_col=0)\n",
    "X_train = pd.read_csv('../data/Xtr.csv',sep=',',index_col=0)\n",
    "\n",
    "y = pd.read_csv('../data/Ytr.csv',sep=',',index_col=0)\n",
    "y['Bound'] = y.Bound.apply(lambda x: -1 if x == 0 else 1)\n",
    "y=y.values\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKmers(sequence, size):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]\n",
    "\n",
    "def compare(beta1, beta2):\n",
    "    print('''\n",
    "Difference between the two:\n",
    "{}\n",
    "        '''.format(np.sum((beta1-beta2)**2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-96e73b7380d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mX_later\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_later\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# breakS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "n = 6\n",
    "\n",
    "\n",
    "X_te = []\n",
    "X = []\n",
    "cv = CountVectorizer()\n",
    "for i in X_train:\n",
    "    sentence = ' '.join(getKmers(i[0], size=n))\n",
    "    X.append(sentence)\n",
    "    \n",
    "for i in X_test:\n",
    "    sentence = ' '.join(getKmers(i[0], size=n))\n",
    "    X_te.append(sentence)\n",
    "\n",
    "    \n",
    "X_later = X+X_te\n",
    "X = cv.fit_transform(X_later).toarray()\n",
    "# breakS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:15,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (2000, 150) y_train (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train: {} y_train {}'.format(X[:2000,:].shape,y.shape))\n",
    "\n",
    "# print('x_train: {} y_train {}'.format(X_train.shape,y.shape))\n",
    "# print('x_test: {}'.format(X_te.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 150) (600, 150) (1400, 1) (600, 1) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_tr= scale(X[:2000,:])\n",
    "X_te = scale(X[2000:,:])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tr, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape,X_val.shape,y_train.shape, y_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression (RR)\n",
    "def solveRR(y, X, lam):\n",
    "    n, p = X.shape\n",
    "    assert (len(y) == n)\n",
    "    \n",
    "    A = X.T.dot(X)\n",
    "    # Adjust diagonal due to Ridge\n",
    "    A[np.diag_indices_from(A)] += lam * n\n",
    "    b = X.T.dot(y)\n",
    "    \n",
    "    # Hint:\n",
    "    beta = np.linalg.solve(A, b)\n",
    "    # Finds solution to the linear system Ax = b\n",
    "    return (beta)\n",
    "\n",
    "# Weighted Ridge Regression (WRR)\n",
    "def solveWRR(y, X, w, lam):\n",
    "    n, p = X.shape\n",
    "    assert (len(y) == len(w) == n)\n",
    "    \n",
    "    y1 = np.sqrt(w) * y\n",
    "    X1 = (np.sqrt(w) * X.T).T\n",
    "    # Hint:\n",
    "    # Find y1 and X1 such that:\n",
    "    beta = solveRR(y1, X1, lam)\n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = 10\n",
    "\n",
    "w = np.random.rand(len(y_train))\n",
    "# Our solver\n",
    "beta1 = solveWRR(y_train, X_train,w, lam)\n",
    "\n",
    "# Python solver\n",
    "alpha = lam * X_train.shape[0]\n",
    "model = lm.Ridge(alpha=alpha, fit_intercept=False, normalize=False)\n",
    "beta2 = model.fit(X_train,y_train).coef_\n",
    "\n",
    "# Check\n",
    "# compare(beta1, beta2)\n",
    "beta2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression (RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveRR(y, X, lam):\n",
    "    n, p = X.shape\n",
    "    assert (len(y) == n)\n",
    "    \n",
    "    A = X.T.dot(X)\n",
    "    # Adjust diagonal due to Ridge\n",
    "    A[np.diag_indices_from(A)] = np.add(A[np.diag_indices_from(A)], lam * n)\n",
    "    b = X.T.dot(y)\n",
    "    \n",
    "    # Hint:\n",
    "    beta = np.linalg.solve(A, b)\n",
    "    # Finds solution to the linear system Ax = b\n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validate(x_data,y_data,lr,lamda=0.2,epoch=10,k=5,decay=10):\n",
    "#     if len(x_data)%k != 0:\n",
    "#         print('cant vsplit',len(x_data),' by ',k)\n",
    "#         return\n",
    "    \n",
    "#     x_data_splitted = np.vsplit(x_data,k)\n",
    "#     y_data_splitted = np.vsplit(y_data,k)\n",
    "    \n",
    "#     aggrigate_result = []\n",
    "#     for i in range(len(x_data_splitted)):\n",
    "#         train = []\n",
    "#         test = []\n",
    "#         items = [j for j in range(len(x_data_splitted)) if j !=i ]\n",
    "#         x_test = x_data_splitted[i]\n",
    "#         y_test = y_data_splitted[i]\n",
    "#         for item in items:\n",
    "#             if len(train) == 0:\n",
    "#                 x_train = x_data_splitted[item]\n",
    "#                 y_train = y_data_splitted[item]\n",
    "#             else:\n",
    "#                 x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n",
    "#                 y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n",
    "            \n",
    "#         logistic = logisticregression(x_train,y_train,lamda=lamda,lr=lr,decay=decay,epoch=epoch)\n",
    "#         logistic.train()\n",
    "        \n",
    "#         result = logistic.evaluate(x_test,y_test)\n",
    "#         aggrigate_result.append(result)\n",
    "        \n",
    "#         value = sum(aggrigate_result)/len(aggrigate_result)\n",
    "#     return value if value!= None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(X_tr, y,lam,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lam = trial.suggest_loguniform('lamda', 0.01, 5)\n",
    "\n",
    "    # Our solver\n",
    "    beta1 = solveRR(y_train, X_train, lam)\n",
    "\n",
    "    # Python solver\n",
    "    alpha = lam *  X_train.shape[0]\n",
    "    model = lm.Ridge(alpha=alpha, fit_intercept=False, normalize=False)\n",
    "    beta2 = model.fit(X_train,y_train).coef_\n",
    "    \n",
    "    valid_acc = sum(np.sign(np.dot(X_val,beta1))==y_val)/len(y_val)\n",
    "    train_acc = sum(np.sign(np.dot(X_train,beta1))==y_train)/len(y_train)\n",
    "    \n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-26 15:32:34,490]\u001b[0m Finished trial#0 with value: 0.6066666666666667 with parameters: {'lamda': 0.5256211664635327}. Best is trial#0 with value: 0.6066666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:34,606]\u001b[0m Finished trial#1 with value: 0.6133333333333333 with parameters: {'lamda': 0.1260265087281257}. Best is trial#1 with value: 0.6133333333333333.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:34,704]\u001b[0m Finished trial#2 with value: 0.6216666666666667 with parameters: {'lamda': 0.033431459825172954}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:34,807]\u001b[0m Finished trial#3 with value: 0.6016666666666667 with parameters: {'lamda': 1.5297769496966853}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:34,914]\u001b[0m Finished trial#4 with value: 0.605 with parameters: {'lamda': 0.7766828789687985}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,050]\u001b[0m Finished trial#5 with value: 0.6033333333333334 with parameters: {'lamda': 0.374354481602087}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,156]\u001b[0m Finished trial#6 with value: 0.6183333333333333 with parameters: {'lamda': 0.08343876316576891}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,251]\u001b[0m Finished trial#7 with value: 0.6166666666666667 with parameters: {'lamda': 0.06329162801228407}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,366]\u001b[0m Finished trial#8 with value: 0.605 with parameters: {'lamda': 0.36009245442489}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,472]\u001b[0m Finished trial#9 with value: 0.6083333333333333 with parameters: {'lamda': 0.2806443760293978}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,577]\u001b[0m Finished trial#10 with value: 0.6183333333333333 with parameters: {'lamda': 0.010295355924813001}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,686]\u001b[0m Finished trial#11 with value: 0.6216666666666667 with parameters: {'lamda': 0.02656298422257467}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,792]\u001b[0m Finished trial#12 with value: 0.6183333333333333 with parameters: {'lamda': 0.014162207408493634}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:35,900]\u001b[0m Finished trial#13 with value: 0.62 with parameters: {'lamda': 0.02773665393792584}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,003]\u001b[0m Finished trial#14 with value: 0.6216666666666667 with parameters: {'lamda': 0.025128152701748636}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,115]\u001b[0m Finished trial#15 with value: 0.6216666666666667 with parameters: {'lamda': 0.032733071696386874}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,210]\u001b[0m Finished trial#16 with value: 0.62 with parameters: {'lamda': 0.046424613914201586}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,326]\u001b[0m Finished trial#17 with value: 0.6183333333333333 with parameters: {'lamda': 0.013651171787119689}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,430]\u001b[0m Finished trial#18 with value: 0.615 with parameters: {'lamda': 0.1652381177074154}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,545]\u001b[0m Finished trial#19 with value: 0.62 with parameters: {'lamda': 0.04549689038054344}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,651]\u001b[0m Finished trial#20 with value: 0.6133333333333333 with parameters: {'lamda': 0.11324053092338078}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,758]\u001b[0m Finished trial#21 with value: 0.6216666666666667 with parameters: {'lamda': 0.021287080028236195}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,861]\u001b[0m Finished trial#22 with value: 0.62 with parameters: {'lamda': 0.016036801598333643}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:36,955]\u001b[0m Finished trial#23 with value: 0.62 with parameters: {'lamda': 0.027741496613263104}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,063]\u001b[0m Finished trial#24 with value: 0.62 with parameters: {'lamda': 0.019625723514925718}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,194]\u001b[0m Finished trial#25 with value: 0.595 with parameters: {'lamda': 4.595150319340593}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,308]\u001b[0m Finished trial#26 with value: 0.6183333333333333 with parameters: {'lamda': 0.041849825098607185}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,409]\u001b[0m Finished trial#27 with value: 0.6183333333333333 with parameters: {'lamda': 0.010521339697231524}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,526]\u001b[0m Finished trial#28 with value: 0.6183333333333333 with parameters: {'lamda': 0.0727958907416015}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,622]\u001b[0m Finished trial#29 with value: 0.6216666666666667 with parameters: {'lamda': 0.022072434591901842}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,720]\u001b[0m Finished trial#30 with value: 0.6183333333333333 with parameters: {'lamda': 0.010433772323648631}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,819]\u001b[0m Finished trial#31 with value: 0.62 with parameters: {'lamda': 0.03600708975340233}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:37,917]\u001b[0m Finished trial#32 with value: 0.6216666666666667 with parameters: {'lamda': 0.021765729514682426}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,022]\u001b[0m Finished trial#33 with value: 0.62 with parameters: {'lamda': 0.018184939248718238}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,114]\u001b[0m Finished trial#34 with value: 0.6166666666666667 with parameters: {'lamda': 0.05866495744320503}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,224]\u001b[0m Finished trial#35 with value: 0.6133333333333333 with parameters: {'lamda': 0.10721428799576467}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,338]\u001b[0m Finished trial#36 with value: 0.6 with parameters: {'lamda': 0.8678433738070048}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,446]\u001b[0m Finished trial#37 with value: 0.62 with parameters: {'lamda': 0.030028943712402136}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,569]\u001b[0m Finished trial#38 with value: 0.62 with parameters: {'lamda': 0.01907263054813992}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,667]\u001b[0m Finished trial#39 with value: 0.6183333333333333 with parameters: {'lamda': 0.012244227193796082}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,765]\u001b[0m Finished trial#40 with value: 0.6116666666666667 with parameters: {'lamda': 0.20747223033000475}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,854]\u001b[0m Finished trial#41 with value: 0.6216666666666667 with parameters: {'lamda': 0.022224902949371173}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:38,952]\u001b[0m Finished trial#42 with value: 0.6216666666666667 with parameters: {'lamda': 0.02228623926094589}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:39,047]\u001b[0m Finished trial#43 with value: 0.6166666666666667 with parameters: {'lamda': 0.05855740824629787}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:39,140]\u001b[0m Finished trial#44 with value: 0.6183333333333333 with parameters: {'lamda': 0.014949733077037229}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:39,239]\u001b[0m Finished trial#45 with value: 0.6183333333333333 with parameters: {'lamda': 0.08789752277021602}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:39,333]\u001b[0m Finished trial#46 with value: 0.6183333333333333 with parameters: {'lamda': 0.04213577900999889}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:39,446]\u001b[0m Finished trial#47 with value: 0.62 with parameters: {'lamda': 0.023164175681504223}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:39,546]\u001b[0m Finished trial#48 with value: 0.6216666666666667 with parameters: {'lamda': 0.03498321619482169}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n",
      "\u001b[32m[I 2020-05-26 15:32:39,640]\u001b[0m Finished trial#49 with value: 0.6183333333333333 with parameters: {'lamda': 0.05410832891224172}. Best is trial#2 with value: 0.6216666666666667.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import optuna\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective, n_trials=50,show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_lamda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>00:00:00.129606</td>\n",
       "      <td>4.595150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>00:00:00.112667</td>\n",
       "      <td>0.867843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.601667</td>\n",
       "      <td>00:00:00.099266</td>\n",
       "      <td>1.529777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>00:00:00.132510</td>\n",
       "      <td>0.374354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>00:00:00.113079</td>\n",
       "      <td>0.360092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>00:00:00.101604</td>\n",
       "      <td>0.776683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>00:00:00.125164</td>\n",
       "      <td>0.525621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>00:00:00.104613</td>\n",
       "      <td>0.280644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.611667</td>\n",
       "      <td>00:00:00.097310</td>\n",
       "      <td>0.207472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>00:00:00.108289</td>\n",
       "      <td>0.107214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>00:00:00.104504</td>\n",
       "      <td>0.113241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>00:00:00.112056</td>\n",
       "      <td>0.126027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>00:00:00.102564</td>\n",
       "      <td>0.165238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>00:00:00.090473</td>\n",
       "      <td>0.058665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>00:00:00.094018</td>\n",
       "      <td>0.063292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>00:00:00.093708</td>\n",
       "      <td>0.058557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.097621</td>\n",
       "      <td>0.087898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.112687</td>\n",
       "      <td>0.041850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.096997</td>\n",
       "      <td>0.010434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.092012</td>\n",
       "      <td>0.014950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.115578</td>\n",
       "      <td>0.072796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.092463</td>\n",
       "      <td>0.042136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.099776</td>\n",
       "      <td>0.010521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.096770</td>\n",
       "      <td>0.012244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.093337</td>\n",
       "      <td>0.054108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.104576</td>\n",
       "      <td>0.083439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.103858</td>\n",
       "      <td>0.010295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.105077</td>\n",
       "      <td>0.014162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.618333</td>\n",
       "      <td>00:00:00.115090</td>\n",
       "      <td>0.013651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.092266</td>\n",
       "      <td>0.027741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.112417</td>\n",
       "      <td>0.023164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.106413</td>\n",
       "      <td>0.027737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.121115</td>\n",
       "      <td>0.019073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.092984</td>\n",
       "      <td>0.046425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.106731</td>\n",
       "      <td>0.030029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.097628</td>\n",
       "      <td>0.036007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.111830</td>\n",
       "      <td>0.045497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.101086</td>\n",
       "      <td>0.016037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.103891</td>\n",
       "      <td>0.018185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>00:00:00.107182</td>\n",
       "      <td>0.019626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.111238</td>\n",
       "      <td>0.032733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.101259</td>\n",
       "      <td>0.025128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.097743</td>\n",
       "      <td>0.034983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.096763</td>\n",
       "      <td>0.021766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.094604</td>\n",
       "      <td>0.022072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.087562</td>\n",
       "      <td>0.022225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.096052</td>\n",
       "      <td>0.022286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.107243</td>\n",
       "      <td>0.026563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.106038</td>\n",
       "      <td>0.021287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>00:00:00.094432</td>\n",
       "      <td>0.033431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value        duration  params_lamda\n",
       "25      25  0.595000 00:00:00.129606      4.595150\n",
       "36      36  0.600000 00:00:00.112667      0.867843\n",
       "3        3  0.601667 00:00:00.099266      1.529777\n",
       "5        5  0.603333 00:00:00.132510      0.374354\n",
       "8        8  0.605000 00:00:00.113079      0.360092\n",
       "4        4  0.605000 00:00:00.101604      0.776683\n",
       "0        0  0.606667 00:00:00.125164      0.525621\n",
       "9        9  0.608333 00:00:00.104613      0.280644\n",
       "40      40  0.611667 00:00:00.097310      0.207472\n",
       "35      35  0.613333 00:00:00.108289      0.107214\n",
       "20      20  0.613333 00:00:00.104504      0.113241\n",
       "1        1  0.613333 00:00:00.112056      0.126027\n",
       "18      18  0.615000 00:00:00.102564      0.165238\n",
       "34      34  0.616667 00:00:00.090473      0.058665\n",
       "7        7  0.616667 00:00:00.094018      0.063292\n",
       "43      43  0.616667 00:00:00.093708      0.058557\n",
       "45      45  0.618333 00:00:00.097621      0.087898\n",
       "26      26  0.618333 00:00:00.112687      0.041850\n",
       "30      30  0.618333 00:00:00.096997      0.010434\n",
       "44      44  0.618333 00:00:00.092012      0.014950\n",
       "28      28  0.618333 00:00:00.115578      0.072796\n",
       "46      46  0.618333 00:00:00.092463      0.042136\n",
       "27      27  0.618333 00:00:00.099776      0.010521\n",
       "39      39  0.618333 00:00:00.096770      0.012244\n",
       "49      49  0.618333 00:00:00.093337      0.054108\n",
       "6        6  0.618333 00:00:00.104576      0.083439\n",
       "10      10  0.618333 00:00:00.103858      0.010295\n",
       "12      12  0.618333 00:00:00.105077      0.014162\n",
       "17      17  0.618333 00:00:00.115090      0.013651\n",
       "23      23  0.620000 00:00:00.092266      0.027741\n",
       "47      47  0.620000 00:00:00.112417      0.023164\n",
       "13      13  0.620000 00:00:00.106413      0.027737\n",
       "38      38  0.620000 00:00:00.121115      0.019073\n",
       "16      16  0.620000 00:00:00.092984      0.046425\n",
       "37      37  0.620000 00:00:00.106731      0.030029\n",
       "31      31  0.620000 00:00:00.097628      0.036007\n",
       "19      19  0.620000 00:00:00.111830      0.045497\n",
       "22      22  0.620000 00:00:00.101086      0.016037\n",
       "33      33  0.620000 00:00:00.103891      0.018185\n",
       "24      24  0.620000 00:00:00.107182      0.019626\n",
       "15      15  0.621667 00:00:00.111238      0.032733\n",
       "14      14  0.621667 00:00:00.101259      0.025128\n",
       "48      48  0.621667 00:00:00.097743      0.034983\n",
       "32      32  0.621667 00:00:00.096763      0.021766\n",
       "29      29  0.621667 00:00:00.094604      0.022072\n",
       "41      41  0.621667 00:00:00.087562      0.022225\n",
       "42      42  0.621667 00:00:00.096052      0.022286\n",
       "11      11  0.621667 00:00:00.107243      0.026563\n",
       "21      21  0.621667 00:00:00.106038      0.021287\n",
       "2        2  0.621667 00:00:00.094432      0.033431"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "\n",
    "df.sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-71a3adeb72f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolveRR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.962821\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-32b0083fa5d2>\u001b[0m in \u001b[0;36msolveRR\u001b[0;34m(y, X, lam)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Adjust diagonal due to Ridge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_indices_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "beta1 = solveRR(y_train, X_train, 4.962821)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544444444444444"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sign(np.dot(X_train,beta1))==y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sign(np.dot(X_val,beta1))==y_val)/len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = []\n",
    "\n",
    "for i in range(len(X_te)):\n",
    "    result = np.sign(np.dot(X_te[i],beta1))\n",
    "    if result == 1:\n",
    "        sol.append([i,1])\n",
    "    else:\n",
    "        sol.append([i,0])\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Bound\n",
       "0   0      1\n",
       "1   1      1\n",
       "2   2      0\n",
       "3   3      0\n",
       "4   4      1"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(sol)\n",
    "d.columns = ['Id','Bound']\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('test_65_rr_solver.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def polynomial_kernel(x, y, p=2):\n",
    "#     return (1 + np.dot(x, y)) ** p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def solveRR(y, X, lam):\n",
    "#     n, p = X.shape\n",
    "#     assert (len(y) == n)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     A = X.T.dot(X)\n",
    "#     # Adjust diagonal due to Ridge\n",
    "#     A[np.diag_indices_from(A)] += lam * n\n",
    "#     b = X.T.dot(y)\n",
    "    \n",
    "#     # Hint:\n",
    "#     beta = np.linalg.solve(A, b)\n",
    "#     # Finds solution to the linear system Ax = b\n",
    "#     return (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta1 = solveRR(y_train, X_train, 2)\n",
    "# beta1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     lam = trial.suggest_loguniform('lam', 0.01, 5)\n",
    "\n",
    "#     # Our solver\n",
    "#     beta1 = solveRR(y_train, X_train, lam)\n",
    "\n",
    "#     # Python solver\n",
    "#     alpha = lam *  X_train.shape[0]\n",
    "#     model = lm.Ridge(alpha=alpha, fit_intercept=False, normalize=False)\n",
    "#     beta2 = model.fit(X_train,y_train).coef_\n",
    "    \n",
    "#     valid_acc = sum(np.sign(np.dot(X_val,beta1))==y_val)/len(y_val)\n",
    "#     train_acc = sum(np.sign(np.dot(X_train,beta1))==y_train)/len(y_train)\n",
    "    \n",
    "#     return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import optuna\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler()\n",
    "# study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# study.optimize(func=objective, n_trials=50,show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Ridge Regression (WRR)\n",
    "def solveWRR(y, X, w, lam):\n",
    "    n, p = X.shape\n",
    "    assert (len(y) == len(w) == n)\n",
    "    \n",
    "    y1 = np.sqrt(w) * y\n",
    "    X1 = (np.sqrt(w) * X.T).T\n",
    "    # Hint:\n",
    "    # Find y1 and X1 such that:\n",
    "    beta = solveRR(y1, X1, lam)\n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4096, 1800), (1, 4096))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = 0.1\n",
    "w = np.random.rand(len(y_train))\n",
    "\n",
    "# Our solver\n",
    "beta1 = solveWRR(y_train, X_train, w, lam)\n",
    "\n",
    "# Python solver\n",
    "alpha = lam * X_train.shape[0]\n",
    "model = lm.Ridge(alpha=alpha, fit_intercept=False, normalize=False)\n",
    "beta2 = model.fit(X_train, y_train, sample_weight=w).coef_\n",
    "\n",
    "# Check\n",
    "# compare(beta1, beta2)\n",
    "beta1.shape,beta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

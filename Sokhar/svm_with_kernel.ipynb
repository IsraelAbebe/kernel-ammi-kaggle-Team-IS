{"cells":[{"metadata":{},"cell_type":"markdown","source":"Principal Files\nThis data challenge contains one dataset of 2000 training sequences. The main files available are the following ones\n\n* Xtr.csv - the training sequences.\n* \n* Xte.csv - the test sequences.\n* \n* Ytr.csv - the sequence labels of the training sequences indicating bound (1) or not (0).\n* \nEach row of Xtr.csv represents a sequence. Xte.csv contains 1000 test sequences, for which you need to predict. Ytr.csv contains the labels corresponding to the training data, in the same format as a submission file."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nfrom sklearn.preprocessing import OneHotEncoder\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nimport optuna\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score, precision_score\n\nimport os\n","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/kernel-methods-ammi-2020/Xtr_mat100.csv\n/kaggle/input/kernel-methods-ammi-2020/Xte.csv\n/kaggle/input/kernel-methods-ammi-2020/Xte_mat100.csv\n/kaggle/input/kernel-methods-ammi-2020/Ytr.csv\n/kaggle/input/kernel-methods-ammi-2020/Xtr.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data=pd.read_csv(\"/kaggle/input/kernel-methods-ammi-2020/Xtr.csv\", sep=' ',index_col=0).values\n\nlabels=pd.read_csv(\"/kaggle/input/kernel-methods-ammi-2020/Ytr.csv\", sep=',',index_col=0).values\n\n\ntest_data=pd.read_csv(\"/kaggle/input/kernel-methods-ammi-2020/Xte.csv\",sep=' ', index_col=0).values\n\n\n#optional data \n\ntrain_op_data=pd.read_csv(\"/kaggle/input/kernel-methods-ammi-2020/Xtr_mat100.csv\", sep=' ',header=None).values\ntest_op_data=pd.read_csv(\"/kaggle/input/kernel-methods-ammi-2020/Xte_mat100.csv\", sep=' ',header=None).values\n\n\n\n","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Change the labels from 0,1 to -1 ,1"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels= np.where(labels==0,-1,1)\n\ntrain_op_data[:5,:5]","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"array([[0.01086957, 0.01086957, 0.01086957, 0.0326087 , 0.01086957],\n       [0.        , 0.01086957, 0.02173913, 0.        , 0.02173913],\n       [0.02173913, 0.        , 0.        , 0.        , 0.04347826],\n       [0.        , 0.02173913, 0.0326087 , 0.        , 0.02173913],\n       [0.01086957, 0.04347826, 0.        , 0.0326087 , 0.01086957]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"array([[ 1],\n       [-1],\n       [ 1],\n       ...,\n       [ 1],\n       [ 1],\n       [ 1]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Data exploring"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape,test_data.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"(2000, 0) (1000, 0)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## optional data view"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_op_data.shape)","execution_count":7,"outputs":[{"output_type":"stream","text":"(2000, 100)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Split the training dataset in train and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train_mat100 = scale(train_op_data)\n# \nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_mat100, labels, test_size=0.33, random_state=42)\n\nprint(X_train.shape,X_val.shape,y_train.shape, y_val.shape)\n","execution_count":8,"outputs":[{"output_type":"stream","text":"(1340, 100) (660, 100) (1340, 1) (660, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# soft margin svm with SGD from scratch"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SVM:\n    def __init__(self, lr,lamb, epoch):\n        self.lr=lr\n        self.lamb=lamb\n        self.epoch=epoch\n    def compute_cost(self,W, X, Y):\n        # calculate hinge loss\n        N = X.shape[0]\n        \n        distances = 1 - Y * (np.dot(X, W))\n        distances[distances < 0] = 0  # equivalent to max(0, distance)\n        hinge_loss = self.lamb * (np.sum(distances) / N)\n\n        # calculate cost\n        cost = 1 / 2 * (np.dot(W, W)) + hinge_loss\n        return cost\n    \n    def calculate_cost_gradient(self,W, X_batch, Y_batch):\n        # if only one example is passed (eg. in case of SGD)\n        if type(Y_batch) == np.float64:\n            Y_batch = np.array([Y_batch])\n            X_batch = np.array([X_batch])  # gives multidimensional array\n\n        distance = 1 - (Y_batch * np.dot(X_batch, W))\n        dw = np.zeros(len(W))\n\n        for ind, d in enumerate(distance):\n            if max(0, d) == 0:\n                di = W\n            else:\n                di = W -(self.lamb* Y_batch[ind] * X_batch[ind])\n            dw += di\n\n        dw = dw/len(Y_batch)  # average\n        return dw\n    \n    def sgd(self,features, outputs):\n        \n        weights = np.zeros(features.shape[1])\n        nth = 0\n        prev_cost = float(\"inf\")\n        cost_threshold = 2  # in percent\n        # stochastic gradient descent\n        for epoch in range(1, self.epoch):\n            # shuffle to prevent repeating update cycles\n            X, Y = (features, outputs)\n            for ind, x in enumerate(X):\n                ascent = self.calculate_cost_gradient(weights, x, Y[ind])\n                weights = weights -(self.lr * ascent)\n\n\n            cost = self.compute_cost(weights, features, outputs)\n#             print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n            # stoppage criterion\n            if abs(prev_cost - cost) < cost_threshold * prev_cost:\n                return weights\n            prev_cost = cost\n            nth += 1\n        return weights\n    \n    \n    \n    def train_func(self,x_train,y_train):\n        W = self.sgd(x_train, y_train)\n#         print(\"training finished.\")\n        return W\n\n    def validation(self,x_val,y_val,w):\n        y_test_predicted = np.array([])\n        for i in range(x_val.shape[0]):\n            yp = np.sign(np.dot(w, x_val[i])) #model\n            y_test_predicted = np.append(y_test_predicted, yp)\n        return accuracy_score(y_val, y_test_predicted)\n\n","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Insert the bias"},{"metadata":{"trusted":true},"cell_type":"code","source":"def insert_intercept(train_op_data):\n    N=train_op_data.shape[0]\n   \n    a = np.ones((N,1))\n    \n    train_op_data=np.append(train_op_data,a, axis=1)\n    return train_op_data","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_op_data=insert_intercept(train_op_data)\nsvm_sgd=SVM(lr=0.1,lamb=1,epoch=10)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w=svm_sgd.train_func(X_train,y_train)\nsvm_sgd.validation(X_val,y_val,w)","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"0.5257575757575758"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef cross_validate(x_data,y_data,model,lr,lamda=0.2,epoch=10,k=5):\n    if len(x_data)%k != 0:\n        print('cant vsplit',len(x_data),' by ',k)\n        return\n    \n    x_data_splitted = np.vsplit(x_data,k)\n    y_data_splitted = np.vsplit(y_data,k)\n    \n    aggrigate_result = []\n    \n    for i in range(len(x_data_splitted)):\n        train = []\n        test = []\n        items = [j for j in range(len(x_data_splitted)) if j !=i ]\n        x_test = x_data_splitted[i]\n        y_test = y_data_splitted[i]\n        \n        for item in items:\n            if len(train) == 0:\n                x_train = x_data_splitted[item]\n                y_train = y_data_splitted[item]\n                \n                \n            else:\n                x_train = np.concatenate((x_train,x_data_splitted[item]), axis=0)\n                \n                \n                y_train = np.concatenate((y_train,y_data_splitted[item]), axis=0)\n                \n                \n       \n        w=model.train_func(x_train,y_train)\n       \n       \n        \n        result = model.validation(x_test,y_test,w)\n        aggrigate_result.append(result)\n         \n        \n        value = sum(aggrigate_result)/len(aggrigate_result)\n        \n        \n    return value ","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter search using optuna"},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial):\n    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n    lamda = trial.suggest_loguniform('lamda', 0.2, 1)\n    k =  trial.suggest_categorical('k', [4,5,8,10])\n    epoch =  trial.suggest_int('epoch', 3, 15)\n    return cross_validate(train_op_data, labels,svm_sgd,lr=lr,lamda=lamda,k=k,epoch=epoch)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\n\nsampler = optuna.samplers.TPESampler()\nstudy = optuna.create_study(sampler=sampler, direction='maximize')\nstudy.optimize(func=objective, n_trials=200,show_progress_bar=True)","execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe47b6e5999345a5a99e9105cd2f6cfb"}},"metadata":{}},{"output_type":"stream","text":"[I 2020-05-26 10:01:48,758] Finished trial#0 with value: 0.4999999999999999 with parameters: {'lr': 3.156669340679139e-05, 'lamda': 0.20278061256132357, 'k': 10, 'epoch': 14}. Best is trial#0 with value: 0.4999999999999999.\n[I 2020-05-26 10:01:49,044] Finished trial#1 with value: 0.4999999999999999 with parameters: {'lr': 0.03224239746196466, 'lamda': 0.49505289735630237, 'k': 10, 'epoch': 13}. Best is trial#0 with value: 0.4999999999999999.\n[I 2020-05-26 10:01:49,345] Finished trial#2 with value: 0.505 with parameters: {'lr': 0.002259097170901521, 'lamda': 0.20838394504806315, 'k': 4, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:49,642] Finished trial#3 with value: 0.4999999999999999 with parameters: {'lr': 3.5688339150237606e-05, 'lamda': 0.5867656348476377, 'k': 10, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:49,941] Finished trial#4 with value: 0.5 with parameters: {'lr': 0.0017176422607032866, 'lamda': 0.5096123664424019, 'k': 5, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:50,232] Finished trial#5 with value: 0.5 with parameters: {'lr': 0.0017055911248720426, 'lamda': 0.4371092526520521, 'k': 5, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:50,536] Finished trial#6 with value: 0.5 with parameters: {'lr': 0.07225108333027926, 'lamda': 0.38046895946484066, 'k': 5, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:50,839] Finished trial#7 with value: 0.505 with parameters: {'lr': 0.007115446994156292, 'lamda': 0.6054779079990757, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:51,130] Finished trial#8 with value: 0.4999999999999999 with parameters: {'lr': 0.004044397261330346, 'lamda': 0.6225578264913987, 'k': 10, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:51,417] Finished trial#9 with value: 0.505 with parameters: {'lr': 0.00018907146223689757, 'lamda': 0.3747974566015829, 'k': 8, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:51,735] Finished trial#10 with value: 0.505 with parameters: {'lr': 0.00026812292922842644, 'lamda': 0.9887428942828328, 'k': 4, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:52,045] Finished trial#11 with value: 0.505 with parameters: {'lr': 0.0132779046688171, 'lamda': 0.2100224928241631, 'k': 4, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:52,363] Finished trial#12 with value: 0.505 with parameters: {'lr': 0.008541558374855502, 'lamda': 0.8238802461013763, 'k': 4, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:52,680] Finished trial#13 with value: 0.505 with parameters: {'lr': 0.0004121581623813637, 'lamda': 0.27102321606857877, 'k': 4, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:52,993] Finished trial#14 with value: 0.505 with parameters: {'lr': 0.004765830892422818, 'lamda': 0.741191768854404, 'k': 4, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:53,291] Finished trial#15 with value: 0.505 with parameters: {'lr': 0.03583324202884722, 'lamda': 0.2839169984598141, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:53,602] Finished trial#16 with value: 0.505 with parameters: {'lr': 0.0010463707388663115, 'lamda': 0.2914252476611047, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:53,919] Finished trial#17 with value: 0.505 with parameters: {'lr': 0.0006498558914416781, 'lamda': 0.7947835682305925, 'k': 4, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:54,217] Finished trial#18 with value: 0.505 with parameters: {'lr': 9.667623051772591e-05, 'lamda': 0.29168048987692646, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:54,519] Finished trial#19 with value: 0.505 with parameters: {'lr': 0.00020665277487168278, 'lamda': 0.3544583431946245, 'k': 8, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:54,858] Finished trial#20 with value: 0.505 with parameters: {'lr': 1.0160067224335398e-05, 'lamda': 0.9091962988013934, 'k': 8, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:55,156] Finished trial#21 with value: 0.505 with parameters: {'lr': 7.399405672295951e-05, 'lamda': 0.9543338877577028, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:55,459] Finished trial#22 with value: 0.505 with parameters: {'lr': 0.00018645346150789456, 'lamda': 0.3502696363537507, 'k': 8, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:55,761] Finished trial#23 with value: 0.505 with parameters: {'lr': 1.0503038502531424e-05, 'lamda': 0.23394839486355287, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:56,060] Finished trial#24 with value: 0.505 with parameters: {'lr': 1.3315971457842672e-05, 'lamda': 0.9859309102477856, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:56,361] Finished trial#25 with value: 0.505 with parameters: {'lr': 8.588585246783473e-05, 'lamda': 0.8113926081627219, 'k': 8, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:56,661] Finished trial#26 with value: 0.505 with parameters: {'lr': 0.015829924387452402, 'lamda': 0.2496066246958287, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:56,961] Finished trial#27 with value: 0.505 with parameters: {'lr': 1.0464731664717626e-05, 'lamda': 0.27542138813456857, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:57,273] Finished trial#28 with value: 0.505 with parameters: {'lr': 2.8869916767267407e-05, 'lamda': 0.742263276592103, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:57,596] Finished trial#29 with value: 0.505 with parameters: {'lr': 0.025706644387333864, 'lamda': 0.7011471148964054, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:57,913] Finished trial#30 with value: 0.5 with parameters: {'lr': 0.004113638614811013, 'lamda': 0.24995263456910413, 'k': 5, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:58,211] Finished trial#31 with value: 0.505 with parameters: {'lr': 9.517275827388279e-05, 'lamda': 0.3254330899560465, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:58,520] Finished trial#32 with value: 0.505 with parameters: {'lr': 0.06778159559481717, 'lamda': 0.7292767367511402, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:58,815] Finished trial#33 with value: 0.4999999999999999 with parameters: {'lr': 3.760010581106217e-05, 'lamda': 0.4362128446227091, 'k': 10, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:59,117] Finished trial#34 with value: 0.505 with parameters: {'lr': 0.0007646923616421915, 'lamda': 0.20109057472371467, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:59,408] Finished trial#35 with value: 0.505 with parameters: {'lr': 0.052386417199286585, 'lamda': 0.6913392836423355, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:59,704] Finished trial#36 with value: 0.4999999999999999 with parameters: {'lr': 0.023134382985591707, 'lamda': 0.5226535728318958, 'k': 10, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:01:59,999] Finished trial#37 with value: 0.505 with parameters: {'lr': 2.040708083730258e-05, 'lamda': 0.31195453250383615, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:00,297] Finished trial#38 with value: 0.505 with parameters: {'lr': 7.80640706884765e-05, 'lamda': 0.8828664442806791, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:00,606] Finished trial#39 with value: 0.505 with parameters: {'lr': 0.00019708644295501058, 'lamda': 0.35969438594076325, 'k': 8, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:00,914] Finished trial#40 with value: 0.5 with parameters: {'lr': 4.993211025654313e-05, 'lamda': 0.412833607725904, 'k': 5, 'epoch': 12}. Best is trial#2 with value: 0.505.\n","name":"stdout"},{"output_type":"stream","text":"[I 2020-05-26 10:02:01,217] Finished trial#41 with value: 0.505 with parameters: {'lr': 1.066348925208264e-05, 'lamda': 0.8919981250959458, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:01,521] Finished trial#42 with value: 0.505 with parameters: {'lr': 1.5775937133762342e-05, 'lamda': 0.9958940234318522, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:01,824] Finished trial#43 with value: 0.505 with parameters: {'lr': 1.6689308809363798e-05, 'lamda': 0.8893810342552694, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:02,116] Finished trial#44 with value: 0.505 with parameters: {'lr': 5.743250168327003e-05, 'lamda': 0.5495220600975191, 'k': 8, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:02,416] Finished trial#45 with value: 0.505 with parameters: {'lr': 1.964636760838781e-05, 'lamda': 0.836164228003733, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:02,724] Finished trial#46 with value: 0.505 with parameters: {'lr': 0.0003537119786635495, 'lamda': 0.23187802444265412, 'k': 8, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:03,024] Finished trial#47 with value: 0.505 with parameters: {'lr': 2.909401779542892e-05, 'lamda': 0.2218705067578182, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:03,320] Finished trial#48 with value: 0.4999999999999999 with parameters: {'lr': 1.3047339971185448e-05, 'lamda': 0.25350283509229515, 'k': 10, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:03,616] Finished trial#49 with value: 0.5 with parameters: {'lr': 2.545671187907231e-05, 'lamda': 0.2173262156825029, 'k': 5, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:03,913] Finished trial#50 with value: 0.505 with parameters: {'lr': 0.00013167248783306403, 'lamda': 0.9699653391345977, 'k': 8, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:04,218] Finished trial#51 with value: 0.505 with parameters: {'lr': 0.0021026213243546168, 'lamda': 0.6486625572338203, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:04,520] Finished trial#52 with value: 0.505 with parameters: {'lr': 0.014906682975846516, 'lamda': 0.7693503181055272, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:04,827] Finished trial#53 with value: 0.505 with parameters: {'lr': 0.0026095212540096185, 'lamda': 0.6567321820820539, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:05,130] Finished trial#54 with value: 0.505 with parameters: {'lr': 0.011528413451434343, 'lamda': 0.3163964069677513, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:05,442] Finished trial#55 with value: 0.505 with parameters: {'lr': 0.0944703428814085, 'lamda': 0.5989274455313424, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:05,772] Finished trial#56 with value: 0.505 with parameters: {'lr': 0.04752864144899332, 'lamda': 0.31088765543473823, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:06,073] Finished trial#57 with value: 0.505 with parameters: {'lr': 0.0866642025184753, 'lamda': 0.5724445986848725, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:06,371] Finished trial#58 with value: 0.505 with parameters: {'lr': 0.0581918408042261, 'lamda': 0.7270606828456664, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:06,680] Finished trial#59 with value: 0.505 with parameters: {'lr': 0.0006261001145430355, 'lamda': 0.6985130855495144, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:06,975] Finished trial#60 with value: 0.505 with parameters: {'lr': 0.06538866388375811, 'lamda': 0.4729960004218525, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:07,274] Finished trial#61 with value: 0.505 with parameters: {'lr': 0.03022766165750829, 'lamda': 0.27082888633017865, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:07,574] Finished trial#62 with value: 0.505 with parameters: {'lr': 0.020679375642400646, 'lamda': 0.2664694800452172, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:07,872] Finished trial#63 with value: 0.505 with parameters: {'lr': 0.00012490637104407935, 'lamda': 0.31403393166908733, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:08,165] Finished trial#64 with value: 0.505 with parameters: {'lr': 0.0006643882052760458, 'lamda': 0.3809829092657369, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:08,464] Finished trial#65 with value: 0.505 with parameters: {'lr': 0.0001321363399836148, 'lamda': 0.339425994329563, 'k': 8, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:08,769] Finished trial#66 with value: 0.505 with parameters: {'lr': 0.0013041904252099172, 'lamda': 0.8623471368927801, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:09,078] Finished trial#67 with value: 0.505 with parameters: {'lr': 0.03644842957931488, 'lamda': 0.33821351785302306, 'k': 4, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:09,386] Finished trial#68 with value: 0.505 with parameters: {'lr': 0.04759506677095627, 'lamda': 0.4102144693163066, 'k': 4, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:09,678] Finished trial#69 with value: 0.505 with parameters: {'lr': 4.1230091376066805e-05, 'lamda': 0.9138676314306612, 'k': 8, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:09,979] Finished trial#70 with value: 0.4999999999999999 with parameters: {'lr': 0.00023198398084586937, 'lamda': 0.9304086366734515, 'k': 10, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:10,276] Finished trial#71 with value: 0.505 with parameters: {'lr': 0.0006006378602765157, 'lamda': 0.3725965653214068, 'k': 8, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:10,571] Finished trial#72 with value: 0.505 with parameters: {'lr': 1.8808445750926262e-05, 'lamda': 0.8468388599343872, 'k': 8, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:10,862] Finished trial#73 with value: 0.505 with parameters: {'lr': 0.000461364037101225, 'lamda': 0.37304619982724124, 'k': 8, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:11,153] Finished trial#74 with value: 0.505 with parameters: {'lr': 0.0003499844466382436, 'lamda': 0.4027139044452633, 'k': 8, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:11,453] Finished trial#75 with value: 0.505 with parameters: {'lr': 1.926699689063977e-05, 'lamda': 0.8759682269800136, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:11,750] Finished trial#76 with value: 0.505 with parameters: {'lr': 0.0029696989372949576, 'lamda': 0.6240284035512786, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:12,056] Finished trial#77 with value: 0.5 with parameters: {'lr': 0.00654277151410193, 'lamda': 0.6433048826677391, 'k': 5, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:12,364] Finished trial#78 with value: 0.505 with parameters: {'lr': 0.0012097490351241607, 'lamda': 0.47106717096451284, 'k': 4, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:12,742] Finished trial#79 with value: 0.505 with parameters: {'lr': 0.09810697683533622, 'lamda': 0.5902257496267428, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:13,084] Finished trial#80 with value: 0.505 with parameters: {'lr': 0.0026507652670756335, 'lamda': 0.7799629089761256, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:13,379] Finished trial#81 with value: 0.505 with parameters: {'lr': 4.104300922745308e-05, 'lamda': 0.9364398993216697, 'k': 8, 'epoch': 11}. Best is trial#2 with value: 0.505.\n","name":"stdout"},{"output_type":"stream","text":"[I 2020-05-26 10:02:13,672] Finished trial#82 with value: 0.505 with parameters: {'lr': 1.5289137849486307e-05, 'lamda': 0.7863763571785314, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:13,967] Finished trial#83 with value: 0.505 with parameters: {'lr': 0.010964130241952178, 'lamda': 0.6579402486305578, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:14,267] Finished trial#84 with value: 0.505 with parameters: {'lr': 0.08698219883216297, 'lamda': 0.4916908205210452, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:14,566] Finished trial#85 with value: 0.505 with parameters: {'lr': 0.06453281258163607, 'lamda': 0.5542847104070878, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:14,857] Finished trial#86 with value: 0.505 with parameters: {'lr': 0.044720613754619186, 'lamda': 0.5216359352838875, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:15,152] Finished trial#87 with value: 0.505 with parameters: {'lr': 0.03189968431832419, 'lamda': 0.6836552904032587, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:15,448] Finished trial#88 with value: 0.505 with parameters: {'lr': 0.02047946392328375, 'lamda': 0.5655515070005307, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:15,747] Finished trial#89 with value: 0.505 with parameters: {'lr': 0.07936073495878648, 'lamda': 0.45447388433635666, 'k': 8, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:16,046] Finished trial#90 with value: 0.505 with parameters: {'lr': 0.05927480194463005, 'lamda': 0.2626222877477163, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:16,342] Finished trial#91 with value: 0.505 with parameters: {'lr': 0.0006450845298841168, 'lamda': 0.29696582487140666, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:16,652] Finished trial#92 with value: 0.505 with parameters: {'lr': 0.00014635864820385748, 'lamda': 0.33058396796626377, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:16,969] Finished trial#93 with value: 0.505 with parameters: {'lr': 0.0002890157054891204, 'lamda': 0.27203347114940785, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:17,276] Finished trial#94 with value: 0.505 with parameters: {'lr': 0.001232904387719598, 'lamda': 0.24036681901335655, 'k': 4, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:17,581] Finished trial#95 with value: 0.505 with parameters: {'lr': 0.0008439852433028449, 'lamda': 0.3369631681189988, 'k': 4, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:17,966] Finished trial#96 with value: 0.505 with parameters: {'lr': 0.0382265161093612, 'lamda': 0.39660786514815416, 'k': 4, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:18,280] Finished trial#97 with value: 0.4999999999999999 with parameters: {'lr': 0.026995471032170367, 'lamda': 0.3027208985703136, 'k': 10, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:18,593] Finished trial#98 with value: 0.505 with parameters: {'lr': 5.8660709252071676e-05, 'lamda': 0.28807870506596056, 'k': 8, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:18,888] Finished trial#99 with value: 0.505 with parameters: {'lr': 0.0020186463241208615, 'lamda': 0.7651257026510275, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:19,182] Finished trial#100 with value: 0.505 with parameters: {'lr': 0.005697145013418898, 'lamda': 0.7180415521945794, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:19,493] Finished trial#101 with value: 0.505 with parameters: {'lr': 0.00013736580951873115, 'lamda': 0.3799478877818922, 'k': 4, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:19,804] Finished trial#102 with value: 0.505 with parameters: {'lr': 0.00015135816472901934, 'lamda': 0.3457921300771698, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:20,112] Finished trial#103 with value: 0.505 with parameters: {'lr': 0.0005132489507201342, 'lamda': 0.36664950534478363, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:20,422] Finished trial#104 with value: 0.505 with parameters: {'lr': 0.0004905367389650338, 'lamda': 0.39242773454634167, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:20,734] Finished trial#105 with value: 0.505 with parameters: {'lr': 0.0003649958288012933, 'lamda': 0.41873757150355884, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:21,038] Finished trial#106 with value: 0.505 with parameters: {'lr': 2.1787161649105444e-05, 'lamda': 0.4017417234531534, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:21,337] Finished trial#107 with value: 0.5 with parameters: {'lr': 0.0029753737909025894, 'lamda': 0.8414627984276558, 'k': 5, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:21,631] Finished trial#108 with value: 0.505 with parameters: {'lr': 0.01846294731577444, 'lamda': 0.2803647866265542, 'k': 8, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:21,938] Finished trial#109 with value: 0.505 with parameters: {'lr': 0.008988582205679935, 'lamda': 0.4293532954909203, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:22,246] Finished trial#110 with value: 0.505 with parameters: {'lr': 0.0014924042745327977, 'lamda': 0.44737003458974434, 'k': 4, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:22,575] Finished trial#111 with value: 0.505 with parameters: {'lr': 0.0005006854144700959, 'lamda': 0.6020035579744893, 'k': 4, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:22,871] Finished trial#112 with value: 0.505 with parameters: {'lr': 0.0009747247887767902, 'lamda': 0.4703079623930931, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:23,169] Finished trial#113 with value: 0.505 with parameters: {'lr': 0.0037986963229952814, 'lamda': 0.808693644289116, 'k': 8, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:23,472] Finished trial#114 with value: 0.505 with parameters: {'lr': 3.949204745647333e-05, 'lamda': 0.9429604407413391, 'k': 8, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:23,772] Finished trial#115 with value: 0.505 with parameters: {'lr': 1.795501524876523e-05, 'lamda': 0.7788455684478222, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:24,067] Finished trial#116 with value: 0.505 with parameters: {'lr': 1.3480875619887386e-05, 'lamda': 0.6215962471734934, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:24,366] Finished trial#117 with value: 0.505 with parameters: {'lr': 0.003069079676370451, 'lamda': 0.6708977955107209, 'k': 8, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:24,671] Finished trial#118 with value: 0.505 with parameters: {'lr': 0.004905739121490698, 'lamda': 0.7214065745897066, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:24,968] Finished trial#119 with value: 0.505 with parameters: {'lr': 0.0014829383808977565, 'lamda': 0.5511804312875112, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:25,264] Finished trial#120 with value: 0.505 with parameters: {'lr': 0.09318206081303397, 'lamda': 0.5104012744082271, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:25,567] Finished trial#121 with value: 0.505 with parameters: {'lr': 0.07183387475933023, 'lamda': 0.5027079620522381, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:25,863] Finished trial#122 with value: 0.505 with parameters: {'lr': 0.058284431527920295, 'lamda': 0.5301638113050404, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n","name":"stdout"},{"output_type":"stream","text":"[I 2020-05-26 10:02:26,157] Finished trial#123 with value: 0.505 with parameters: {'lr': 0.028951077153470374, 'lamda': 0.5668276361304311, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:26,455] Finished trial#124 with value: 0.505 with parameters: {'lr': 0.03934808889931656, 'lamda': 0.48466040895281676, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:26,757] Finished trial#125 with value: 0.505 with parameters: {'lr': 0.02140002782854367, 'lamda': 0.45539679883545175, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:27,056] Finished trial#126 with value: 0.505 with parameters: {'lr': 0.08088183943439811, 'lamda': 0.584341950948867, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:27,356] Finished trial#127 with value: 0.505 with parameters: {'lr': 0.011863595796069657, 'lamda': 0.5342377861048171, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:27,666] Finished trial#128 with value: 0.505 with parameters: {'lr': 0.044056362043360546, 'lamda': 0.2981320328900294, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:27,989] Finished trial#129 with value: 0.505 with parameters: {'lr': 0.05926616556663185, 'lamda': 0.5144843767347151, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:28,292] Finished trial#130 with value: 0.505 with parameters: {'lr': 0.031992327472519094, 'lamda': 0.25491792038362654, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:28,595] Finished trial#131 with value: 0.505 with parameters: {'lr': 0.00027619483790640995, 'lamda': 0.4928302891790747, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:28,902] Finished trial#132 with value: 0.505 with parameters: {'lr': 0.0008859298525207766, 'lamda': 0.2579211674114819, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:29,200] Finished trial#133 with value: 0.505 with parameters: {'lr': 0.00118175786040702, 'lamda': 0.2399808384784363, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:29,537] Finished trial#134 with value: 0.505 with parameters: {'lr': 0.0367708225523799, 'lamda': 0.335313176541776, 'k': 4, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:29,880] Finished trial#135 with value: 0.505 with parameters: {'lr': 0.03980345592783, 'lamda': 0.28963933619036386, 'k': 4, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:30,214] Finished trial#136 with value: 0.505 with parameters: {'lr': 6.490751959375849e-05, 'lamda': 0.26701695532480985, 'k': 4, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:30,529] Finished trial#137 with value: 0.505 with parameters: {'lr': 0.0018981972653823913, 'lamda': 0.2877402437582402, 'k': 4, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:30,850] Finished trial#138 with value: 0.505 with parameters: {'lr': 0.0008909770298261321, 'lamda': 0.32169841921090014, 'k': 4, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:31,167] Finished trial#139 with value: 0.505 with parameters: {'lr': 0.00010592371647522349, 'lamda': 0.3568621034071047, 'k': 4, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:31,478] Finished trial#140 with value: 0.505 with parameters: {'lr': 0.00017724266218988136, 'lamda': 0.24068333317864057, 'k': 4, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:31,782] Finished trial#141 with value: 0.505 with parameters: {'lr': 0.00026802213908561393, 'lamda': 0.23968654880626195, 'k': 4, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:32,080] Finished trial#142 with value: 0.4999999999999999 with parameters: {'lr': 0.00023694547146350082, 'lamda': 0.21898773834902563, 'k': 10, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:32,375] Finished trial#143 with value: 0.505 with parameters: {'lr': 0.0007142458143247855, 'lamda': 0.546387915007687, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:32,689] Finished trial#144 with value: 0.505 with parameters: {'lr': 0.0005654730247291932, 'lamda': 0.3861931239294156, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:33,002] Finished trial#145 with value: 0.505 with parameters: {'lr': 0.0003397344424313007, 'lamda': 0.348089731979148, 'k': 4, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:33,308] Finished trial#146 with value: 0.505 with parameters: {'lr': 0.00016798669759899828, 'lamda': 0.3916063580456003, 'k': 4, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:33,618] Finished trial#147 with value: 0.505 with parameters: {'lr': 0.00045266244380164723, 'lamda': 0.36280392006675133, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:33,926] Finished trial#148 with value: 0.505 with parameters: {'lr': 0.00044603293709251, 'lamda': 0.4255252357557678, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:34,233] Finished trial#149 with value: 0.505 with parameters: {'lr': 0.0003241420054408742, 'lamda': 0.3983170231769951, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:34,539] Finished trial#150 with value: 0.505 with parameters: {'lr': 0.009562423068157867, 'lamda': 0.4232824116047696, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:34,853] Finished trial#151 with value: 0.505 with parameters: {'lr': 0.007251077809205853, 'lamda': 0.41516876386265245, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:35,162] Finished trial#152 with value: 0.505 with parameters: {'lr': 0.0005092718582165865, 'lamda': 0.4388188295181485, 'k': 4, 'epoch': 9}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:35,471] Finished trial#153 with value: 0.505 with parameters: {'lr': 0.0015052054778214863, 'lamda': 0.3758877945722649, 'k': 4, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:35,787] Finished trial#154 with value: 0.505 with parameters: {'lr': 0.002167812682542059, 'lamda': 0.3999146134627209, 'k': 4, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:36,086] Finished trial#155 with value: 0.505 with parameters: {'lr': 0.0008161250658982822, 'lamda': 0.32981395602138314, 'k': 8, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:36,393] Finished trial#156 with value: 0.505 with parameters: {'lr': 9.159765973920925e-05, 'lamda': 0.304052737040076, 'k': 8, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:36,710] Finished trial#157 with value: 0.505 with parameters: {'lr': 0.004624412590092258, 'lamda': 0.44812671502614215, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:37,030] Finished trial#158 with value: 0.505 with parameters: {'lr': 0.0063207571449723395, 'lamda': 0.4653219218685246, 'k': 4, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:37,354] Finished trial#159 with value: 0.505 with parameters: {'lr': 1.0498603187631462e-05, 'lamda': 0.6220995276270178, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:37,677] Finished trial#160 with value: 0.505 with parameters: {'lr': 2.3640321178910254e-05, 'lamda': 0.4095947040075857, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:37,994] Finished trial#161 with value: 0.505 with parameters: {'lr': 0.0035812433268927147, 'lamda': 0.8111674387333099, 'k': 4, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:38,305] Finished trial#162 with value: 0.505 with parameters: {'lr': 0.0038840845971699974, 'lamda': 0.7584918877499663, 'k': 4, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:38,634] Finished trial#163 with value: 0.505 with parameters: {'lr': 0.001536627794105372, 'lamda': 0.6760791472887472, 'k': 4, 'epoch': 12}. Best is trial#2 with value: 0.505.\n","name":"stdout"},{"output_type":"stream","text":"[I 2020-05-26 10:02:38,975] Finished trial#164 with value: 0.505 with parameters: {'lr': 1.2374582724527737e-05, 'lamda': 0.9534599306912925, 'k': 4, 'epoch': 11}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:39,292] Finished trial#165 with value: 0.5 with parameters: {'lr': 1.4362213399937621e-05, 'lamda': 0.612285853950937, 'k': 5, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:39,620] Finished trial#166 with value: 0.505 with parameters: {'lr': 0.0003603728414594243, 'lamda': 0.39847871659302503, 'k': 4, 'epoch': 10}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:39,933] Finished trial#167 with value: 0.505 with parameters: {'lr': 0.008546903005037448, 'lamda': 0.6604930067323166, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:40,236] Finished trial#168 with value: 0.505 with parameters: {'lr': 0.0052161453646496925, 'lamda': 0.5357487103455103, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:40,538] Finished trial#169 with value: 0.505 with parameters: {'lr': 0.002435504651794564, 'lamda': 0.5056817048834759, 'k': 8, 'epoch': 12}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:40,847] Finished trial#170 with value: 0.505 with parameters: {'lr': 0.015440899262346382, 'lamda': 0.4960991259257012, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:41,151] Finished trial#171 with value: 0.505 with parameters: {'lr': 0.06969606754663489, 'lamda': 0.5665425292875351, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:41,452] Finished trial#172 with value: 0.505 with parameters: {'lr': 0.026610481195283694, 'lamda': 0.48070106693703957, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:41,754] Finished trial#173 with value: 0.505 with parameters: {'lr': 0.0542896224181956, 'lamda': 0.4627429754240803, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:42,051] Finished trial#174 with value: 0.505 with parameters: {'lr': 0.08156987694665853, 'lamda': 0.5809589590682757, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:42,352] Finished trial#175 with value: 0.505 with parameters: {'lr': 0.022388458233055308, 'lamda': 0.5937889305700965, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:42,652] Finished trial#176 with value: 0.505 with parameters: {'lr': 0.045014833942564385, 'lamda': 0.7031726932197658, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:42,949] Finished trial#177 with value: 0.505 with parameters: {'lr': 0.01701200551679157, 'lamda': 0.5249749601800896, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:43,250] Finished trial#178 with value: 0.505 with parameters: {'lr': 0.05592433763085703, 'lamda': 0.5615721943821097, 'k': 8, 'epoch': 15}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:43,549] Finished trial#179 with value: 0.505 with parameters: {'lr': 0.08062177431807532, 'lamda': 0.5195050532064026, 'k': 8, 'epoch': 13}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:43,846] Finished trial#180 with value: 0.505 with parameters: {'lr': 0.09497842664674648, 'lamda': 0.5363682123645808, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:44,141] Finished trial#181 with value: 0.505 with parameters: {'lr': 0.0659215262404562, 'lamda': 0.5022113676694359, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:44,442] Finished trial#182 with value: 0.505 with parameters: {'lr': 0.03316149615451991, 'lamda': 0.5175126017103194, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:44,747] Finished trial#183 with value: 0.505 with parameters: {'lr': 0.045673130055070205, 'lamda': 0.2574345660499442, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:45,049] Finished trial#184 with value: 0.505 with parameters: {'lr': 0.0010769098688801196, 'lamda': 0.22808345429485385, 'k': 8, 'epoch': 6}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:45,348] Finished trial#185 with value: 0.505 with parameters: {'lr': 0.02965325935434896, 'lamda': 0.4803404311785099, 'k': 8, 'epoch': 7}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:45,647] Finished trial#186 with value: 0.505 with parameters: {'lr': 0.04032677866516774, 'lamda': 0.4936738418835181, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:45,948] Finished trial#187 with value: 0.505 with parameters: {'lr': 0.03671184488068336, 'lamda': 0.2748440511163665, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:46,246] Finished trial#188 with value: 0.505 with parameters: {'lr': 0.024495385896481793, 'lamda': 0.2501112121593126, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:46,548] Finished trial#189 with value: 0.505 with parameters: {'lr': 0.03909328282846544, 'lamda': 0.24361229346956467, 'k': 8, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:46,852] Finished trial#190 with value: 0.4999999999999999 with parameters: {'lr': 0.054428627246296324, 'lamda': 0.2636025696898914, 'k': 10, 'epoch': 5}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:47,152] Finished trial#191 with value: 0.505 with parameters: {'lr': 0.0032323615098206657, 'lamda': 0.6312706924691645, 'k': 8, 'epoch': 8}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:47,461] Finished trial#192 with value: 0.505 with parameters: {'lr': 0.0008509079032649046, 'lamda': 0.31882938423395546, 'k': 4, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:47,774] Finished trial#193 with value: 0.505 with parameters: {'lr': 0.03322642689384771, 'lamda': 0.2834555382022385, 'k': 4, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:48,088] Finished trial#194 with value: 0.505 with parameters: {'lr': 6.176171913759762e-05, 'lamda': 0.2952344001002721, 'k': 4, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:48,386] Finished trial#195 with value: 0.505 with parameters: {'lr': 0.049729727720596285, 'lamda': 0.5405989616466306, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:48,708] Finished trial#196 with value: 0.505 with parameters: {'lr': 0.04827621980265973, 'lamda': 0.5462239501639174, 'k': 8, 'epoch': 4}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:49,024] Finished trial#197 with value: 0.5 with parameters: {'lr': 0.00026197781499658085, 'lamda': 0.23988979142163258, 'k': 5, 'epoch': 3}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:49,328] Finished trial#198 with value: 0.505 with parameters: {'lr': 3.024872961609354e-05, 'lamda': 0.6129774581082937, 'k': 8, 'epoch': 14}. Best is trial#2 with value: 0.505.\n[I 2020-05-26 10:02:49,649] Finished trial#199 with value: 0.505 with parameters: {'lr': 0.000742633867526737, 'lamda': 0.25721224012873556, 'k': 4, 'epoch': 6}. Best is trial#2 with value: 0.505.\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_sgd=SVM(lr=0.0166431449930997,lamb=0.5963218576040026,epoch=10)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w=svm_sgd.train_func(X_train,y_train)\nsvm_sgd.validation(X_val,y_val,w)","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"0.47424242424242424"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_validate(train_op_data,labels,svm_sgd,lr=0.01,lamda=0.2,epoch=100,k=5)","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"0.501"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install  qpsolvers\nfrom qpsolvers import solve_qp","execution_count":44,"outputs":[{"output_type":"stream","text":"Collecting qpsolvers\n  Downloading qpsolvers-1.3.tar.gz (10 kB)\nCollecting quadprog\n  Downloading quadprog-0.1.7.tar.gz (18 kB)\nRequirement already satisfied: Cython in /opt/conda/lib/python3.7/site-packages (from quadprog->qpsolvers) (0.29.17)\nBuilding wheels for collected packages: qpsolvers, quadprog\n  Building wheel for qpsolvers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for qpsolvers: filename=qpsolvers-1.3-py3-none-any.whl size=17440 sha256=b8a569047373f299bb540ee1907a773f561d596d1acde544240d47657c8fd920\n  Stored in directory: /root/.cache/pip/wheels/52/81/13/36e48a1e0441f4a9a22e626b477b58604eb33c1d6bdd14a265\n  Building wheel for quadprog (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for quadprog: filename=quadprog-0.1.7-cp37-cp37m-linux_x86_64.whl size=329595 sha256=194a4d0687f71cb35cb394e8f669d3662639bf4ea0317752606cccea2a41343d\n  Stored in directory: /root/.cache/pip/wheels/70/93/15/32155be29d7e221844ba69884ab5d8c9e36998d6d4a92cd62a\nSuccessfully built qpsolvers quadprog\nInstalling collected packages: quadprog, qpsolvers\nSuccessfully installed qpsolvers-1.3 quadprog-0.1.7\nWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# def svm_primal_hard_to_qp(X, y):\n#     n, p = X.shape\n#     assert (len(y) == n)\n    \n#     Xy = np.diag(y).dot(X)\n#     # Primal formulation, hard margin\n#     diag_P = np.ones(p + 1) # correct this!\n#     diag_P[-1] = 0 # The one multiplies with b\n#     # As a regularization, we add epsilon * identity to P\n#     eps = 1e-12\n#     diag_P += eps\n#     P = np.diag(diag_P)\n    \n#     q = np.zeros(p + 1)\n#     G = np.hstack([Xy, y[:, np.newaxis]]) # newaxis transforms y into column matrix\n#     # G = np.vstack([Xy.T, y]).T\n#     h = - np.ones(n)\n#     A = None\n#     b = None\n    \n#     return P, q, G, h, A, b\n\n# x = solve_qp(*svm_primal_hard_to_qp(x_train, y_train))\n# n, p = X_train.shape\n# w, b = x[:-1], x[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install cvxopt","execution_count":34,"outputs":[{"output_type":"stream","text":"Collecting cvxopt\n  Downloading cvxopt-1.2.5-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n     || 11.6 MB 383 kB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: cvxopt\nSuccessfully installed cvxopt-1.2.5\nWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cvxopt","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM dual problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncvxopt.solvers.options['show_progress'] = False\n\n\ndef getDual(X_train,y_train):\n    m,n = X_train.shape\n    y = y_train.reshape(-1,1) * 1.\n    X_dash = y_train * X_train\n    H = np.dot(X_dash , X_dash.T) * 1\n   # P = P = cvxopt_matrix(H)\n  \n    #Converting into cvxopt format\n    P = cvxopt.matrix(H)\n    q = cvxopt.matrix(-np.ones((m, 1)))\n    G = cvxopt.matrix(-np.eye(m))\n    h = cvxopt.matrix(np.zeros(m))\n    A = cvxopt.matrix(y.reshape(1, -1))\n    b = cvxopt.matrix(np.zeros(1))\n\n    #Setting solver parameters (change default to decrease tolerance) \n    cvxopt.solvers.options['show_progress'] = False\n    cvxopt.solvers.options['abstol'] = 1e-10\n    cvxopt.solvers.options['reltol'] = 1e-10\n    cvxopt.solvers.options['feastol'] = 1e-10\n\n    #Run solver\n    sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n    alphas = np.array(sol['x'])\n    return alphas\n        ","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#w parameter in vectorized form\nalphas=getDual(X_train,y_train)\nw = np.sum((y_train* alphas) * X_train, axis=0)\n\n\nS = (alphas > 1e-4).reshape(-1)\n\n#Computing b\nb = y_train[S] - np.dot(X_train[S], w)\nprint(b)\nb=b[0]\nprint(b)\n","execution_count":76,"outputs":[{"output_type":"stream","text":"[[ 1.00006208  1.00025909  0.99968729 ...  1.0003954   1.0000324\n   1.00119241]\n [-0.99993792 -0.99974091 -1.00031271 ... -0.9996046  -0.9999676\n  -0.99880759]\n [-0.99993792 -0.99974091 -1.00031271 ... -0.9996046  -0.9999676\n  -0.99880759]\n ...\n [-0.99993792 -0.99974091 -1.00031271 ... -0.9996046  -0.9999676\n  -0.99880759]\n [ 1.00006208  1.00025909  0.99968729 ...  1.0003954   1.0000324\n   1.00119241]\n [ 1.00006208  1.00025909  0.99968729 ...  1.0003954   1.0000324\n   1.00119241]]\n[1.00006208 1.00025909 0.99968729 ... 1.0003954  1.0000324  1.00119241]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(b)","execution_count":77,"outputs":[{"output_type":"execute_result","execution_count":77,"data":{"text/plain":"1340"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validation(x_val,y_val,w,b):\n        y_test_predicted = np.array([])\n        for i in range(x_val.shape[0]):\n            #print(w.shape,x_val.shape)\n            yp = np.sign(np.dot(w.T, x_val[i])+b[i]) #model\n            y_test_predicted = np.append(y_test_predicted, yp)\n            print(y_test_predicted.min())\n        return accuracy_score(y_val, y_test_predicted)","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation(X_val,y_val,w,b)","execution_count":85,"outputs":[{"output_type":"stream","text":"1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n","name":"stdout"},{"output_type":"execute_result","execution_count":85,"data":{"text/plain":"0.5287878787878788"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# # soft margin SVM with kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import linalg\nimport cvxopt\nimport cvxopt.solvers","execution_count":63,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define a set of kernels"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef linear_kernel(x1, x2):\n    return np.dot(x1, x2)\n\ndef polynomial_kernel(x, y, p=2):\n    return (1 + np.dot(x, y)) ** p\n\ndef gaussian_kernel(x, y, sigma=5.0):\n    return np.exp(-linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n\n\nkernels=[linear_kernel,polynomial_kernel,gaussian_kernel]","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SVM(object):\n\n    def __init__(self, kernel=linear_kernel, C=0.0001):\n        self.kernel = kernel\n        self.C = C\n        if self.C is not None: self.C = float(self.C)\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n\n        K = np.zeros((n_samples, n_samples))\n        for i in range(n_samples):\n            for j in range(n_samples):\n                K[i,j] = self.kernel(X[i], X[j])\n        y = y_train.reshape(-1,1) * 1.\n        X_dash = y_train * X_train\n        H = np.dot(X_dash , X_dash.T) * 1\n\n        P = cvxopt.matrix(np.outer(y,y) * K)\n        q = cvxopt.matrix(np.ones(n_samples) * -1)\n        A = cvxopt.matrix(y, (1,n_samples))\n        b = cvxopt.matrix(0.0)\n\n        if self.C is None:\n            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n            h = cvxopt.matrix(np.zeros(n_samples))\n        else:\n            tmp1 = np.diag(np.ones(n_samples) * -1)\n            tmp2 = np.identity(n_samples)\n            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n            tmp1 = np.zeros(n_samples)\n            tmp2 = np.ones(n_samples) * self.C\n            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n\n        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n\n        a = np.ravel(solution['x'])\n\n        sv = a > 1e-5\n        ind = np.arange(len(a))[sv]\n        self.a = a[sv]\n        self.sv = X[sv]\n        self.sv_y = y[sv]\n        print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n\n        self.b = 0\n        for n in range(len(self.a)):\n            self.b += self.sv_y[n]\n            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])\n        self.b /= len(self.a)\n\n        # Weight vector\n        if self.kernel == linear_kernel:\n            self.w = np.zeros(n_features)\n            for n in range(len(self.a)):\n                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n        else:\n            self.w = None\n\n    def project(self, X):\n        if self.w is not None:\n            return np.dot(X, self.w) + self.b\n        else:\n            y_predict = np.zeros(len(X))\n            for i in range(len(X)):\n                s = 0\n                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n                    s += a * sv_y * self.kernel(X[i], sv)\n                y_predict[i] = s\n            return y_predict + self.b\n\n    def predict(self, X):\n        return np.sign(self.project(X))","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in kernels:\n    #print(k)\n    svmm=SVM(kernel=k)\n    svmm.fit(X_train,y_train)\n    y_predict = svmm.predict(X_val)\n    print(y_predict)\n    \n    print(accuracy_score(y_val, y_predict))\n","execution_count":96,"outputs":[{"output_type":"stream","text":"1263 support vectors out of 1340 points\n[-1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.\n -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.\n  1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.\n  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n  1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1.  1.\n -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.\n -1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1.\n  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1. -1.  1.\n -1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1.\n  1. -1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.\n  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n -1. -1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.\n -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1.\n  1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.\n  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1.\n  1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.\n  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1.\n  1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1. -1. -1.\n -1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1.\n  1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.\n -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.\n  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.\n -1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.\n  1. -1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1.\n -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1.\n -1. -1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1.\n  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.\n  1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1.  1.\n -1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1.\n  1.  1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.\n  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.\n -1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1.]\n0.5863636363636363\n1063 support vectors out of 1340 points\n[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n0.4712121212121212\n1315 support vectors out of 1340 points\n[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n0.5287878787878788\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}